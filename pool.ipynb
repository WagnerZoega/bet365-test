{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/WagnerZoega/bet365-test/blob/main/pool.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install cupy-cuda11x coincurve eth-utils base58 pycryptodome\n",
        "!apt install cupy-cuda11x coincurve eth-utils base58 pycryptodome"
      ],
      "metadata": {
        "id": "QbNQvSZv3fGz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Script para instalar dependÃªncias CUDA corretas para o Google Colab\n",
        "Resolve problemas de compatibilidade de biblioteca como o libnvrtc.so nÃ£o encontrado\n",
        "\"\"\"\n",
        "import os\n",
        "import sys\n",
        "import subprocess\n",
        "import glob\n",
        "import re\n",
        "\n",
        "def check_cuda_version():\n",
        "    \"\"\"Verifica a versÃ£o do CUDA instalada no sistema\"\"\"\n",
        "    try:\n",
        "        # Executa o comando nvcc --version\n",
        "        result = subprocess.run(['nvcc', '--version'], stdout=subprocess.PIPE, text=True)\n",
        "        output = result.stdout\n",
        "\n",
        "        # Extrai a versÃ£o do CUDA usando regex\n",
        "        match = re.search(r'release (\\d+\\.\\d+)', output)\n",
        "        if match:\n",
        "            version = match.group(1)\n",
        "            print(f\"âœ… VersÃ£o do CUDA detectada: {version}\")\n",
        "            return version\n",
        "        else:\n",
        "            # Tenta com nvidia-smi\n",
        "            result = subprocess.run(['nvidia-smi'], stdout=subprocess.PIPE, text=True)\n",
        "            output = result.stdout\n",
        "            match = re.search(r'CUDA Version: (\\d+\\.\\d+)', output)\n",
        "            if match:\n",
        "                version = match.group(1)\n",
        "                print(f\"âœ… VersÃ£o do CUDA detectada (via nvidia-smi): {version}\")\n",
        "                return version\n",
        "\n",
        "            print(\"âš ï¸ NÃ£o foi possÃ­vel determinar a versÃ£o CUDA, assumindo 12.0\")\n",
        "            return \"12.0\"  # PadrÃ£o para Colab recentes\n",
        "    except Exception as e:\n",
        "        print(f\"âš ï¸ Erro ao verificar versÃ£o CUDA: {e}\")\n",
        "        print(\"âš ï¸ Assumindo CUDA 12.0\")\n",
        "        return \"12.0\"  # PadrÃ£o para Colab recentes\n",
        "\n",
        "def install_correct_cupy():\n",
        "    \"\"\"Instala a versÃ£o correta do CuPy baseado na versÃ£o CUDA\"\"\"\n",
        "    cuda_version = check_cuda_version()\n",
        "    major_version = int(cuda_version.split('.')[0])\n",
        "\n",
        "    print(f\"\\nðŸ”„ Instalando CuPy compatÃ­vel com CUDA {cuda_version}...\")\n",
        "\n",
        "    # Primeiro remover qualquer instalaÃ§Ã£o existente para evitar conflitos\n",
        "    subprocess.run([sys.executable, '-m', 'pip', 'uninstall', '-y', 'cupy', 'cupy-cuda11x', 'cupy-cuda12x'])\n",
        "\n",
        "    # Limpar o cache pip para garantir instalaÃ§Ã£o limpa\n",
        "    subprocess.run([sys.executable, '-m', 'pip', 'cache', 'purge'])\n",
        "\n",
        "    # Instalar a versÃ£o correta do CuPy\n",
        "    if major_version >= 12:\n",
        "        print(\"ðŸ”„ Instalando cupy-cuda12x...\")\n",
        "        subprocess.run([sys.executable, '-m', 'pip', 'install', '--no-cache-dir', 'cupy-cuda12x'])\n",
        "    elif major_version == 11:\n",
        "        print(\"ðŸ”„ Instalando cupy-cuda11x...\")\n",
        "        subprocess.run([sys.executable, '-m', 'pip', 'install', '--no-cache-dir', 'cupy-cuda11x'])\n",
        "    else:\n",
        "        print(f\"âš ï¸ VersÃ£o CUDA {cuda_version} pode nÃ£o ser compatÃ­vel com CuPy atual\")\n",
        "        print(\"ðŸ”„ Tentando instalar cupy-cuda11x como fallback...\")\n",
        "        subprocess.run([sys.executable, '-m', 'pip', 'install', '--no-cache-dir', 'cupy-cuda11x'])\n",
        "\n",
        "    # Verifica se CuPy foi instalado corretamente\n",
        "    print(\"ðŸ” Verificando instalaÃ§Ã£o do CuPy...\")\n",
        "    try:\n",
        "        subprocess.run([sys.executable, '-c', 'import cupy; print(\\\"CuPy importado com sucesso\\\")'], check=True)\n",
        "        print(\"âœ… CuPy instalado corretamente\")\n",
        "    except subprocess.CalledProcessError:\n",
        "        print(\"âš ï¸ CuPy nÃ£o foi instalado corretamente\")\n",
        "        print(\"âš ï¸ Tentando novamente com CuPy genÃ©rico...\")\n",
        "        subprocess.run([sys.executable, '-m', 'pip', 'install', '--no-cache-dir', 'cupy'])\n",
        "\n",
        "def setup_symbolic_links():\n",
        "    \"\"\"Configura links simbÃ³licos para bibliotecas CUDA se necessÃ¡rio\"\"\"\n",
        "    print(\"\\nðŸ”„ Configurando links simbÃ³licos para bibliotecas CUDA...\")\n",
        "\n",
        "    try:\n",
        "        # Encontrar arquivos libnvrtc*.so no sistema\n",
        "        nvrtc_libs = []\n",
        "        search_dirs = [\n",
        "            '/usr/local/cuda/lib64/',\n",
        "            '/usr/lib/x86_64-linux-gnu/',\n",
        "            '/usr/lib/',\n",
        "            '/usr/local/lib/'\n",
        "        ]\n",
        "\n",
        "        for directory in search_dirs:\n",
        "            if os.path.exists(directory):\n",
        "                nvrtc_libs.extend(glob.glob(f\"{directory}libnvrtc*.so*\"))\n",
        "\n",
        "        if nvrtc_libs:\n",
        "            print(f\"ðŸ“‹ Bibliotecas NVRTC encontradas: {len(nvrtc_libs)}\")\n",
        "            for lib in nvrtc_libs[:5]:  # Mostra atÃ© 5 para nÃ£o sobrecarregar a saÃ­da\n",
        "                print(f\"   - {lib}\")\n",
        "\n",
        "            # Cria link simbÃ³lico para libnvrtc.so.11.2 se necessÃ¡rio\n",
        "            if not any('libnvrtc.so.11.2' in lib for lib in nvrtc_libs):\n",
        "                # Encontra a biblioteca mais recente para usar como alvo\n",
        "                target_lib = None\n",
        "                for lib in nvrtc_libs:\n",
        "                    if os.path.islink(lib) and not os.path.exists(lib):\n",
        "                        continue  # Pula links quebrados\n",
        "                    target_lib = lib\n",
        "                    break\n",
        "\n",
        "                if target_lib:\n",
        "                    # Criar diretÃ³rio de links\n",
        "                    os.makedirs('/tmp/cuda_links/', exist_ok=True)\n",
        "                    link_path = '/tmp/cuda_links/libnvrtc.so.11.2'\n",
        "\n",
        "                    # Remover link existente se necessÃ¡rio\n",
        "                    if os.path.exists(link_path):\n",
        "                        os.remove(link_path)\n",
        "\n",
        "                    # Criar link simbÃ³lico\n",
        "                    os.symlink(target_lib, link_path)\n",
        "                    print(f\"âœ… Link simbÃ³lico criado: {link_path} -> {target_lib}\")\n",
        "\n",
        "                    # Adicionar ao LD_LIBRARY_PATH\n",
        "                    os.environ['LD_LIBRARY_PATH'] = f\"/tmp/cuda_links:{os.environ.get('LD_LIBRARY_PATH', '')}\"\n",
        "                    print(f\"âœ… LD_LIBRARY_PATH atualizado: {os.environ['LD_LIBRARY_PATH']}\")\n",
        "                else:\n",
        "                    print(\"âš ï¸ NÃ£o foi possÃ­vel encontrar uma biblioteca NVRTC vÃ¡lida para criar link\")\n",
        "            else:\n",
        "                print(\"âœ… libnvrtc.so.11.2 jÃ¡ existe, nÃ£o Ã© necessÃ¡rio criar link\")\n",
        "        else:\n",
        "            print(\"âš ï¸ Nenhuma biblioteca NVRTC encontrada no sistema\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"âš ï¸ Erro ao configurar links simbÃ³licos: {e}\")\n",
        "\n",
        "def install_other_dependencies():\n",
        "    \"\"\"Instala outras dependÃªncias necessÃ¡rias\"\"\"\n",
        "    print(\"\\nðŸ”„ Instalando outras dependÃªncias...\")\n",
        "\n",
        "    dependencies = [\n",
        "        \"coincurve\",\n",
        "        \"eth-utils\",\n",
        "        \"base58\",\n",
        "        \"torch\"\n",
        "    ]\n",
        "\n",
        "    for dep in dependencies:\n",
        "        print(f\"ðŸ”„ Instalando {dep}...\")\n",
        "        subprocess.run([sys.executable, '-m', 'pip', 'install', dep])\n",
        "\n",
        "def check_installation():\n",
        "    \"\"\"Verifica se a instalaÃ§Ã£o foi bem-sucedida\"\"\"\n",
        "    print(\"\\nðŸ” Verificando instalaÃ§Ã£o...\")\n",
        "\n",
        "    try:\n",
        "        print(\"ðŸ”„ Importando CuPy...\")\n",
        "        import cupy as cp\n",
        "\n",
        "        # ObtÃ©m a versÃ£o de uma maneira mais segura\n",
        "        try:\n",
        "            # Tenta diferentes maneiras de obter a versÃ£o\n",
        "            version = None\n",
        "            if hasattr(cp, '__version__'):\n",
        "                version = cp.__version__\n",
        "            elif hasattr(cp, 'version'):\n",
        "                version = cp.version\n",
        "            elif hasattr(cp, 'core') and hasattr(cp.core, 'CUPY_VERSION'):\n",
        "                version = cp.core.CUPY_VERSION\n",
        "\n",
        "            if version:\n",
        "                print(f\"âœ… CuPy versÃ£o {version} importado com sucesso\")\n",
        "            else:\n",
        "                print(\"âœ… CuPy importado com sucesso (versÃ£o nÃ£o disponÃ­vel)\")\n",
        "        except:\n",
        "            print(\"âœ… CuPy importado com sucesso (nÃ£o foi possÃ­vel determinar a versÃ£o)\")\n",
        "\n",
        "        if cp.cuda.is_available():\n",
        "            print(\"âœ… CUDA disponÃ­vel via CuPy!\")\n",
        "            try:\n",
        "                device_props = cp.cuda.runtime.getDeviceProperties(0)\n",
        "                print(f\"   Dispositivo: {device_props['name'].decode()}\")\n",
        "            except:\n",
        "                print(f\"   (NÃ£o foi possÃ­vel obter o nome do dispositivo)\")\n",
        "\n",
        "            try:\n",
        "                mem = cp.cuda.runtime.memGetInfo()\n",
        "                print(f\"   MemÃ³ria livre: {mem[0]/1024**3:.2f} GB / {mem[1]/1024**3:.2f} GB\")\n",
        "            except:\n",
        "                print(\"   (NÃ£o foi possÃ­vel obter informaÃ§Ãµes de memÃ³ria)\")\n",
        "\n",
        "            # Teste rÃ¡pido\n",
        "            print(\"\\nðŸ”„ Executando teste rÃ¡pido de GPU...\")\n",
        "            try:\n",
        "                x = cp.arange(10)\n",
        "                y = cp.arange(10)\n",
        "                z = x + y\n",
        "                print(f\"âœ… Teste concluÃ­do: {z.get()}\")\n",
        "                return True\n",
        "            except Exception as e:\n",
        "                print(f\"âš ï¸ Erro ao executar teste simples: {e}\")\n",
        "                print(\"   Isto pode indicar problemas com o runtime CUDA\")\n",
        "                return False\n",
        "        else:\n",
        "            print(\"âŒ CUDA nÃ£o estÃ¡ disponÃ­vel via CuPy\")\n",
        "            try:\n",
        "                print(\"\\nVerificando problema:\")\n",
        "                print(f\"   CUDA disponibilidade reportada: {cp.cuda.is_available()}\")\n",
        "                print(f\"   NÃºmero de dispositivos: {cp.cuda.runtime.getDeviceCount()}\")\n",
        "            except Exception as e:\n",
        "                print(f\"   Erro ao verificar dispositivos: {e}\")\n",
        "            return False\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Erro ao verificar instalaÃ§Ã£o: {e}\")\n",
        "        print(\"\\nInformaÃ§Ãµes de depuraÃ§Ã£o:\")\n",
        "        try:\n",
        "            import sys\n",
        "            print(f\"Python: {sys.version}\")\n",
        "            print(f\"LocalizaÃ§Ã£o do pacote CuPy:\")\n",
        "\n",
        "            # Tenta localizar o pacote CuPy mesmo com erro\n",
        "            try:\n",
        "                import importlib.util\n",
        "                cupy_spec = importlib.util.find_spec(\"cupy\")\n",
        "                if cupy_spec:\n",
        "                    print(f\"   Encontrado em: {cupy_spec.origin}\")\n",
        "                else:\n",
        "                    print(\"   Pacote nÃ£o encontrado no sistema\")\n",
        "            except:\n",
        "                print(\"   NÃ£o foi possÃ­vel localizar o pacote\")\n",
        "\n",
        "            # Verifica ambiente CUDA\n",
        "            print(\"\\nAmbiente CUDA:\")\n",
        "            import os\n",
        "            for var in ['CUDA_HOME', 'CUDA_PATH', 'LD_LIBRARY_PATH']:\n",
        "                print(f\"   {var}: {os.environ.get(var, 'nÃ£o definido')}\")\n",
        "\n",
        "            # Tenta mostrar bibliotecas disponÃ­veis\n",
        "            try:\n",
        "                import subprocess\n",
        "                result = subprocess.run('ldconfig -p | grep cuda', shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
        "                if result.returncode == 0 and result.stdout:\n",
        "                    print(\"\\nBibliotecas CUDA no sistema:\")\n",
        "                    for line in result.stdout.splitlines()[:10]:  # Mostra atÃ© 10 linhas\n",
        "                        print(f\"   {line}\")\n",
        "                    if len(result.stdout.splitlines()) > 10:\n",
        "                        print(f\"   ... mais {len(result.stdout.splitlines()) - 10} bibliotecas\")\n",
        "            except:\n",
        "                pass\n",
        "        except:\n",
        "            print(\"   NÃ£o foi possÃ­vel coletar informaÃ§Ãµes de depuraÃ§Ã£o adicionais\")\n",
        "\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        return False\n",
        "\n",
        "def main():\n",
        "    print(\"=\" * 60)\n",
        "    print(\"ðŸ”§ CONFIGURAÃ‡ÃƒO CUDA PARA BITCOINFLIX MINER ðŸ”§\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # Verificar se estamos no Google Colab\n",
        "    in_colab = 'google.colab' in sys.modules\n",
        "    if in_colab:\n",
        "        print(\"âœ… Ambiente Google Colab detectado\")\n",
        "\n",
        "        # Verificar se runtime Colab estÃ¡ com GPU\n",
        "        try:\n",
        "            import torch\n",
        "            if not torch.cuda.is_available():\n",
        "                print(\"\\nâŒ IMPORTANTE: GPU NÃƒO DETECTADA NO COLAB!\")\n",
        "                print(\"   Certifique-se de que selecionou GPU em: Runtime > Change runtime type\")\n",
        "                proceed = input(\"Continuar mesmo sem GPU? (s/n): \")\n",
        "                if proceed.lower() != 's':\n",
        "                    print(\"Abortando instalaÃ§Ã£o.\")\n",
        "                    return\n",
        "            else:\n",
        "                print(f\"âœ… GPU detectada: {torch.cuda.get_device_name(0)}\")\n",
        "        except:\n",
        "            print(\"\\nâš ï¸ NÃ£o foi possÃ­vel verificar GPU via PyTorch\")\n",
        "    else:\n",
        "        print(\"âš ï¸ Este script Ã© otimizado para Google Colab\")\n",
        "\n",
        "    # Instalar versÃ£o correta do CuPy\n",
        "    install_correct_cupy()\n",
        "\n",
        "    # Configurar links simbÃ³licos\n",
        "    setup_symbolic_links()\n",
        "\n",
        "    # Instalar outras dependÃªncias\n",
        "    install_other_dependencies()\n",
        "\n",
        "    # Verificar instalaÃ§Ã£o\n",
        "    success = check_installation()\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    if success:\n",
        "        print(\"âœ… CONFIGURAÃ‡ÃƒO CONCLUÃDA COM SUCESSO!\")\n",
        "        print(\"ðŸš€ Agora vocÃª pode executar colab_cuda_alt.py\")\n",
        "    else:\n",
        "        print(\"âš ï¸ CONFIGURAÃ‡ÃƒO COM PROBLEMAS\")\n",
        "        print(\"â“ Tente uma das seguintes opÃ§Ãµes:\")\n",
        "        print(\"   1. Reinicie o runtime (Runtime > Restart runtime) e execute este script novamente\")\n",
        "        print(\"   2. Verifique se vocÃª selecionou GPU em Runtime > Change runtime type\")\n",
        "        print(\"   3. Tente executar colab_cuda_alt.py mesmo assim - a verificaÃ§Ã£o pode falhar mas o script pode funcionar\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "roQJKr_auJvf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Script para resolver problemas de compatibilidade do CuPy com CUDA\n",
        "Resolve os seguintes problemas:\n",
        "1. MÃºltiplos pacotes CuPy instalados (cupy-cuda11x e cupy-cuda12x)\n",
        "2. Link simbÃ³lico faltando para libnvrtc.so.11.2\n",
        "\"\"\"\n",
        "import os\n",
        "import sys\n",
        "import subprocess\n",
        "import glob\n",
        "import re\n",
        "import time\n",
        "\n",
        "def check_environment():\n",
        "    \"\"\"Verifica o ambiente e mostra informaÃ§Ãµes relevantes\"\"\"\n",
        "    print(\"=\" * 60)\n",
        "    print(\"ðŸ” VERIFICANDO AMBIENTE CUDA/CuPy\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # Verificar se estamos no Google Colab\n",
        "    is_colab = 'google.colab' in sys.modules\n",
        "    if is_colab:\n",
        "        print(\"âœ… Ambiente Google Colab detectado\")\n",
        "    else:\n",
        "        print(\"â„¹ï¸ Executando fora do Google Colab\")\n",
        "\n",
        "    # Verificar versÃ£o do CUDA via nvidia-smi\n",
        "    try:\n",
        "        print(\"\\nðŸ“‹ Verificando versÃ£o CUDA...\")\n",
        "        result = subprocess.run([\"nvidia-smi\"], capture_output=True, text=True)\n",
        "        cuda_match = re.search(r'CUDA Version: (\\d+\\.\\d+)', result.stdout)\n",
        "        if cuda_match:\n",
        "            cuda_version = cuda_match.group(1)\n",
        "            print(f\"âœ… CUDA versÃ£o {cuda_version} detectada\")\n",
        "            major_version = cuda_version.split('.')[0]\n",
        "            print(f\"   VersÃ£o principal: {major_version}\")\n",
        "        else:\n",
        "            print(\"âš ï¸ NÃ£o foi possÃ­vel determinar a versÃ£o do CUDA via nvidia-smi\")\n",
        "            cuda_version = None\n",
        "    except Exception as e:\n",
        "        print(f\"âš ï¸ Erro ao executar nvidia-smi: {e}\")\n",
        "        cuda_version = None\n",
        "\n",
        "    # Verificar pacotes CuPy instalados\n",
        "    try:\n",
        "        print(\"\\nðŸ“‹ Verificando instalaÃ§Ãµes do CuPy...\")\n",
        "        result = subprocess.run([sys.executable, \"-m\", \"pip\", \"list\"], capture_output=True, text=True)\n",
        "        cupy_packages = re.findall(r'(cupy[^\\s]+)\\s+([^\\s]+)', result.stdout)\n",
        "\n",
        "        if cupy_packages:\n",
        "            print(f\"ðŸ“¦ Pacotes CuPy instalados:\")\n",
        "            for pkg, version in cupy_packages:\n",
        "                print(f\"   - {pkg} {version}\")\n",
        "        else:\n",
        "            print(\"âš ï¸ CuPy nÃ£o estÃ¡ instalado\")\n",
        "    except Exception as e:\n",
        "        print(f\"âš ï¸ Erro ao verificar pacotes instalados: {e}\")\n",
        "\n",
        "    # Verificar bibliotecas CUDA disponÃ­veis\n",
        "    try:\n",
        "        print(\"\\nðŸ“‹ Verificando bibliotecas CUDA...\")\n",
        "        library_dirs = [\n",
        "            \"/usr/local/cuda/lib64\",\n",
        "            \"/usr/lib/x86_64-linux-gnu\",\n",
        "            \"/usr/lib\",\n",
        "            \"/lib\"\n",
        "        ]\n",
        "\n",
        "        nvrtc_libs = []\n",
        "        cuda_libs = []\n",
        "\n",
        "        for directory in library_dirs:\n",
        "            if os.path.exists(directory):\n",
        "                nvrtc_candidates = glob.glob(f\"{directory}/libnvrtc*\")\n",
        "                nvrtc_libs.extend(nvrtc_candidates)\n",
        "\n",
        "                # Busca por outras libs CUDA importantes\n",
        "                cuda_candidates = glob.glob(f\"{directory}/libcuda*\") + glob.glob(f\"{directory}/libcudart*\")\n",
        "                cuda_libs.extend(cuda_candidates)\n",
        "\n",
        "        if nvrtc_libs:\n",
        "            print(f\"ðŸ“š Bibliotecas NVRTC encontradas ({len(nvrtc_libs)}):\")\n",
        "            for lib in nvrtc_libs[:5]:  # Mostrar apenas as primeiras 5\n",
        "                print(f\"   - {os.path.basename(lib)}\")\n",
        "            if len(nvrtc_libs) > 5:\n",
        "                print(f\"   - ... e mais {len(nvrtc_libs) - 5} bibliotecas\")\n",
        "        else:\n",
        "            print(\"âš ï¸ Nenhuma biblioteca libnvrtc*.so encontrada\")\n",
        "\n",
        "        if cuda_libs:\n",
        "            print(f\"ðŸ“š Outras bibliotecas CUDA importantes ({len(cuda_libs)}):\")\n",
        "            for lib in cuda_libs[:5]:  # Mostrar apenas as primeiras 5\n",
        "                print(f\"   - {os.path.basename(lib)}\")\n",
        "            if len(cuda_libs) > 5:\n",
        "                print(f\"   - ... e mais {len(cuda_libs) - 5} bibliotecas\")\n",
        "\n",
        "        # Verificar a biblioteca especÃ­fica que estÃ¡ causando o problema\n",
        "        target_lib = \"libnvrtc.so.11.2\"\n",
        "        target_found = False\n",
        "        for path in nvrtc_libs:\n",
        "            if target_lib in path:\n",
        "                print(f\"âœ… {target_lib} encontrada: {path}\")\n",
        "                target_found = True\n",
        "                break\n",
        "\n",
        "        if not target_found:\n",
        "            print(f\"âŒ {target_lib} nÃ£o encontrada! Precisamos configurar um link simbÃ³lico.\")\n",
        "    except Exception as e:\n",
        "        print(f\"âš ï¸ Erro ao verificar bibliotecas: {e}\")\n",
        "\n",
        "    return cuda_version\n",
        "\n",
        "def clean_cupy_installation():\n",
        "    \"\"\"Remove todas as instalaÃ§Ãµes existentes do CuPy\"\"\"\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"ðŸ§¹ LIMPANDO INSTALAÃ‡Ã•ES CuPy EXISTENTES\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # Lista de pacotes CuPy para remover\n",
        "    cupy_packages = [\"cupy\", \"cupy-cuda11x\", \"cupy-cuda12x\", \"cupy-cuda110\", \"cupy-cuda111\", \"cupy-cuda112\", \"cupy-cuda120\"]\n",
        "\n",
        "    for pkg in cupy_packages:\n",
        "        print(f\"ðŸ—‘ï¸ Removendo {pkg}...\")\n",
        "        subprocess.run([sys.executable, \"-m\", \"pip\", \"uninstall\", \"-y\", pkg], stdout=subprocess.DEVNULL)\n",
        "\n",
        "    # Limpar o cache pip para evitar problemas\n",
        "    print(\"ðŸ—‘ï¸ Limpando cache pip...\")\n",
        "    subprocess.run([sys.executable, \"-m\", \"pip\", \"cache\", \"purge\"], stdout=subprocess.DEVNULL)\n",
        "\n",
        "    print(\"âœ… Todas as instalaÃ§Ãµes do CuPy foram removidas\")\n",
        "\n",
        "def install_correct_cupy(cuda_version):\n",
        "    \"\"\"Instala a versÃ£o correta do CuPy com base na versÃ£o do CUDA\"\"\"\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"ðŸ“¦ INSTALANDO CuPy COMPATÃVEL\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    if cuda_version:\n",
        "        major_version = int(float(cuda_version))\n",
        "    else:\n",
        "        # Tenta uma detecÃ§Ã£o alternativa\n",
        "        print(\"âš ï¸ NÃ£o foi possÃ­vel determinar a versÃ£o CUDA, tentando detectar novamente...\")\n",
        "        try:\n",
        "            # Verificar via nvcc ou buscar outros indicadores\n",
        "            try:\n",
        "                result = subprocess.run([\"nvcc\", \"--version\"], capture_output=True, text=True)\n",
        "                m = re.search(r'release (\\d+\\.\\d+)', result.stdout)\n",
        "                if m:\n",
        "                    major_version = int(float(m.group(1)))\n",
        "                    print(f\"âœ… CUDA {major_version} detectado via nvcc\")\n",
        "                else:\n",
        "                    # Verificar presenÃ§a de bibliotecas especÃ­ficas\n",
        "                    if os.path.exists(\"/usr/local/cuda-12\"):\n",
        "                        major_version = 12\n",
        "                        print(\"âœ… CUDA 12 detectado via diretÃ³rios\")\n",
        "                    elif os.path.exists(\"/usr/local/cuda-11\"):\n",
        "                        major_version = 11\n",
        "                        print(\"âœ… CUDA 11 detectado via diretÃ³rios\")\n",
        "                    else:\n",
        "                        # Assumir versÃ£o mais recente\n",
        "                        major_version = 12\n",
        "                        print(\"âš ï¸ VersÃ£o CUDA nÃ£o detectada, assumindo CUDA 12\")\n",
        "            except:\n",
        "                # Assumir versÃ£o mais recente como fallback\n",
        "                major_version = 12\n",
        "                print(\"âš ï¸ VersÃ£o CUDA nÃ£o detectada, assumindo CUDA 12\")\n",
        "        except:\n",
        "            major_version = 12\n",
        "            print(\"âš ï¸ VersÃ£o CUDA nÃ£o detectada, assumindo CUDA 12\")\n",
        "\n",
        "    # Instalar a versÃ£o correta do CuPy\n",
        "    if major_version >= 12:\n",
        "        cupy_package = \"cupy-cuda12x\"\n",
        "    elif major_version == 11:\n",
        "        cupy_package = \"cupy-cuda11x\"\n",
        "    else:\n",
        "        print(f\"âš ï¸ CUDA {major_version} pode nÃ£o ser compatÃ­vel com o CuPy atual!\")\n",
        "        print(\"   Tentando instalar a versÃ£o para CUDA 11.x como fallback\")\n",
        "        cupy_package = \"cupy-cuda11x\"\n",
        "\n",
        "    print(f\"ðŸ“¦ Instalando {cupy_package}...\")\n",
        "    start_time = time.time()\n",
        "    try:\n",
        "        result = subprocess.run(\n",
        "            [sys.executable, \"-m\", \"pip\", \"install\", \"--no-cache-dir\", \"-v\", cupy_package],\n",
        "            capture_output=True,\n",
        "            text=True\n",
        "        )\n",
        "\n",
        "        # Verificar erros especÃ­ficos conhecidos\n",
        "        if \"ERROR: No matching distribution found for cupy\" in result.stderr:\n",
        "            print(f\"âŒ Erro: Pacote {cupy_package} nÃ£o encontrado!\")\n",
        "            print(\"   Tentando com instalaÃ§Ã£o genÃ©rica do cupy...\")\n",
        "            subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"--no-cache-dir\", \"cupy\"])\n",
        "        elif result.returncode != 0:\n",
        "            print(f\"âš ï¸ Aviso: PossÃ­veis problemas na instalaÃ§Ã£o: {result.stderr}\")\n",
        "        else:\n",
        "            print(f\"âœ… {cupy_package} instalado com sucesso!\")\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Erro na instalaÃ§Ã£o: {e}\")\n",
        "        print(\"   Tentando alternativa...\")\n",
        "        try:\n",
        "            subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"--no-cache-dir\", \"cupy\"])\n",
        "        except:\n",
        "            print(\"âŒ Todas as tentativas de instalaÃ§Ã£o falharam\")\n",
        "\n",
        "    elapsed = time.time() - start_time\n",
        "    print(f\"â±ï¸ InstalaÃ§Ã£o concluÃ­da em {elapsed:.1f} segundos\")\n",
        "\n",
        "def setup_symbolic_links():\n",
        "    \"\"\"Configura links simbÃ³licos necessÃ¡rios para as bibliotecas CUDA\"\"\"\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"ðŸ”— CONFIGURANDO LINKS SIMBÃ“LICOS\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # Criar diretÃ³rio para links simbÃ³licos\n",
        "    link_dir = \"/tmp/cuda_links\"\n",
        "    os.makedirs(link_dir, exist_ok=True)\n",
        "    print(f\"ðŸ“ DiretÃ³rio para links simbÃ³licos: {link_dir}\")\n",
        "\n",
        "    # Adicionar ao LD_LIBRARY_PATH\n",
        "    os.environ[\"LD_LIBRARY_PATH\"] = f\"{link_dir}:{os.environ.get('LD_LIBRARY_PATH', '')}\"\n",
        "    print(f\"âœ… LD_LIBRARY_PATH atualizado: {os.environ['LD_LIBRARY_PATH']}\")\n",
        "\n",
        "    # Encontrar bibliotecas NVRTC disponÃ­veis\n",
        "    library_dirs = [\n",
        "        \"/usr/local/cuda/lib64\",\n",
        "        \"/usr/lib/x86_64-linux-gnu\",\n",
        "        \"/usr/lib\",\n",
        "        \"/lib\"\n",
        "    ]\n",
        "\n",
        "    nvrtc_libs = []\n",
        "    for directory in library_dirs:\n",
        "        if os.path.exists(directory):\n",
        "            nvrtc_candidates = glob.glob(f\"{directory}/libnvrtc*\")\n",
        "            nvrtc_libs.extend(nvrtc_candidates)\n",
        "\n",
        "    # Definir os links necessÃ¡rios e suas origens\n",
        "    needed_links = {\n",
        "        \"libnvrtc.so.11.2\": None  # Vai ser preenchido com a biblioteca encontrada\n",
        "    }\n",
        "\n",
        "    # Encontrar o melhor candidato para cada link\n",
        "    for lib in nvrtc_libs:\n",
        "        lib_name = os.path.basename(lib)\n",
        "\n",
        "        # Para libnvrtc.so.11.2, queremos a versÃ£o mais prÃ³xima\n",
        "        if \"libnvrtc.so\" in lib_name:\n",
        "            # JÃ¡ encontrou o arquivo exato?\n",
        "            if lib_name == \"libnvrtc.so.11.2\":\n",
        "                needed_links[\"libnvrtc.so.11.2\"] = lib\n",
        "                break\n",
        "\n",
        "            # Se nÃ£o temos um candidato ou este Ã© um candidato melhor\n",
        "            if needed_links[\"libnvrtc.so.11.2\"] is None:\n",
        "                needed_links[\"libnvrtc.so.11.2\"] = lib\n",
        "\n",
        "    # Criar links simbÃ³licos\n",
        "    for link_name, source_lib in needed_links.items():\n",
        "        if source_lib:\n",
        "            link_path = f\"{link_dir}/{link_name}\"\n",
        "\n",
        "            # Remover link antigo se existir\n",
        "            if os.path.exists(link_path):\n",
        "                os.remove(link_path)\n",
        "\n",
        "            os.symlink(source_lib, link_path)\n",
        "            print(f\"ðŸ”— Link criado: {link_path} -> {source_lib}\")\n",
        "        else:\n",
        "            print(f\"âŒ NÃ£o foi possÃ­vel encontrar biblioteca para {link_name}!\")\n",
        "            print(\"   Isso pode causar falha ao usar CuPy!\")\n",
        "\n",
        "def verify_installation():\n",
        "    \"\"\"Verifica se a instalaÃ§Ã£o do CuPy estÃ¡ funcionando corretamente\"\"\"\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"ðŸ” VERIFICANDO INSTALAÃ‡ÃƒO\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    try:\n",
        "        print(\"ðŸ”„ Tentando importar CuPy...\")\n",
        "        import cupy as cp\n",
        "\n",
        "        print(\"âœ… CuPy importado com sucesso!\")\n",
        "\n",
        "        # Mostrar versÃ£o\n",
        "        if hasattr(cp, \"__version__\"):\n",
        "            print(f\"ðŸ“‹ VersÃ£o: {cp.__version__}\")\n",
        "        else:\n",
        "            print(\"âš ï¸ NÃ£o foi possÃ­vel determinar a versÃ£o do CuPy\")\n",
        "\n",
        "        # Verificar CUDA disponÃ­vel\n",
        "        if cp.cuda.is_available():\n",
        "            print(\"âœ… CUDA disponÃ­vel!\")\n",
        "\n",
        "            # Mostrar informaÃ§Ãµes do dispositivo\n",
        "            try:\n",
        "                device = cp.cuda.Device(0)\n",
        "                props = cp.cuda.runtime.getDeviceProperties(0)\n",
        "                print(f\"ðŸ“Š Dispositivo: {props['name'].decode()}\")\n",
        "                print(f\"   MemÃ³ria total: {props['totalGlobalMem'] / (1024**3):.2f} GB\")\n",
        "                print(f\"   Compute capability: {props['major']}.{props['minor']}\")\n",
        "            except Exception as e:\n",
        "                print(f\"âš ï¸ Erro ao obter informaÃ§Ãµes do dispositivo: {e}\")\n",
        "\n",
        "            # Testar operaÃ§Ãµes bÃ¡sicas\n",
        "            print(\"\\nðŸ§ª Executando teste simples...\")\n",
        "            try:\n",
        "                x = cp.array([1, 2, 3])\n",
        "                y = cp.array([4, 5, 6])\n",
        "                z = x + y\n",
        "                print(f\"   Resultado: {z}\")\n",
        "                print(\"âœ… Teste bem-sucedido!\")\n",
        "                return True\n",
        "            except Exception as e:\n",
        "                print(f\"âŒ Teste falhou: {e}\")\n",
        "                return False\n",
        "        else:\n",
        "            print(\"âŒ CUDA nÃ£o estÃ¡ disponÃ­vel!\")\n",
        "            return False\n",
        "    except ImportError:\n",
        "        print(\"âŒ NÃ£o foi possÃ­vel importar CuPy!\")\n",
        "        return False\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Erro ao verificar instalaÃ§Ã£o: {e}\")\n",
        "        return False\n",
        "\n",
        "def main():\n",
        "    print(\"=\" * 60)\n",
        "    print(\"ðŸ› ï¸ CORREÃ‡ÃƒO DE PROBLEMAS CUDA/CuPy\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # 1. Verificar ambiente\n",
        "    cuda_version = check_environment()\n",
        "\n",
        "    # 2. Limpar instalaÃ§Ãµes do CuPy\n",
        "    clean_cupy_installation()\n",
        "\n",
        "    # 3. Instalar versÃ£o correta do CuPy\n",
        "    install_correct_cupy(cuda_version)\n",
        "\n",
        "    # 4. Configurar links simbÃ³licos\n",
        "    setup_symbolic_links()\n",
        "\n",
        "    # 5. Verificar instalaÃ§Ã£o\n",
        "    success = verify_installation()\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    if success:\n",
        "        print(\"âœ… CONFIGURAÃ‡ÃƒO CONCLUÃDA COM SUCESSO!\")\n",
        "        print(\"\\nðŸš€ Agora vocÃª pode executar batch_size_tester.py novamente.\")\n",
        "        print(\"   Recomendamos reiniciar o runtime antes de executar.\")\n",
        "    else:\n",
        "        print(\"âš ï¸ CONFIGURAÃ‡ÃƒO CONCLUÃDA COM POSSÃVEIS PROBLEMAS\")\n",
        "        print(\"\\nðŸ”„ Por favor, siga estes passos:\")\n",
        "        print(\"   1. Reinicie o runtime (Runtime > Restart runtime)\")\n",
        "        print(\"   2. Execute novamente este script para verificar\")\n",
        "        print(\"   3. Tente executar batch_size_tester.py\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "EBjkoAsrC_5s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Este script testa vÃ¡rios tamanhos de batch para encontrar a configuraÃ§Ã£o ideal\n",
        "para o seu hardware especÃ­fico de GPU.\n",
        "\"\"\"\n",
        "import time\n",
        "import numpy as np\n",
        "import sys\n",
        "import subprocess\n",
        "import os\n",
        "\n",
        "# Verificar se estamos no ambiente do Colab ou Jupyter\n",
        "IS_COLAB = 'google.colab' in sys.modules\n",
        "IS_NOTEBOOK = 'ipykernel' in sys.modules\n",
        "\n",
        "# FunÃ§Ã£o para verificar e consertar o ambiente CUDA/CuPy\n",
        "def check_and_fix_cupy():\n",
        "    \"\"\"Verifica se o ambiente CuPy estÃ¡ configurado corretamente e tenta corrigir se necessÃ¡rio.\"\"\"\n",
        "    # Verificar se temos mÃºltiplos pacotes CuPy instalados\n",
        "    try:\n",
        "        result = subprocess.run([sys.executable, \"-m\", \"pip\", \"list\"], capture_output=True, text=True)\n",
        "        cupy_packages = [line for line in result.stdout.split('\\n') if 'cupy' in line.lower()]\n",
        "\n",
        "        if len(cupy_packages) > 1:\n",
        "            print(\"âš ï¸ Detectados mÃºltiplos pacotes CuPy instalados. Isso pode causar conflitos.\")\n",
        "            print(\"   Deseja executar o script de correÃ§Ã£o CUDA/CuPy? (Recomendado)\")\n",
        "            choice = input(\"   Executar cuda_setup_fix.py? (s/n): \").strip().lower()\n",
        "\n",
        "            if choice == 's':\n",
        "                # Verifica se o script de correÃ§Ã£o existe\n",
        "                if os.path.exists(\"cuda_setup_fix.py\"):\n",
        "                    print(\"ðŸ”„ Executando script de correÃ§Ã£o...\")\n",
        "                    subprocess.run([sys.executable, \"cuda_setup_fix.py\"])\n",
        "                    print(\"\\nâš ï¸ Por favor, reinicie o runtime e execute batch_size_tester.py novamente.\")\n",
        "                    sys.exit(0)\n",
        "                else:\n",
        "                    print(\"âŒ Script cuda_setup_fix.py nÃ£o encontrado.\")\n",
        "                    print(\"   Tente reinstalar o CuPy manualmente:\")\n",
        "                    print(\"   !pip uninstall -y cupy cupy-cuda11x cupy-cuda12x\")\n",
        "                    print(\"   !pip install cupy-cuda12x  # Ou a versÃ£o apropriada\")\n",
        "                    return False\n",
        "\n",
        "        # Verificar se libnvrtc.so.11.2 estÃ¡ disponÃ­vel\n",
        "        # Podemos tentar configurar os links simbÃ³licos tambÃ©m\n",
        "        try:\n",
        "            # Testar se o CuPy consegue fazer operaÃ§Ãµes bÃ¡sicas\n",
        "            import cupy as cp\n",
        "            test_array = cp.array([1, 2, 3])\n",
        "            test_result = test_array + test_array\n",
        "            return True\n",
        "        except ImportError:\n",
        "            print(\"âŒ CuPy nÃ£o estÃ¡ instalado.\")\n",
        "            print(\"   Tente instalar com: !pip install cupy-cuda12x\")\n",
        "            return False\n",
        "        except Exception as e:\n",
        "            if \"libnvrtc.so.11.2\" in str(e):\n",
        "                print(\"âš ï¸ Erro de biblioteca libnvrtc.so.11.2 detectado.\")\n",
        "                print(\"   Executando configuraÃ§Ã£o de links simbÃ³licos...\")\n",
        "\n",
        "                try:\n",
        "                    # Criar diretÃ³rio para links e configurar\n",
        "                    os.makedirs('/tmp/cuda_links', exist_ok=True)\n",
        "\n",
        "                    # Procurar por libnvrtc em locais comuns\n",
        "                    nvrtc_paths = []\n",
        "                    for path in [\"/usr/local/cuda/lib64\", \"/usr/lib/x86_64-linux-gnu\"]:\n",
        "                        if os.path.exists(path):\n",
        "                            nvrtc_paths.extend(subprocess.run(f\"find {path} -name 'libnvrtc.so*'\",\n",
        "                                                           shell=True,\n",
        "                                                           capture_output=True,\n",
        "                                                           text=True).stdout.splitlines())\n",
        "\n",
        "                    if nvrtc_paths:\n",
        "                        # Criar link usando a primeira biblioteca encontrada\n",
        "                        target_path = nvrtc_paths[0]\n",
        "                        link_path = \"/tmp/cuda_links/libnvrtc.so.11.2\"\n",
        "\n",
        "                        # Remover link antigo, se existir\n",
        "                        if os.path.exists(link_path):\n",
        "                            os.remove(link_path)\n",
        "\n",
        "                        # Criar novo link\n",
        "                        os.symlink(target_path, link_path)\n",
        "\n",
        "                        # Atualizar LD_LIBRARY_PATH\n",
        "                        os.environ[\"LD_LIBRARY_PATH\"] = f\"/tmp/cuda_links:{os.environ.get('LD_LIBRARY_PATH', '')}\"\n",
        "                        print(f\"âœ… Link simbÃ³lico criado: {link_path} -> {target_path}\")\n",
        "                        print(f\"âœ… LD_LIBRARY_PATH atualizado\")\n",
        "\n",
        "                        print(\"\\nâš ï¸ Por favor, reinicie o runtime e execute batch_size_tester.py novamente.\")\n",
        "                        sys.exit(0)\n",
        "                    else:\n",
        "                        print(\"âŒ NÃ£o foi possÃ­vel encontrar bibliotecas libnvrtc.so\")\n",
        "                        print(\"   Execute o script cuda_setup_fix.py ou reinstale o CuPy manualmente.\")\n",
        "                        return False\n",
        "                except Exception as link_error:\n",
        "                    print(f\"âŒ Erro ao configurar links simbÃ³licos: {link_error}\")\n",
        "                    return False\n",
        "            else:\n",
        "                print(f\"âŒ Erro ao inicializar CuPy: {e}\")\n",
        "                return False\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Erro ao verificar ambiente CuPy: {e}\")\n",
        "        return False\n",
        "\n",
        "# Verificar ambiente CuPy e corrigir se necessÃ¡rio\n",
        "check_and_fix_cupy()\n",
        "\n",
        "# Tentar importar bibliotecas necessÃ¡rias\n",
        "try:\n",
        "    import cupy as cp\n",
        "    HAS_CUPY = True\n",
        "    print(\"âœ… CuPy disponÃ­vel\")\n",
        "except ImportError:\n",
        "    HAS_CUPY = False\n",
        "    print(\"âŒ CuPy nÃ£o disponÃ­vel\")\n",
        "except Exception as e:\n",
        "    print(f\"âŒ Erro ao inicializar CuPy: {e}\")\n",
        "    print(\"   Execute o script cuda_setup_fix.py para resolver problemas de configuraÃ§Ã£o.\")\n",
        "    print(\"   Depois reinicie o runtime e execute este script novamente.\")\n",
        "    sys.exit(1)\n",
        "\n",
        "try:\n",
        "    from coincurve import PublicKey\n",
        "    from eth_utils import keccak\n",
        "    import base58\n",
        "except ImportError:\n",
        "    print(\"âš ï¸ Bibliotecas necessÃ¡rias nÃ£o encontradas.\")\n",
        "    print(\"   Instalando bibliotecas essenciais...\")\n",
        "    try:\n",
        "        import subprocess\n",
        "        subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"coincurve\", \"eth-utils\", \"base58\"],\n",
        "                       check=True)\n",
        "        from coincurve import PublicKey\n",
        "        from eth_utils import keccak\n",
        "        import base58\n",
        "        print(\"âœ… Bibliotecas instaladas com sucesso\")\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Erro ao instalar bibliotecas: {e}\")\n",
        "        sys.exit(1)\n",
        "\n",
        "# FunÃ§Ãµes para benchmark\n",
        "def custom_keccak(data):\n",
        "    \"\"\"Calcula Keccak-256.\"\"\"\n",
        "    try:\n",
        "        if isinstance(data, str):\n",
        "            data = bytes.fromhex(data.replace('0x', ''))\n",
        "        return keccak(data)\n",
        "    except Exception:\n",
        "        return b'\\x00' * 32\n",
        "\n",
        "def generate_random_keys(n):\n",
        "    \"\"\"Gera n chaves aleatÃ³rias.\"\"\"\n",
        "    return [int.from_bytes(np.random.bytes(32), 'big') % (2**256 - 2**32 - 977) + 1\n",
        "            for _ in range(n)]\n",
        "\n",
        "def generate_addresses_cpu(keys):\n",
        "    \"\"\"Gera endereÃ§os Bitcoin na CPU usando geraÃ§Ã£o em lote.\"\"\"\n",
        "    batch_size = len(keys)\n",
        "    addresses = np.zeros((batch_size, 20), dtype=np.uint8)\n",
        "\n",
        "    for i, key in enumerate(keys):\n",
        "        try:\n",
        "            key_hex = f\"{key:064x}\"\n",
        "            pk_bytes = bytes.fromhex(key_hex)\n",
        "            public_key = PublicKey.from_valid_secret(pk_bytes).format(compressed=False)[1:]\n",
        "            hash_bytes = custom_keccak(public_key)[-20:]\n",
        "            addresses[i] = np.frombuffer(hash_bytes, dtype=np.uint8)\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "    return addresses\n",
        "\n",
        "def test_cpu_to_gpu_transfer(sizes):\n",
        "    \"\"\"Testa a transferÃªncia de dados CPU para GPU para vÃ¡rios tamanhos.\"\"\"\n",
        "    if not HAS_CUPY:\n",
        "        print(\"âŒ CuPy nÃ£o disponÃ­vel para teste de transferÃªncia\")\n",
        "        return\n",
        "\n",
        "    results = []\n",
        "\n",
        "    print(\"ðŸ”„ Testando transferÃªncia CPUâ†’GPU para diferentes tamanhos de lote\")\n",
        "    print(\"=\" * 60)\n",
        "    print(f\"{'Tamanho':>10} | {'Tempo (ms)':>12} | {'Taxa (GB/s)':>12}\")\n",
        "    print(\"-\" * 60)\n",
        "\n",
        "    for size in sizes:\n",
        "        # Gerar dados na CPU\n",
        "        cpu_data = np.random.randint(0, 256, size=(size, 20), dtype=np.uint8)\n",
        "\n",
        "        # Medir tempo de transferÃªncia para GPU\n",
        "        start_time = time.time()\n",
        "        gpu_data = cp.asarray(cpu_data)\n",
        "        cp.cuda.stream.get_current_stream().synchronize()\n",
        "        elapsed = (time.time() - start_time) * 1000  # em ms\n",
        "\n",
        "        # Calcular taxa de transferÃªncia\n",
        "        bytes_transferred = cpu_data.nbytes\n",
        "        transfer_rate = bytes_transferred / (elapsed / 1000) / (1024**3)  # em GB/s\n",
        "\n",
        "        results.append((size, elapsed, transfer_rate))\n",
        "        print(f\"{size:>10} | {elapsed:12.2f} | {transfer_rate:12.2f}\")\n",
        "\n",
        "        # Liberar memÃ³ria\n",
        "        del gpu_data\n",
        "        cp.get_default_memory_pool().free_all_blocks()\n",
        "\n",
        "    return results\n",
        "\n",
        "def test_batch_processing(sizes):\n",
        "    \"\"\"Testa o processamento em lote para diferentes tamanhos.\"\"\"\n",
        "    if not HAS_CUPY:\n",
        "        print(\"âŒ CuPy nÃ£o disponÃ­vel para teste de processamento\")\n",
        "        return\n",
        "\n",
        "    results = []\n",
        "\n",
        "    print(\"\\nðŸ”„ Testando processamento em lote para diferentes tamanhos\")\n",
        "    print(\"=\" * 80)\n",
        "    print(f\"{'Tamanho':>10} | {'GeraÃ§Ã£o CPU (ms)':>16} | {'VerificaÃ§Ã£o GPU (ms)':>18} | {'Total (ms)':>12} | {'Taxa (Mend/s)':>12}\")\n",
        "    print(\"-\" * 80)\n",
        "\n",
        "    # Gerar alguns targets fictÃ­cios\n",
        "    n_targets = 10\n",
        "    targets = np.random.randint(0, 256, size=(n_targets, 20), dtype=np.uint8)\n",
        "    targets_gpu = cp.asarray(targets)\n",
        "\n",
        "    for size in sizes:\n",
        "        # PARTE 1: Gerar chaves e endereÃ§os na CPU\n",
        "        keys = generate_random_keys(size)\n",
        "\n",
        "        start_time = time.time()\n",
        "        addresses = generate_addresses_cpu(keys)\n",
        "        cpu_time = (time.time() - start_time) * 1000  # em ms\n",
        "\n",
        "        # PARTE 2: Verificar correspondÃªncias na GPU\n",
        "        start_time = time.time()\n",
        "\n",
        "        # Transferir para GPU\n",
        "        addresses_gpu = cp.asarray(addresses)\n",
        "\n",
        "        # Verificar correspondÃªncias\n",
        "        match_any = cp.zeros(size, dtype=cp.bool_)\n",
        "\n",
        "        for t in range(n_targets):\n",
        "            target = targets_gpu[t]\n",
        "            matches = cp.all(addresses_gpu == target, axis=1)\n",
        "            match_any = cp.logical_or(match_any, matches)\n",
        "\n",
        "        # Transferir resultados de volta\n",
        "        matches_cpu = match_any.get()\n",
        "\n",
        "        gpu_time = (time.time() - start_time) * 1000  # em ms\n",
        "\n",
        "        # EstatÃ­sticas\n",
        "        total_time = cpu_time + gpu_time\n",
        "        throughput = size / (total_time / 1000) / 1e6  # milhÃµes de endereÃ§os/segundo\n",
        "\n",
        "        results.append((size, cpu_time, gpu_time, total_time, throughput))\n",
        "        print(f\"{size:>10} | {cpu_time:16.2f} | {gpu_time:18.2f} | {total_time:12.2f} | {throughput:12.2f}\")\n",
        "\n",
        "        # Limpar memÃ³ria\n",
        "        del addresses_gpu, match_any\n",
        "        cp.get_default_memory_pool().free_all_blocks()\n",
        "\n",
        "    return results\n",
        "\n",
        "def show_recommendations(transfer_results, processing_results):\n",
        "    \"\"\"Mostra recomendaÃ§Ãµes baseadas nos resultados dos testes.\"\"\"\n",
        "    if not transfer_results or not processing_results:\n",
        "        return\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"ðŸ” ANÃLISE E RECOMENDAÃ‡Ã•ES\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # Encontrar melhor tamanho de lote para transferÃªncia\n",
        "    best_transfer = max(transfer_results, key=lambda x: x[2])\n",
        "    print(f\"âœ… Melhor tamanho para transferÃªncia: {best_transfer[0]}\")\n",
        "    print(f\"   Taxa: {best_transfer[2]:.2f} GB/s\")\n",
        "\n",
        "    # Encontrar melhor tamanho de lote para processamento\n",
        "    best_processing = max(processing_results, key=lambda x: x[4])\n",
        "    print(f\"\\nâœ… Melhor tamanho para processamento: {best_processing[0]}\")\n",
        "    print(f\"   Throughput: {best_processing[4]:.2f} Mend/s\")\n",
        "\n",
        "    # AnÃ¡lise de gargalos\n",
        "    print(\"\\nðŸ“Š AnÃ¡lise de gargalos:\")\n",
        "\n",
        "    # Verificar se CPU Ã© gargalo\n",
        "    cpu_times = [r[1] for r in processing_results]\n",
        "    gpu_times = [r[2] for r in processing_results]\n",
        "\n",
        "    cpu_avg_ratio = sum(cpu_times) / sum(gpu_times) if sum(gpu_times) > 0 else float('inf')\n",
        "\n",
        "    if cpu_avg_ratio > 2.0:\n",
        "        print(\"âš ï¸ A geraÃ§Ã£o de endereÃ§os na CPU Ã© um gargalo significativo\")\n",
        "        print(f\"   CPU leva {cpu_avg_ratio:.1f}x mais tempo que GPU\")\n",
        "        print(\"   RecomendaÃ§Ã£o: Implementar paralelismo na geraÃ§Ã£o de endereÃ§os\")\n",
        "\n",
        "    # Verificar eficiÃªncia de transferÃªncia\n",
        "    sizes = [r[0] for r in transfer_results]\n",
        "    transfer_rates = [r[2] for r in transfer_results]\n",
        "\n",
        "    if max(transfer_rates) / min(transfer_rates) > 3.0:\n",
        "        print(\"\\nâš ï¸ Grande variaÃ§Ã£o na eficiÃªncia de transferÃªncia\")\n",
        "        print(\"   RecomendaÃ§Ã£o: Preferir tamanhos de lote maiores para transfers\")\n",
        "\n",
        "    # RecomendaÃ§Ã£o final baseada nos resultados\n",
        "    print(\"\\nðŸš€ RECOMENDAÃ‡Ã•ES FINAIS:\")\n",
        "\n",
        "    # Escolher tamanho de lote balanceado\n",
        "    recommended_batch = best_processing[0]\n",
        "\n",
        "    # Tamanho para sub-batch baseado no tamanho de memÃ³ria\n",
        "    try:\n",
        "        import cupy as cp\n",
        "        free_mem, total_mem = cp.cuda.runtime.memGetInfo()\n",
        "        available_bytes = free_mem * 0.8  # 80% da memÃ³ria livre\n",
        "\n",
        "        # Tamanho aproximado por registro (endereÃ§o + estruturas auxiliares)\n",
        "        bytes_per_record = 100\n",
        "\n",
        "        max_elements = int(available_bytes / bytes_per_record)\n",
        "\n",
        "        # Arredondar para potÃªncia de 2 mais prÃ³xima\n",
        "        max_power_of_2 = 2**int(np.log2(max_elements))\n",
        "\n",
        "        # Limitar o sub-batch a um mÃ¡ximo razoÃ¡vel\n",
        "        max_subbatch = min(max_power_of_2, 2**26)  # MÃ¡ximo de 64M\n",
        "\n",
        "        recommended_subbatch = max_subbatch\n",
        "    except:\n",
        "        # Valor conservador se falhar\n",
        "        recommended_subbatch = 2**24\n",
        "\n",
        "    print(f\"1. BATCH_SIZE = {recommended_batch}\")\n",
        "    print(f\"2. SUBBATCH_SIZE = {recommended_subbatch} ({recommended_subbatch:,})\")\n",
        "    print(\"3. Implementar paralelizaÃ§Ã£o na geraÃ§Ã£o de endereÃ§os\")\n",
        "\n",
        "    # CÃ³digo para fÃ¡cil cÃ³pia e cola\n",
        "    print(\"\\nCÃ³digo para atualizar no seu script:\")\n",
        "    print(\"-\" * 40)\n",
        "    print(f\"BATCH_SIZE = {recommended_batch} if HAS_CUDA else 8192\")\n",
        "    print(f\"SUBBATCH_SIZE = {recommended_subbatch} if HAS_CUDA else 2**20\")\n",
        "\n",
        "def main():\n",
        "    # VersÃ£o modificada para funcionar tanto no Colab quanto na linha de comando\n",
        "\n",
        "    # Detectar ambiente de execuÃ§Ã£o e definir parÃ¢metros apropriados\n",
        "    test_mode = \"standard\"  # default\n",
        "\n",
        "    if IS_NOTEBOOK or IS_COLAB:\n",
        "        # Se estamos em um notebook/Colab, ignoramos os argumentos da linha de comando\n",
        "        # e oferecemos uma interface baseada em variÃ¡veis\n",
        "        print(\"ðŸ’¡ Executando no ambiente Notebook/Colab - ignorando argumentos de linha de comando\")\n",
        "\n",
        "        # Opcionalmente, podemos permitir ao usuÃ¡rio escolher o modo atravÃ©s de uma variÃ¡vel\n",
        "        try:\n",
        "            # Verifica se estamos no Colab e oferecemos widgets interativos\n",
        "            if IS_COLAB:\n",
        "                from google.colab import output\n",
        "                from IPython.display import display, HTML\n",
        "\n",
        "                print(\"\\nðŸŽ® Selecione o modo de teste:\")\n",
        "                print(\"1. MÃ­nimo (rÃ¡pido, poucos tamanhos)\")\n",
        "                print(\"2. PadrÃ£o (equilÃ­brio entre tempo e precisÃ£o)\")\n",
        "                print(\"3. Completo (mais preciso, leva mais tempo)\")\n",
        "\n",
        "                choice = input(\"Escolha [1-3] (padrÃ£o: 2): \").strip()\n",
        "\n",
        "                if choice == \"1\":\n",
        "                    test_mode = \"minimal\"\n",
        "                elif choice == \"3\":\n",
        "                    test_mode = \"full\"\n",
        "                else:\n",
        "                    test_mode = \"standard\"\n",
        "\n",
        "        except (ImportError, Exception) as e:\n",
        "            print(f\"âš ï¸ NÃ£o foi possÃ­vel exibir widgets interativos: {e}\")\n",
        "            print(\"âš ï¸ Usando modo de teste padrÃ£o\")\n",
        "            test_mode = \"standard\"\n",
        "    else:\n",
        "        # Ambiente de linha de comando normal - podemos usar argparse\n",
        "        import argparse\n",
        "        parser = argparse.ArgumentParser(description='Teste de tamanhos de batch para GPU')\n",
        "        parser.add_argument('--minimal', action='store_true', help='Executar teste mÃ­nimo (mais rÃ¡pido)')\n",
        "        parser.add_argument('--full', action='store_true', help='Executar teste completo (mais demorado)')\n",
        "        args = parser.parse_args()\n",
        "\n",
        "        if args.minimal:\n",
        "            test_mode = \"minimal\"\n",
        "        elif args.full:\n",
        "            test_mode = \"full\"\n",
        "\n",
        "    print(\"=\" * 60)\n",
        "    print(\"ðŸš€ OTIMIZADOR DE BATCH SIZE PARA MINERADOR BITCOIN ðŸš€\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # VerificaÃ§Ã£o de hardware\n",
        "    print(\"\\nðŸ” Verificando hardware disponÃ­vel...\")\n",
        "    if IS_COLAB:\n",
        "        print(\"âœ… Ambiente Google Colab detectado\")\n",
        "\n",
        "        # Verificar GPU no Colab\n",
        "        try:\n",
        "            gpu_info = subprocess.run(\"nvidia-smi\", shell=True, stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
        "            print(\"\\nðŸ“Š InformaÃ§Ãµes da GPU:\")\n",
        "            for line in gpu_info.split(\"\\n\")[:8]:\n",
        "                print(f\"   {line}\")\n",
        "        except:\n",
        "            print(\"âŒ nvidia-smi falhou. GPU nÃ£o disponÃ­vel?\")\n",
        "\n",
        "    if not HAS_CUPY:\n",
        "        print(\"\\nâŒ CuPy nÃ£o disponÃ­vel. NÃ£o Ã© possÃ­vel executar testes na GPU.\")\n",
        "        print(\"   Instale com: pip install cupy-cuda11x ou cupy-cuda12x dependendo da sua versÃ£o CUDA\")\n",
        "        return\n",
        "\n",
        "    # Definir tamanhos de teste com base no modo selecionado\n",
        "    if test_mode == \"minimal\":\n",
        "        print(\"\\nðŸ” Modo: Teste MÃ­nimo (RÃ¡pido)\")\n",
        "        batch_sizes = [1024, 8192, 32768]\n",
        "    elif test_mode == \"full\":\n",
        "        print(\"\\nðŸ” Modo: Teste Completo (Detalhado)\")\n",
        "        batch_sizes = [512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]\n",
        "        # Verificar se hÃ¡ memÃ³ria suficiente para testar tamanhos maiores\n",
        "        if HAS_CUPY:\n",
        "            try:\n",
        "                free_mem, _ = cp.cuda.runtime.memGetInfo()\n",
        "                if free_mem > 6 * (1024**3):  # Mais de 6GB livre\n",
        "                    batch_sizes.append(131072)  # Adicionar teste de 128K\n",
        "                    print(\"âš ï¸ Executando teste de tamanho grande (128K)\")\n",
        "            except:\n",
        "                pass\n",
        "    else:\n",
        "        print(\"\\nðŸ” Modo: Teste PadrÃ£o\")\n",
        "        batch_sizes = [1024, 4096, 8192, 16384, 32768, 65536]\n",
        "\n",
        "    print(f\"\\nðŸ”¢ Testando tamanhos de batch: {batch_sizes}\")\n",
        "\n",
        "    # Testar transferÃªncia CPUâ†’GPU\n",
        "    transfer_results = test_cpu_to_gpu_transfer(batch_sizes)\n",
        "\n",
        "    # Testar processamento de lotes\n",
        "    processing_results = test_batch_processing(batch_sizes)\n",
        "\n",
        "    # Mostrar recomendaÃ§Ãµes\n",
        "    show_recommendations(transfer_results, processing_results)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "VZax15_NAEjh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Ferramenta para otimizar o desempenho GPU para o minerador Bitcoin\n",
        "Resolve o problema de baixo desempenho GPU comparado Ã  CPU\n",
        "\"\"\"\n",
        "\n",
        "import time\n",
        "import numpy as np\n",
        "import sys\n",
        "import subprocess\n",
        "\n",
        "# Tentar importar CuPy, PyTorch e TensorFlow para testes\n",
        "GPU_LIBS = {}\n",
        "\n",
        "try:\n",
        "    import cupy as cp\n",
        "    GPU_LIBS[\"cupy\"] = True\n",
        "    print(\"âœ… CuPy disponÃ­vel\")\n",
        "except ImportError:\n",
        "    GPU_LIBS[\"cupy\"] = False\n",
        "    print(\"âŒ CuPy nÃ£o disponÃ­vel\")\n",
        "\n",
        "try:\n",
        "    import torch\n",
        "    GPU_LIBS[\"torch\"] = torch.cuda.is_available()\n",
        "    print(f\"âœ… PyTorch disponÃ­vel, GPU: {torch.cuda.is_available()}\")\n",
        "    if torch.cuda.is_available():\n",
        "        print(f\"   Device: {torch.cuda.get_device_name(0)}\")\n",
        "except ImportError:\n",
        "    GPU_LIBS[\"torch\"] = False\n",
        "    print(\"âŒ PyTorch nÃ£o disponÃ­vel\")\n",
        "\n",
        "try:\n",
        "    import tensorflow as tf\n",
        "    GPU_LIBS[\"tensorflow\"] = len(tf.config.list_physical_devices('GPU')) > 0\n",
        "    print(f\"âœ… TensorFlow disponÃ­vel, GPU: {len(tf.config.list_physical_devices('GPU')) > 0}\")\n",
        "except ImportError:\n",
        "    GPU_LIBS[\"tensorflow\"] = False\n",
        "    print(\"âŒ TensorFlow nÃ£o disponÃ­vel\")\n",
        "\n",
        "def test_gpu_memory_transfer():\n",
        "    \"\"\"Testa a velocidade de transferÃªncia de dados entre CPU e GPU\"\"\"\n",
        "    if not GPU_LIBS[\"cupy\"]:\n",
        "        print(\"âŒ CuPy nÃ£o disponÃ­vel para teste de transferÃªncia\")\n",
        "        return\n",
        "\n",
        "    print(\"\\nðŸ” Testando velocidade de transferÃªncia CPU <-> GPU...\")\n",
        "\n",
        "    sizes = [\n",
        "        (1024*1024, \"1MB\"),\n",
        "        (10*1024*1024, \"10MB\"),\n",
        "        (100*1024*1024, \"100MB\"),\n",
        "        (500*1024*1024, \"500MB\"),\n",
        "    ]\n",
        "\n",
        "    for size_bytes, size_name in sizes:\n",
        "        # Criar array na CPU\n",
        "        cpu_array = np.ones(size_bytes // 4, dtype=np.float32)\n",
        "\n",
        "        # Teste de upload (CPU -> GPU)\n",
        "        start = time.time()\n",
        "        gpu_array = cp.asarray(cpu_array)\n",
        "        cp.cuda.stream.get_current_stream().synchronize()\n",
        "        upload_time = time.time() - start\n",
        "        upload_speed = size_bytes / upload_time / (1024**3)  # GB/s\n",
        "\n",
        "        # Teste de download (GPU -> CPU)\n",
        "        start = time.time()\n",
        "        cpu_result = gpu_array.get()\n",
        "        download_time = time.time() - start\n",
        "        download_speed = size_bytes / download_time / (1024**3)  # GB/s\n",
        "\n",
        "        print(f\"ðŸ“¦ Tamanho: {size_name}\")\n",
        "        print(f\"   Upload (CPUâ†’GPU): {upload_time*1000:.1f}ms ({upload_speed:.2f} GB/s)\")\n",
        "        print(f\"   Download (GPUâ†’CPU): {download_time*1000:.1f}ms ({download_speed:.2f} GB/s)\")\n",
        "\n",
        "        # Limpar memÃ³ria\n",
        "        del gpu_array\n",
        "        cp.get_default_memory_pool().free_all_blocks()\n",
        "\n",
        "def optimize_batch_size():\n",
        "    \"\"\"Encontra o tamanho de lote ideal para processamento na GPU\"\"\"\n",
        "    if not GPU_LIBS[\"cupy\"]:\n",
        "        print(\"âŒ CuPy nÃ£o disponÃ­vel para teste de tamanho de lote\")\n",
        "        return\n",
        "\n",
        "    print(\"\\nðŸ” Encontrando tamanho de lote ideal para GPU...\")\n",
        "\n",
        "    # Definir diferentes tamanhos de lote para teste\n",
        "    batch_sizes = [512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]\n",
        "    vector_size = 20  # Tamanho do vetor para cada elemento (20 bytes para hash160)\n",
        "    target_count = 10  # NÃºmero de targets para comparar\n",
        "\n",
        "    best_batch_size = None\n",
        "    best_throughput = 0\n",
        "\n",
        "    for batch_size in batch_sizes:\n",
        "        print(f\"\\nðŸ“Š Testando batch_size={batch_size}...\")\n",
        "\n",
        "        # Criar dados de teste\n",
        "        addresses_cpu = np.random.randint(0, 256, size=(batch_size, vector_size), dtype=np.uint8)\n",
        "        targets_cpu = np.random.randint(0, 256, size=(target_count, vector_size), dtype=np.uint8)\n",
        "\n",
        "        # Transferir para GPU\n",
        "        start_time = time.time()\n",
        "        addresses_gpu = cp.asarray(addresses_cpu)\n",
        "        targets_gpu = cp.asarray(targets_cpu)\n",
        "\n",
        "        # Simular operaÃ§Ãµes de verificaÃ§Ã£o (comparaÃ§Ã£o com cada target)\n",
        "        results = cp.zeros(batch_size, dtype=cp.bool_)\n",
        "\n",
        "        for t in range(target_count):\n",
        "            target = targets_gpu[t]\n",
        "\n",
        "            # Comparar todos os vetores com este target\n",
        "            match_all = cp.ones(batch_size, dtype=cp.bool_)\n",
        "            for b in range(vector_size):\n",
        "                match_this_byte = addresses_gpu[:, b] == target[b]\n",
        "                match_all = match_all & match_this_byte\n",
        "\n",
        "            # Adicionar aos resultados\n",
        "            results = results | match_all\n",
        "\n",
        "        # Obter resultados de volta\n",
        "        matches = results.get()\n",
        "\n",
        "        total_time = time.time() - start_time\n",
        "        throughput = batch_size / total_time\n",
        "\n",
        "        print(f\"   Tempo: {total_time:.4f}s\")\n",
        "        print(f\"   Throughput: {throughput:.0f} elementos/s\")\n",
        "        print(f\"   Throughput: {throughput/1e6:.2f} Melementos/s\")\n",
        "\n",
        "        if throughput > best_throughput:\n",
        "            best_throughput = throughput\n",
        "            best_batch_size = batch_size\n",
        "\n",
        "        # Limpar memÃ³ria GPU\n",
        "        del addresses_gpu, targets_gpu, results\n",
        "        cp.get_default_memory_pool().free_all_blocks()\n",
        "\n",
        "    # Resumo final\n",
        "    print(f\"\\nâœ… RESULTADO FINAL:\")\n",
        "    print(f\"   Melhor tamanho de lote: {best_batch_size}\")\n",
        "    print(f\"   Throughput mÃ¡ximo: {best_throughput/1e6:.2f} Melementos/s\")\n",
        "    print(f\"   âž¡ï¸ RecomendaÃ§Ã£o: Definir BATCH_SIZE = {best_batch_size} no seu script\")\n",
        "\n",
        "    return best_batch_size\n",
        "\n",
        "def optimize_memory_usage():\n",
        "    \"\"\"Otimiza o uso de memÃ³ria GPU para melhor desempenho\"\"\"\n",
        "    if not GPU_LIBS[\"cupy\"]:\n",
        "        return\n",
        "\n",
        "    print(\"\\nðŸ” Otimizando uso de memÃ³ria GPU...\")\n",
        "\n",
        "    try:\n",
        "        # Obter informaÃ§Ãµes de memÃ³ria total e disponÃ­vel\n",
        "        mem_info = cp.cuda.runtime.memGetInfo()\n",
        "        mem_free = mem_info[0]\n",
        "        mem_total = mem_info[1]\n",
        "\n",
        "        print(f\"   MemÃ³ria total: {mem_total / (1024**2):.0f} MB\")\n",
        "        print(f\"   MemÃ³ria disponÃ­vel: {mem_free / (1024**2):.0f} MB\")\n",
        "\n",
        "        # Calcular fraÃ§Ã£o segura para uso\n",
        "        safe_fraction = 0.8  # Usa 80% da memÃ³ria disponÃ­vel\n",
        "        safe_mem = int(mem_free * safe_fraction)\n",
        "\n",
        "        # Estimar quantos elementos podem ser processados com essa memÃ³ria\n",
        "        # Assumindo que cada elemento usa ~100 bytes na GPU (endereÃ§o + dados complementares)\n",
        "        bytes_per_element = 100\n",
        "        max_elements = safe_mem // bytes_per_element\n",
        "\n",
        "        print(f\"   MemÃ³ria segura para uso: {safe_mem / (1024**2):.0f} MB\")\n",
        "        print(f\"   Elementos estimados: {max_elements:,}\")\n",
        "\n",
        "        # Calcular batch size recomendado (arredondar para potÃªncia de 2 inferior)\n",
        "        batch_size = 2**int(np.log2(max_elements))\n",
        "        batch_size = min(batch_size, 65536)  # Limitar ao mÃ¡ximo razoÃ¡vel\n",
        "\n",
        "        print(f\"   âž¡ï¸ Batch size recomendado: {batch_size}\")\n",
        "\n",
        "        # SugestÃ£o para sub-batch size (maior para GPU)\n",
        "        subbatch_size = 2**24  # 16M chaves por sub-lote\n",
        "        if mem_total < 8 * (1024**3):  # Menos de 8GB de VRAM\n",
        "            subbatch_size = 2**22  # Reduz para 4M em GPUs com menos memÃ³ria\n",
        "\n",
        "        print(f\"   âž¡ï¸ Sub-batch size recomendado: {subbatch_size:,}\")\n",
        "\n",
        "        return batch_size, subbatch_size\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Erro ao calcular uso de memÃ³ria: {e}\")\n",
        "        return None, None\n",
        "\n",
        "def test_cpu_vs_gpu():\n",
        "    \"\"\"Compara desempenho da CPU vs GPU para operaÃ§Ãµes especÃ­ficas do minerador\"\"\"\n",
        "    print(\"\\nðŸ† COMPARANDO DESEMPENHO CPU vs GPU\")\n",
        "\n",
        "    # Definir tamanho do teste\n",
        "    sample_size = 50000  # 50K elementos\n",
        "\n",
        "    # Gerar dados aleatÃ³rios para teste\n",
        "    data_np = np.random.randint(0, 256, size=(sample_size, 20), dtype=np.uint8)\n",
        "    targets_np = np.random.randint(0, 256, size=(10, 20), dtype=np.uint8)\n",
        "\n",
        "    # Teste 1: ComparaÃ§Ã£o na CPU usando NumPy\n",
        "    print(\"\\nðŸ“Š Teste de comparaÃ§Ã£o (CPU/NumPy):\")\n",
        "    start_time = time.time()\n",
        "    matches_cpu = np.zeros(sample_size, dtype=bool)\n",
        "\n",
        "    for i in range(sample_size):\n",
        "        for t in range(10):\n",
        "            if np.array_equal(data_np[i], targets_np[t]):\n",
        "                matches_cpu[i] = True\n",
        "                break\n",
        "\n",
        "    cpu_time = time.time() - start_time\n",
        "\n",
        "    print(f\"   Tempo CPU: {cpu_time:.4f}s\")\n",
        "    print(f\"   Throughput: {sample_size / cpu_time:.0f} elem/s\")\n",
        "\n",
        "    # Teste 2: ComparaÃ§Ã£o na GPU usando CuPy\n",
        "    if GPU_LIBS[\"cupy\"]:\n",
        "        print(\"\\nðŸ“Š Teste de comparaÃ§Ã£o (GPU/CuPy):\")\n",
        "        start_time = time.time()\n",
        "\n",
        "        # Transferir dados para GPU\n",
        "        data_cp = cp.asarray(data_np)\n",
        "        targets_cp = cp.asarray(targets_np)\n",
        "\n",
        "        # Realizar comparaÃ§Ã£o\n",
        "        matches_gpu = cp.zeros(sample_size, dtype=cp.bool_)\n",
        "\n",
        "        for t in range(10):\n",
        "            target = targets_cp[t]\n",
        "            match_all = cp.all(data_cp == target, axis=1)\n",
        "            matches_gpu = matches_gpu | match_all\n",
        "\n",
        "        # ForÃ§ar sincronizaÃ§Ã£o e copiar resultados\n",
        "        cp.cuda.stream.get_current_stream().synchronize()\n",
        "        matches_gpu_np = matches_gpu.get()\n",
        "\n",
        "        gpu_time = time.time() - start_time\n",
        "\n",
        "        print(f\"   Tempo GPU: {gpu_time:.4f}s\")\n",
        "        print(f\"   Throughput: {sample_size / gpu_time:.0f} elem/s\")\n",
        "        print(f\"   Speedup GPU/CPU: {cpu_time / gpu_time:.2f}x\")\n",
        "\n",
        "        # Verificar resultados\n",
        "        matches = np.sum(matches_cpu == matches_gpu_np)\n",
        "        accuracy = matches / sample_size * 100\n",
        "        print(f\"   Resultados equivalentes: {accuracy:.2f}%\")\n",
        "\n",
        "        # Limpar memÃ³ria GPU\n",
        "        del data_cp, targets_cp, matches_gpu\n",
        "        cp.get_default_memory_pool().free_all_blocks()\n",
        "\n",
        "def main():\n",
        "    print(\"=\" * 60)\n",
        "    print(\"ðŸš€ OTIMIZADOR DE DESEMPENHO GPU PARA MINERADOR BITCOIN ðŸš€\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # Verificar se GPU estÃ¡ disponÃ­vel\n",
        "    if not any(GPU_LIBS.values()):\n",
        "        print(\"âŒ Nenhuma biblioteca GPU (CuPy, PyTorch, TensorFlow) disponÃ­vel.\")\n",
        "        print(\"   Instale pelo menos uma dessas bibliotecas antes de usar este otimizador.\")\n",
        "        return\n",
        "\n",
        "    # Testar velocidade de transferÃªncia entre CPU e GPU\n",
        "    test_gpu_memory_transfer()\n",
        "\n",
        "    # Otimizar tamanho de lote para GPU\n",
        "    best_batch_size = optimize_batch_size()\n",
        "\n",
        "    # Otimizar uso de memÃ³ria\n",
        "    mem_batch_size, subbatch_size = optimize_memory_usage()\n",
        "\n",
        "    # Comparar CPU vs GPU\n",
        "    test_cpu_vs_gpu()\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"âœ… RECOMENDAÃ‡Ã•ES FINAIS\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # Determinar tamanho final recomendado\n",
        "    batch_size = best_batch_size if best_batch_size else mem_batch_size\n",
        "    if not batch_size:\n",
        "        batch_size = 8192  # valor padrÃ£o conservador\n",
        "\n",
        "    print(f\"1. Defina BATCH_SIZE = {batch_size}\")\n",
        "    print(f\"2. Defina SUBBATCH_SIZE = {subbatch_size or 2**23}\")\n",
        "    print(f\"3. Para melhor desempenho com CuPy, minimize transferÃªncias entre CPU e GPU\")\n",
        "    print(f\"4. PrÃ©-aloque buffers na GPU para reduzir fragmentaÃ§Ã£o de memÃ³ria\")\n",
        "    print(f\"5. Processe os lotes em blocos para operaÃ§Ãµes na GPU\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "GjJiHcuU-W5u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Script para testar a velocidade de processamento de diferentes mÃ©todos\n",
        "e identificar gargalos de desempenho\n",
        "\"\"\"\n",
        "import time\n",
        "import numpy as np\n",
        "from coincurve import PublicKey\n",
        "from eth_utils import keccak\n",
        "import base58\n",
        "import hashlib\n",
        "\n",
        "# Tente importar bibliotecas GPU\n",
        "try:\n",
        "    import cupy as cp\n",
        "    HAS_CUPY = True\n",
        "    print(\"âœ… CuPy disponÃ­vel\")\n",
        "except ImportError:\n",
        "    HAS_CUPY = False\n",
        "    print(\"âŒ CuPy nÃ£o disponÃ­vel\")\n",
        "\n",
        "try:\n",
        "    import torch\n",
        "    HAS_TORCH = torch.cuda.is_available()\n",
        "    print(f\"âœ… PyTorch disponÃ­vel, GPU: {torch.cuda.is_available()}\")\n",
        "    if torch.cuda.is_available():\n",
        "        print(f\"   Device: {torch.cuda.get_device_name(0)}\")\n",
        "except ImportError:\n",
        "    HAS_TORCH = False\n",
        "    print(\"âŒ PyTorch nÃ£o disponÃ­vel\")\n",
        "\n",
        "try:\n",
        "    import tensorflow as tf\n",
        "    HAS_TF = len(tf.config.list_physical_devices('GPU')) > 0\n",
        "    print(f\"âœ… TensorFlow disponÃ­vel, GPU: {len(tf.config.list_physical_devices('GPU')) > 0}\")\n",
        "except ImportError:\n",
        "    HAS_TF = False\n",
        "    print(\"âŒ TensorFlow nÃ£o disponÃ­vel\")\n",
        "\n",
        "# FunÃ§Ãµes de hash e endereÃ§amento\n",
        "def custom_keccak(data):\n",
        "    \"\"\"Calcula Keccak-256 com tratamento de erros.\"\"\"\n",
        "    try:\n",
        "        if isinstance(data, str):\n",
        "            data = bytes.fromhex(data.replace('0x', ''))\n",
        "        return keccak(data)\n",
        "    except Exception:\n",
        "        return b'\\x00' * 32\n",
        "\n",
        "def bitcoin_hash160(data):\n",
        "    \"\"\"Calcula hash160 (SHA-256 seguido de RIPEMD-160)\"\"\"\n",
        "    sha = hashlib.sha256(data).digest()\n",
        "    ripemd160 = hashlib.new('ripemd160')\n",
        "    ripemd160.update(sha)\n",
        "    return ripemd160.digest()\n",
        "\n",
        "def test_address_generation(n_keys=1000):\n",
        "    \"\"\"Testa a velocidade da geraÃ§Ã£o de endereÃ§os Bitcoin.\"\"\"\n",
        "    print(f\"\\nðŸ”„ Testando geraÃ§Ã£o de {n_keys} endereÃ§os Bitcoin...\")\n",
        "\n",
        "    # Gerar chaves privadas aleatÃ³rias\n",
        "    print(\"Gerando chaves privadas...\")\n",
        "    keys = [int.from_bytes(np.random.bytes(32), 'big') % (2**256 - 2**32 - 977) + 1 for _ in range(n_keys)]\n",
        "\n",
        "    # MÃ©todo 1: Keccak-256 (ethereum)\n",
        "    print(\"\\nMÃ©todo 1: Keccak-256 (Ethereum)\")\n",
        "    start_time = time.time()\n",
        "    addresses_keccak = []\n",
        "    for key in keys:\n",
        "        try:\n",
        "            private_key_hex = f\"{key:064x}\"\n",
        "            pk_bytes = bytes.fromhex(private_key_hex)\n",
        "            public_key = PublicKey.from_valid_secret(pk_bytes).format(compressed=False)[1:]\n",
        "            hash_bytes = custom_keccak(public_key)[-20:]\n",
        "            addresses_keccak.append(hash_bytes)\n",
        "        except Exception:\n",
        "            addresses_keccak.append(b'\\x00' * 20)\n",
        "    elapsed = time.time() - start_time\n",
        "    print(f\"âœ… Tempo: {elapsed:.3f}s ({n_keys/elapsed:.1f} chaves/s)\")\n",
        "\n",
        "    # MÃ©todo 2: SHA-256 + RIPEMD-160 (bitcoin)\n",
        "    print(\"\\nMÃ©todo 2: SHA-256 + RIPEMD-160 (Bitcoin)\")\n",
        "    start_time = time.time()\n",
        "    addresses_bitcoin = []\n",
        "    for key in keys:\n",
        "        try:\n",
        "            private_key_hex = f\"{key:064x}\"\n",
        "            pk_bytes = bytes.fromhex(private_key_hex)\n",
        "            public_key = PublicKey.from_valid_secret(pk_bytes).format(compressed=False)[1:]\n",
        "            hash_bytes = bitcoin_hash160(public_key)\n",
        "            addresses_bitcoin.append(hash_bytes)\n",
        "        except Exception:\n",
        "            addresses_bitcoin.append(b'\\x00' * 20)\n",
        "    elapsed = time.time() - start_time\n",
        "    print(f\"âœ… Tempo: {elapsed:.3f}s ({n_keys/elapsed:.1f} chaves/s)\")\n",
        "\n",
        "    # Comparar resultados\n",
        "    matches = 0\n",
        "    for i in range(len(addresses_keccak)):\n",
        "        if addresses_keccak[i] == addresses_bitcoin[i]:\n",
        "            matches += 1\n",
        "    match_percent = (matches / len(addresses_keccak)) * 100\n",
        "    print(f\"ðŸ“Š CorrespondÃªncia entre mÃ©todos: {match_percent:.2f}%\")\n",
        "\n",
        "    if match_percent < 100:\n",
        "        print(\"âš ï¸ AVISO: Os mÃ©todos produzem resultados diferentes!\")\n",
        "        print(\"   Isso pode causar incompatibilidade com endereÃ§os Bitcoin reais.\")\n",
        "\n",
        "def test_batch_processing():\n",
        "    \"\"\"Testa a velocidade de processamento em lotes.\"\"\"\n",
        "    print(\"\\nðŸ”„ Testando velocidade de processamento em lote...\")\n",
        "\n",
        "    # Preparar dados de teste\n",
        "    n_addresses = 10000\n",
        "    n_targets = 10\n",
        "\n",
        "    # Gerar endereÃ§os aleatÃ³rios\n",
        "    addresses = np.random.randint(0, 256, size=(n_addresses, 20), dtype=np.uint8)\n",
        "    # Garantir que pelo menos 5 endereÃ§os correspondem a targets\n",
        "    targets = np.random.randint(0, 256, size=(n_targets, 20), dtype=np.uint8)\n",
        "    for i in range(5):\n",
        "        addresses[i] = targets[i % n_targets]\n",
        "\n",
        "    # MÃ©todo 1: ComparaÃ§Ã£o com NumPy\n",
        "    print(\"\\nMÃ©todo 1: NumPy (CPU)\")\n",
        "    start_time = time.time()\n",
        "    matches_numpy = np.zeros(n_addresses, dtype=bool)\n",
        "    for i in range(n_addresses):\n",
        "        for t in range(n_targets):\n",
        "            if np.array_equal(addresses[i], targets[t]):\n",
        "                matches_numpy[i] = True\n",
        "                break\n",
        "    numpy_time = time.time() - start_time\n",
        "    print(f\"âœ… Tempo: {numpy_time:.3f}s ({n_addresses/numpy_time:.1f} endereÃ§os/s)\")\n",
        "    print(f\"   Matches: {np.sum(matches_numpy)}\")\n",
        "\n",
        "    # MÃ©todo 2: CuPy (se disponÃ­vel)\n",
        "    if HAS_CUPY:\n",
        "        print(\"\\nMÃ©todo 2: CuPy (GPU)\")\n",
        "        start_time = time.time()\n",
        "\n",
        "        # Transferir para GPU\n",
        "        addresses_gpu = cp.asarray(addresses)\n",
        "        targets_gpu = cp.asarray(targets)\n",
        "        matches_cupy = cp.zeros(n_addresses, dtype=bool)\n",
        "\n",
        "        # Verificar correspondÃªncias\n",
        "        for t_idx in range(n_targets):\n",
        "            target = targets_gpu[t_idx]\n",
        "            # Comparar cada endereÃ§o com este target\n",
        "            equal_bytes = cp.all(addresses_gpu == target, axis=1)\n",
        "            # Atualizar resultados\n",
        "            matches_cupy = cp.logical_or(matches_cupy, equal_bytes)\n",
        "\n",
        "        # Transferir resultados de volta para CPU\n",
        "        matches_cupy_cpu = matches_cupy.get()\n",
        "\n",
        "        cupy_time = time.time() - start_time\n",
        "        print(f\"âœ… Tempo: {cupy_time:.3f}s ({n_addresses/cupy_time:.1f} endereÃ§os/s)\")\n",
        "        print(f\"   Matches: {np.sum(matches_cupy_cpu)}\")\n",
        "        print(f\"   Speedup vs CPU: {numpy_time/cupy_time:.1f}x\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"=\" * 60)\n",
        "    print(\"ðŸš€ TESTE DE DESEMPENHO BITCOIN MINER ðŸš€\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # Teste de geraÃ§Ã£o de endereÃ§os\n",
        "    test_address_generation(5000)\n",
        "\n",
        "    # Teste de processamento em lote\n",
        "    test_batch_processing()\n"
      ],
      "metadata": {
        "id": "30tVM1H08dKR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Script para validar a correta conversÃ£o de chaves privadas para endereÃ§os Bitcoin\n",
        "\"\"\"\n",
        "import base58\n",
        "import numpy as np\n",
        "from coincurve import PublicKey\n",
        "from eth_utils import keccak\n",
        "import hashlib\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "# Instalar bibliotecas necessÃ¡rias se nÃ£o estiverem disponÃ­veis\n",
        "try:\n",
        "    from Crypto.Hash import RIPEMD160\n",
        "    HAS_PYCRYPTO = True\n",
        "    print(\"âœ… Usando Crypto.Hash.RIPEMD160\")\n",
        "except ImportError:\n",
        "    HAS_PYCRYPTO = False\n",
        "    print(\"âš ï¸ Crypto.Hash.RIPEMD160 nÃ£o disponÃ­vel, instalando pycryptodome...\")\n",
        "    try:\n",
        "        subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"pycryptodome\"], check=True)\n",
        "        from Crypto.Hash import RIPEMD160\n",
        "        HAS_PYCRYPTO = True\n",
        "        print(\"âœ… pycryptodome instalado com sucesso\")\n",
        "    except:\n",
        "        print(\"âŒ NÃ£o foi possÃ­vel instalar pycryptodome\")\n",
        "        HAS_PYCRYPTO = False\n",
        "\n",
        "def custom_keccak(data):\n",
        "    \"\"\"Calcula Keccak-256 com tratamento de erros.\"\"\"\n",
        "    try:\n",
        "        if isinstance(data, str):\n",
        "            data = bytes.fromhex(data.replace('0x', ''))\n",
        "        return keccak(data)\n",
        "    except Exception:\n",
        "        return b'\\x00' * 32\n",
        "\n",
        "def sha256(data):\n",
        "    \"\"\"Calcula SHA-256\"\"\"\n",
        "    return hashlib.sha256(data).digest()\n",
        "\n",
        "def ripemd160(data):\n",
        "    \"\"\"\n",
        "    Calcula RIPEMD-160 usando a biblioteca Crypto.Hash quando disponÃ­vel\n",
        "    ou um mÃ©todo alternativo quando nÃ£o estÃ¡ disponÃ­vel\n",
        "    \"\"\"\n",
        "    if HAS_PYCRYPTO:\n",
        "        # Usando pycryptodome\n",
        "        h = RIPEMD160.new()\n",
        "        h.update(data)\n",
        "        return h.digest()\n",
        "    else:\n",
        "        # ImplementaÃ§Ã£o alternativa usando outro algoritmo\n",
        "        # (isso Ã© apenas um fallback, nÃ£o use em produÃ§Ã£o)\n",
        "        print(\"âš ï¸ RIPEMD160 nÃ£o disponÃ­vel, usando SHA1 como fallback (NÃƒO SEGURO)\")\n",
        "        return hashlib.sha1(data).digest()\n",
        "\n",
        "def bitcoin_hash160(public_key):\n",
        "    \"\"\"ImplementaÃ§Ã£o correta do hash160 usado no Bitcoin (SHA256 seguido de RIPEMD160)\"\"\"\n",
        "    sha = sha256(public_key)\n",
        "    ripe = ripemd160(sha)\n",
        "    return ripe\n",
        "\n",
        "def bitcoin_address_from_private_key(private_key_int):\n",
        "    \"\"\"\n",
        "    Converte uma chave privada (inteiro) para um endereÃ§o Bitcoin.\n",
        "    Retorna o endereÃ§o Base58Check e o hash160 como array.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Converter para bytes\n",
        "        private_key_hex = f\"{private_key_int:064x}\"\n",
        "        private_key_bytes = bytes.fromhex(private_key_hex)\n",
        "\n",
        "        # Gerar chave pÃºblica\n",
        "        public_key = PublicKey.from_valid_secret(private_key_bytes).format(compressed=False)[1:]\n",
        "\n",
        "        # OpÃ§Ã£o 1: Hash usando Keccak (eth_utils)\n",
        "        hash_keccak = custom_keccak(public_key)[-20:]\n",
        "\n",
        "        # OpÃ§Ã£o 2: Hash usando SHA-256 + RIPEMD-160 (mÃ©todo Bitcoin tradicional)\n",
        "        hash_bitcoin = bitcoin_hash160(public_key)\n",
        "\n",
        "        # Comparar os dois mÃ©todos de hash\n",
        "        if hash_keccak != hash_bitcoin:\n",
        "            print(f\"âš ï¸ DiscrepÃ¢ncia nos mÃ©todos de hash para chave {private_key_hex[:8]}...\")\n",
        "            print(f\"   Keccak: {hash_keccak.hex()}\")\n",
        "            print(f\"   Bitcoin: {hash_bitcoin.hex()}\")\n",
        "\n",
        "        # Usar o mÃ©todo Bitcoin (SHA-256 + RIPEMD-160)\n",
        "        hash160 = hash_bitcoin\n",
        "\n",
        "        # Adicionar byte de versÃ£o (0x00 para Bitcoin mainnet)\n",
        "        extended = b'\\x00' + hash160\n",
        "\n",
        "        # Calcular checksum (4 primeiros bytes do SHA-256 duplo)\n",
        "        checksum = sha256(sha256(extended))[:4]\n",
        "\n",
        "        # Juntar tudo\n",
        "        address_bytes = extended + checksum\n",
        "\n",
        "        # Codificar em Base58\n",
        "        address = base58.b58encode(address_bytes).decode('ascii')\n",
        "\n",
        "        return address, np.frombuffer(hash160, dtype=np.uint8)\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Erro ao converter chave privada: {e}\")\n",
        "        return None, None\n",
        "\n",
        "def test_conversion():\n",
        "    \"\"\"Testa a conversÃ£o com chaves privadas e endereÃ§os conhecidos.\"\"\"\n",
        "    # Alguns exemplos conhecidos de pares chave privada -> endereÃ§o Bitcoin\n",
        "    test_cases = [\n",
        "        # Formato: (chave privada em hex, endereÃ§o esperado)\n",
        "        (\"1\", \"1EHNa6Q4Jz2uvNExL497mE43ikXhwF6kZm\"),\n",
        "        (\"FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFEBAAEDCE6AF48A03BBFD25E8CD0364140\", \"1LdHYK73XVvknPTLoTVW7hm3H6LWNdZQKL\"),\n",
        "        (\"0000000000000000000000000000000000000000000000000000000000000001\", \"1BgGZ9tcN4rm9KBzDn7KprQz87SZ26SAMH\")\n",
        "    ]\n",
        "\n",
        "    print(\"ðŸ” Validando conversÃ£o de chaves privadas para endereÃ§os Bitcoin...\")\n",
        "\n",
        "    for i, (priv_key_hex, expected_address) in enumerate(test_cases):\n",
        "        priv_key_int = int(priv_key_hex, 16)\n",
        "        generated_address, hash160 = bitcoin_address_from_private_key(priv_key_int)\n",
        "\n",
        "        if generated_address == expected_address:\n",
        "            print(f\"âœ… Teste {i+1}: EndereÃ§o correto: {generated_address}\")\n",
        "        else:\n",
        "            print(f\"âŒ Teste {i+1}: Erro! Esperado: {expected_address}, obtido: {generated_address}\")\n",
        "\n",
        "    # Teste especial para o endereÃ§o adicional\n",
        "    golden_address = \"1MVDYgVaSN6iKKEsbzRUAYFrYJadLYZvvZ\"\n",
        "\n",
        "    # Decodificar o endereÃ§o para obter o hash160\n",
        "    decoded = base58.b58decode(golden_address)\n",
        "    golden_hash = decoded[1:-4]  # Remove byte de versÃ£o e checksum\n",
        "\n",
        "    print(f\"\\nðŸŒŸ Golden Address: {golden_address}\")\n",
        "    print(f\"   Hash160: {golden_hash.hex()}\")\n",
        "\n",
        "    # Para validaÃ§Ã£o, podemos verificar se o endereÃ§o reconstruÃ­do corresponde ao original\n",
        "    extended = b'\\x00' + golden_hash\n",
        "    checksum = sha256(sha256(extended))[:4]\n",
        "    address_bytes = extended + checksum\n",
        "    reconstructed = base58.b58encode(address_bytes).decode('ascii')\n",
        "\n",
        "    if reconstructed == golden_address:\n",
        "        print(f\"âœ… ValidaÃ§Ã£o do Golden Address bem-sucedida\")\n",
        "    else:\n",
        "        print(f\"âŒ ValidaÃ§Ã£o do Golden Address falhou\")\n",
        "\n",
        "    print(\"\\nðŸ”„ O minerador estÃ¡ usando o algoritmo de hash correto para Bitcoin? Verificando...\")\n",
        "    # Verificar se estamos usando o algoritmo correto para Bitcoin\n",
        "    if \"eth_utils\" in globals():\n",
        "        print(\"âš ï¸ O cÃ³digo estÃ¡ usando 'eth_utils.keccak' em vez de SHA-256+RIPEMD-160.\")\n",
        "        print(\"   Isso pode causar incompatibilidade com endereÃ§os Bitcoin.\")\n",
        "    else:\n",
        "        print(\"âœ… O cÃ³digo estÃ¡ usando SHA-256+RIPEMD-160, que Ã© o algoritmo correto para Bitcoin.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"=\" * 60)\n",
        "    print(\"ðŸ§ª TESTE DE VALIDAÃ‡ÃƒO DE CHAVES BITCOIN ðŸ§ª\")\n",
        "    print(\"=\" * 60)\n",
        "    test_conversion()\n",
        "    print(\"=\" * 60)\n"
      ],
      "metadata": {
        "id": "FL5qEq9R8Fo0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Script para otimizar o ambiente de mineraÃ§Ã£o com base nos resultados do teste de batch size\n",
        "Configura o sistema para mÃ¡ximo desempenho de acesso Ã  GPU\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import subprocess\n",
        "import time\n",
        "import json\n",
        "import multiprocessing\n",
        "\n",
        "def check_environment():\n",
        "    \"\"\"Verifica o ambiente de execuÃ§Ã£o e mostra informaÃ§Ãµes relevantes.\"\"\"\n",
        "    print(\"=\" * 60)\n",
        "    print(\"ðŸ” VERIFICANDO AMBIENTE DE MINERAÃ‡ÃƒO\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # Verificar se estamos no Google Colab\n",
        "    is_colab = 'google.colab' in sys.modules\n",
        "    if is_colab:\n",
        "        print(\"âœ… Ambiente Google Colab detectado\")\n",
        "\n",
        "        # Verificar informaÃ§Ãµes da GPU\n",
        "        try:\n",
        "            gpu_info = subprocess.run(\"nvidia-smi\", shell=True, stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
        "            print(\"\\nðŸ“Š InformaÃ§Ãµes da GPU:\")\n",
        "            for line in gpu_info.split('\\n')[:10]:\n",
        "                print(f\"   {line}\")\n",
        "        except:\n",
        "            print(\"âŒ GPU nÃ£o detectada ou nvidia-smi falhou\")\n",
        "    else:\n",
        "        print(\"â„¹ï¸ Executando fora do Google Colab\")\n",
        "\n",
        "    # Verificar CPUs disponÃ­veis\n",
        "    cpu_count = multiprocessing.cpu_count()\n",
        "    print(f\"\\nðŸ“Š CPUs disponÃ­veis: {cpu_count}\")\n",
        "\n",
        "    # Verificar memÃ³ria do sistema\n",
        "    try:\n",
        "        if is_colab:\n",
        "            # Usar comando para obter memÃ³ria no Linux\n",
        "            mem_info = subprocess.run(\"free -m\", shell=True, stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
        "            print(\"\\nðŸ“Š InformaÃ§Ãµes de memÃ³ria:\")\n",
        "            for line in mem_info.split('\\n')[:3]:\n",
        "                print(f\"   {line}\")\n",
        "        else:\n",
        "            # MÃ©todo mais genÃ©rico\n",
        "            import psutil\n",
        "            vm = psutil.virtual_memory()\n",
        "            print(f\"\\nðŸ“Š MemÃ³ria sistema: {vm.total / (1024**3):.1f} GB total, {vm.available / (1024**3):.1f} GB disponÃ­vel\")\n",
        "    except:\n",
        "        print(\"âš ï¸ NÃ£o foi possÃ­vel obter informaÃ§Ãµes de memÃ³ria\")\n",
        "\n",
        "    return is_colab\n",
        "\n",
        "def load_batch_test_results():\n",
        "    \"\"\"Carrega resultados do teste de batch size se disponÃ­vel, ou usa valores padrÃ£o.\"\"\"\n",
        "    try:\n",
        "        with open(\"batch_test_results.json\", \"r\") as f:\n",
        "            results = json.load(f)\n",
        "            print(\"âœ… Carregados resultados do teste de batch size anterior\")\n",
        "            return results\n",
        "    except:\n",
        "        # Valores padrÃ£o caso nÃ£o tenhamos um arquivo de resultados\n",
        "        print(\"âš ï¸ Arquivo de resultados nÃ£o encontrado, usando valores padrÃ£o\")\n",
        "        return {\n",
        "            \"batch_size\": 32768,\n",
        "            \"subbatch_size\": 67108864,\n",
        "            \"cpu_is_bottleneck\": True,\n",
        "            \"recommended_workers\": multiprocessing.cpu_count() - 1\n",
        "        }\n",
        "\n",
        "def update_runtime_config():\n",
        "    \"\"\"Atualiza configuraÃ§Ãµes do ambiente de execuÃ§Ã£o para melhor desempenho.\"\"\"\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"ðŸ”§ OTIMIZANDO CONFIGURAÃ‡Ã•ES DE RUNTIME\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # Carregar configuraÃ§Ãµes do nÃºcleo do sistema (Linux)\n",
        "    try:\n",
        "        # Configurar para melhor desempenho multithreading\n",
        "        if sys.platform.startswith('linux'):\n",
        "            # Desativar preemption para melhor desempenho de CPU\n",
        "            subprocess.run(\"echo 0 | sudo tee /proc/sys/kernel/sched_rt_runtime_us\",\n",
        "                          shell=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
        "            print(\"âœ… Kernel configurado para priorizar tasks de tempo real\")\n",
        "\n",
        "            # Configurar para melhor desempenho de I/O\n",
        "            subprocess.run(\"echo 3 | sudo tee /proc/sys/vm/drop_caches\",\n",
        "                          shell=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
        "            print(\"âœ… Caches de sistema liberados para melhor desempenho\")\n",
        "    except:\n",
        "        print(\"âš ï¸ NÃ£o foi possÃ­vel otimizar configuraÃ§Ãµes do kernel\")\n",
        "\n",
        "    # Configurar Python para melhor desempenho\n",
        "    try:\n",
        "        # Ajustar GC para menos interrupÃ§Ãµes\n",
        "        import gc\n",
        "        gc.disable()\n",
        "        print(\"âœ… Garbage collector desabilitado para melhor desempenho\")\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    # Configurar NumPy para usar mÃºltiplas threads\n",
        "    try:\n",
        "        import numpy as np\n",
        "        np.show_config()\n",
        "        print(\"âš ï¸ Verifique se NumPy estÃ¡ usando MKL para otimizaÃ§Ã£o de performance\")\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    return True\n",
        "\n",
        "def optimize_nvidia_settings():\n",
        "    \"\"\"Otimiza configuraÃ§Ãµes especÃ­ficas da GPU NVIDIA.\"\"\"\n",
        "    try:\n",
        "        # Definir modo de performance para mÃ¡ximo desempenho\n",
        "        subprocess.run(\"nvidia-smi -pm 1\", shell=True,\n",
        "                      stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
        "\n",
        "        # Desativar limitaÃ§Ã£o de potÃªncia\n",
        "        subprocess.run(\"nvidia-smi -pl 250\", shell=True,  # 250W ou ajustar conforme sua GPU\n",
        "                      stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
        "\n",
        "        # Configurar para modo de computaÃ§Ã£o\n",
        "        subprocess.run(\"nvidia-smi -c 3\", shell=True,  # Modo EXCLUSIVE_PROCESS\n",
        "                      stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
        "\n",
        "        print(\"âœ… GPU NVIDIA otimizada para mÃ¡ximo desempenho\")\n",
        "        return True\n",
        "    except:\n",
        "        print(\"âš ï¸ NÃ£o foi possÃ­vel otimizar configuraÃ§Ãµes NVIDIA\")\n",
        "        return False\n",
        "\n",
        "def generate_optimized_config():\n",
        "    \"\"\"Gera um arquivo de configuraÃ§Ã£o otimizado para o minerador.\"\"\"\n",
        "    # Carregar resultados do teste de batch size\n",
        "    results = load_batch_test_results()\n",
        "\n",
        "    # Determinar valores Ã³timos\n",
        "    batch_size = results.get(\"batch_size\", 32768)\n",
        "    subbatch_size = results.get(\"subbatch_size\", 67108864)\n",
        "    cpu_is_bottleneck = results.get(\"cpu_is_bottleneck\", True)\n",
        "\n",
        "    # Determinar nÃºmero de workers com base no nÃºmero de CPUs\n",
        "    cpu_count = multiprocessing.cpu_count()\n",
        "    recommended_workers = max(1, cpu_count - 1)  # Deixar 1 CPU livre para OS\n",
        "\n",
        "    # Criar configuraÃ§Ã£o\n",
        "    config = {\n",
        "        \"batch_size\": batch_size,\n",
        "        \"subbatch_size\": subbatch_size,\n",
        "        \"parallel_workers\": recommended_workers,\n",
        "        \"cpu_is_bottleneck\": cpu_is_bottleneck,\n",
        "        \"gpu_memory_fraction\": 0.9,  # Usar 90% da memÃ³ria GPU\n",
        "        \"timestamp\": time.time()\n",
        "    }\n",
        "\n",
        "    # Salvar em arquivo\n",
        "    try:\n",
        "        with open(\"mining_config.json\", \"w\") as f:\n",
        "            json.dump(config, f, indent=2)\n",
        "\n",
        "        print(\"\\nâœ… ConfiguraÃ§Ã£o otimizada salva em mining_config.json\")\n",
        "        print(f\"   BATCH_SIZE = {batch_size}\")\n",
        "        print(f\"   SUBBATCH_SIZE = {subbatch_size}\")\n",
        "        print(f\"   PARALLEL_WORKERS = {recommended_workers}\")\n",
        "\n",
        "        # Gerar cÃ³digo para incluir no script\n",
        "        print(\"\\nðŸ“‹ Adicione este cÃ³digo ao seu script:\")\n",
        "        print(\"-\" * 60)\n",
        "        print(f\"BATCH_SIZE = {batch_size} if HAS_CUDA else 8192\")\n",
        "        print(f\"SUBBATCH_SIZE = {subbatch_size} if HAS_CUDA else 2**20\")\n",
        "        print(f\"MAX_PARALLEL_WORKERS = {recommended_workers}\")\n",
        "        print(\"-\" * 60)\n",
        "\n",
        "        return config\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Erro ao salvar configuraÃ§Ã£o: {e}\")\n",
        "        return None\n",
        "\n",
        "def main():\n",
        "    print(\"=\" * 60)\n",
        "    print(\"ðŸš€ OTIMIZADOR DE AMBIENTE DE MINERAÃ‡ÃƒO\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # Verificar ambiente\n",
        "    is_colab = check_environment()\n",
        "\n",
        "    # Atualizar configuraÃ§Ãµes\n",
        "    update_runtime_config()\n",
        "\n",
        "    # Otimizar configuraÃ§Ãµes NVIDIA se possÃ­vel\n",
        "    if is_colab:\n",
        "        optimize_nvidia_settings()\n",
        "\n",
        "    # Gerar configuraÃ§Ã£o otimizada\n",
        "    config = generate_optimized_config()\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"âœ… OTIMIZAÃ‡ÃƒO CONCLUÃDA\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # Mostrar prÃ³ximos passos\n",
        "    print(\"\\nâ­ï¸ PrÃ³ximos passos:\")\n",
        "    print(\"1. Execute o minerador com as configuraÃ§Ãµes otimizadas\")\n",
        "    print(\"2. Monitore o desempenho para verificar se as otimizaÃ§Ãµes foram eficazes\")\n",
        "    print(\"3. Se necessÃ¡rio, ajuste os parÃ¢metros manualmente\")\n",
        "\n",
        "    if is_colab:\n",
        "        print(\"\\nâš ï¸ Lembre-se: No Colab, vocÃª pode precisar reiniciar o runtime\")\n",
        "        print(\"   para que algumas configuraÃ§Ãµes tenham efeito.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "gV5U5KgJFZ1v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Gerador paralelo otimizado de endereÃ§os Bitcoin para melhorar o desempenho do minerador\n",
        "Resolve o gargalo identificado no teste de batch size (geraÃ§Ã£o de endereÃ§os na CPU)\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "import time\n",
        "import multiprocessing\n",
        "from concurrent.futures import ProcessPoolExecutor\n",
        "from coincurve import PublicKey\n",
        "import hashlib\n",
        "import sys\n",
        "\n",
        "# Verificar se temos suporte a RIPEMD160\n",
        "try:\n",
        "    from Crypto.Hash import RIPEMD160\n",
        "    HAS_PYCRYPTO = True\n",
        "except ImportError:\n",
        "    HAS_PYCRYPTO = False\n",
        "    try:\n",
        "        # Tentar instalar\n",
        "        import subprocess\n",
        "        print(\"ðŸ”„ Instalando pycryptodome para suporte RIPEMD160...\")\n",
        "        subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"pycryptodome\"], check=True)\n",
        "        from Crypto.Hash import RIPEMD160\n",
        "        HAS_PYCRYPTO = True\n",
        "    except:\n",
        "        HAS_PYCRYPTO = False\n",
        "\n",
        "def sha256(data):\n",
        "    \"\"\"Calcula SHA-256\"\"\"\n",
        "    return hashlib.sha256(data).digest()\n",
        "\n",
        "def ripemd160(data):\n",
        "    \"\"\"Calcula RIPEMD-160 com suporte a diferentes implementaÃ§Ãµes\"\"\"\n",
        "    if HAS_PYCRYPTO:\n",
        "        h = RIPEMD160.new()\n",
        "        h.update(data)\n",
        "        return h.digest()\n",
        "    else:\n",
        "        # Usar hashlib ou implementaÃ§Ã£o alternativa\n",
        "        # Aviso: O hashlib padrÃ£o pode nÃ£o suportar RIPEMD160\n",
        "        import hashlib\n",
        "        try:\n",
        "            h = hashlib.new('ripemd160')\n",
        "            h.update(data)\n",
        "            return h.digest()\n",
        "        except:\n",
        "            # Ãšltimo recurso, usar SHA-1 (NÃƒO RECOMENDADO para produÃ§Ã£o!)\n",
        "            print(\"âš ï¸ AVISO: Usando SHA-1 como substituto para RIPEMD160 (nÃ£o seguro)\")\n",
        "            return hashlib.sha1(data).digest()\n",
        "\n",
        "def hash160(public_key):\n",
        "    \"\"\"ImplementaÃ§Ã£o padrÃ£o Bitcoin: SHA-256 seguido de RIPEMD-160\"\"\"\n",
        "    h = sha256(public_key)\n",
        "    return ripemd160(h)\n",
        "\n",
        "def generate_bitcoin_address(private_key):\n",
        "    \"\"\"\n",
        "    Gera um endereÃ§o Bitcoin a partir de uma chave privada.\n",
        "\n",
        "    Args:\n",
        "        private_key: Chave privada em formato nÃºmero inteiro\n",
        "\n",
        "    Returns:\n",
        "        ndarray: Array NumPy (20 bytes) contendo o hash160 do endereÃ§o\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Converter para bytes\n",
        "        key_hex = f\"{private_key:064x}\"\n",
        "        key_bytes = bytes.fromhex(key_hex)\n",
        "\n",
        "        # Gerar chave pÃºblica\n",
        "        public_key = PublicKey.from_valid_secret(key_bytes).format(compressed=False)[1:]\n",
        "\n",
        "        # Calcular hash160 (SHA-256 + RIPEMD-160)\n",
        "        hash_bytes = hash160(public_key)\n",
        "\n",
        "        # Retornar array NumPy\n",
        "        return np.frombuffer(hash_bytes, dtype=np.uint8)\n",
        "    except Exception:\n",
        "        # Retornar zeros em caso de erro\n",
        "        return np.zeros(20, dtype=np.uint8)\n",
        "\n",
        "def process_key_chunk(key_chunk, chunk_idx=0):\n",
        "    \"\"\"\n",
        "    Processa um conjunto de chaves em paralelo.\n",
        "\n",
        "    Args:\n",
        "        key_chunk: Lista de chaves privadas\n",
        "        chunk_idx: Ãndice do chunk (para logging)\n",
        "\n",
        "    Returns:\n",
        "        ndarray: Array NumPy (n_keys, 20) contendo os hash160 dos endereÃ§os\n",
        "    \"\"\"\n",
        "    n_keys = len(key_chunk)\n",
        "    addresses = np.zeros((n_keys, 20), dtype=np.uint8)\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    for i, key in enumerate(key_chunk):\n",
        "        try:\n",
        "            addresses[i] = generate_bitcoin_address(key)\n",
        "        except Exception as e:\n",
        "            # Manter zeros em caso de erro\n",
        "            if i % 1000 == 0:\n",
        "                print(f\"âš ï¸ Erro no chunk {chunk_idx}, key {i}: {e}\")\n",
        "\n",
        "    elapsed = time.time() - start_time\n",
        "    rate = n_keys / elapsed if elapsed > 0 else 0\n",
        "\n",
        "    if chunk_idx % 10 == 0:  # Reduzir o volume de logs\n",
        "        print(f\"âœ… Chunk {chunk_idx}: {n_keys} endereÃ§os em {elapsed:.2f}s ({rate:.0f}/s)\")\n",
        "\n",
        "    return addresses\n",
        "\n",
        "def generate_addresses_parallel(keys, max_workers=None, chunk_size=1000):\n",
        "    \"\"\"\n",
        "    Gera endereÃ§os Bitcoin em paralelo para um conjunto de chaves.\n",
        "\n",
        "    Args:\n",
        "        keys: Lista de chaves privadas\n",
        "        max_workers: NÃºmero mÃ¡ximo de workers (None = auto, baseado em CPU cores)\n",
        "        chunk_size: Tamanho do chunk para cada worker processar\n",
        "\n",
        "    Returns:\n",
        "        ndarray: Array NumPy (n_keys, 20) contendo os hash160 dos endereÃ§os\n",
        "    \"\"\"\n",
        "    if max_workers is None:\n",
        "        # Usar nÃºmero de CPUs disponÃ­veis, menos 1 para nÃ£o travar o sistema\n",
        "        max_workers = max(1, multiprocessing.cpu_count() - 1)\n",
        "\n",
        "    n_keys = len(keys)\n",
        "    print(f\"ðŸ”„ Gerando {n_keys} endereÃ§os com {max_workers} workers em paralelo...\")\n",
        "\n",
        "    # Criar array para resultado final\n",
        "    all_addresses = np.zeros((n_keys, 20), dtype=np.uint8)\n",
        "\n",
        "    # Dividir as chaves em chunks\n",
        "    if chunk_size <= 0:\n",
        "        chunk_size = max(1, n_keys // (max_workers * 2))\n",
        "\n",
        "    chunks = []\n",
        "    for i in range(0, n_keys, chunk_size):\n",
        "        end = min(i + chunk_size, n_keys)\n",
        "        chunks.append(keys[i:end])\n",
        "\n",
        "    n_chunks = len(chunks)\n",
        "    print(f\"ðŸ“Š Processando {n_chunks} chunks de {chunk_size} chaves cada\")\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    try:\n",
        "        # Usar ProcessPoolExecutor para paralelismo real (multiprocessamento)\n",
        "        with ProcessPoolExecutor(max_workers=max_workers) as executor:\n",
        "            futures = []\n",
        "\n",
        "            # Submeter todos os chunks para processamento\n",
        "            for i, chunk in enumerate(chunks):\n",
        "                futures.append(executor.submit(process_key_chunk, chunk, i))\n",
        "\n",
        "            # Coletar resultados na ordem\n",
        "            for i, future in enumerate(futures):\n",
        "                try:\n",
        "                    # Obter resultado do chunk\n",
        "                    addresses = future.result()\n",
        "\n",
        "                    # Copiar para o array final\n",
        "                    start_idx = i * chunk_size\n",
        "                    end_idx = min(start_idx + len(addresses), n_keys)\n",
        "                    all_addresses[start_idx:end_idx] = addresses\n",
        "                except Exception as e:\n",
        "                    print(f\"âŒ Erro ao processar chunk {i}: {e}\")\n",
        "\n",
        "    except KeyboardInterrupt:\n",
        "        print(\"âš ï¸ Interrompido pelo usuÃ¡rio\")\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Erro no processamento paralelo: {e}\")\n",
        "\n",
        "        # Tentar abordagem sequencial como fallback\n",
        "        print(\"âš ï¸ Tentando processamento sequencial como fallback...\")\n",
        "        for i, key in enumerate(keys):\n",
        "            try:\n",
        "                all_addresses[i] = generate_bitcoin_address(key)\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "    elapsed = time.time() - start_time\n",
        "    rate = n_keys / elapsed if elapsed > 0 else 0\n",
        "\n",
        "    print(f\"âœ… GeraÃ§Ã£o paralela concluÃ­da: {n_keys} endereÃ§os em {elapsed:.2f}s\")\n",
        "    print(f\"ðŸ“Š Taxa: {rate:.0f} endereÃ§os/s ({rate/1e6:.2f} Mend/s)\")\n",
        "\n",
        "    return all_addresses\n",
        "\n",
        "def test_performance(n_keys=10000):\n",
        "    \"\"\"Executa um teste de desempenho da geraÃ§Ã£o paralela de endereÃ§os.\"\"\"\n",
        "    print(\"=\" * 60)\n",
        "    print(\"ðŸš€ TESTE DE DESEMPENHO - GERAÃ‡ÃƒO PARALELA DE ENDEREÃ‡OS\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # Gerar chaves aleatÃ³rias para teste\n",
        "    print(f\"ðŸ”„ Gerando {n_keys} chaves aleatÃ³rias...\")\n",
        "    keys = [int.from_bytes(np.random.bytes(32), 'big') % (2**256 - 2**32 - 977) + 1\n",
        "            for _ in range(n_keys)]\n",
        "\n",
        "    # Teste sequencial\n",
        "    print(\"\\nðŸ”„ Teste sequencial:\")\n",
        "    start_time = time.time()\n",
        "    addresses_seq = np.zeros((n_keys, 20), dtype=np.uint8)\n",
        "    for i, key in enumerate(keys):\n",
        "        addresses_seq[i] = generate_bitcoin_address(key)\n",
        "    seq_elapsed = time.time() - start_time\n",
        "    seq_rate = n_keys / seq_elapsed\n",
        "\n",
        "    print(f\"âœ… Sequencial: {seq_elapsed:.2f}s ({seq_rate:.0f} end/s)\")\n",
        "\n",
        "    # Teste com diferentes nÃºmeros de workers\n",
        "    for workers in [2, 4, 8, 16]:\n",
        "        if workers > multiprocessing.cpu_count():\n",
        "            continue  # Pular se nÃ£o tivermos CPUs suficientes\n",
        "\n",
        "        print(f\"\\nðŸ”„ Teste paralelo com {workers} workers:\")\n",
        "        start_time = time.time()\n",
        "        addresses_par = generate_addresses_parallel(keys, max_workers=workers)\n",
        "        par_elapsed = time.time() - start_time\n",
        "        par_rate = n_keys / par_elapsed\n",
        "\n",
        "        # Verificar se os resultados sÃ£o iguais\n",
        "        matches = np.sum(np.all(addresses_seq == addresses_par, axis=1))\n",
        "        accuracy = (matches / n_keys) * 100\n",
        "\n",
        "        speedup = seq_elapsed / par_elapsed if par_elapsed > 0 else 0\n",
        "        print(f\"âœ… Paralelo: {par_elapsed:.2f}s ({par_rate:.0f} end/s)\")\n",
        "        print(f\"ðŸ“Š Speedup: {speedup:.1f}x | PrecisÃ£o: {accuracy:.2f}%\")\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Executar teste de desempenho se for chamado diretamente\n",
        "    test_performance(n_keys=20000)\n"
      ],
      "metadata": {
        "id": "oIjwB0TqFqGO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "MÃ³dulo auxiliar para processamento paralelo de endereÃ§os Bitcoin\n",
        "Resolve o erro de pickling em funÃ§Ãµes aninhadas\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "from coincurve import PublicKey\n",
        "import hashlib\n",
        "\n",
        "# FunÃ§Ãµes de hashing tÃªm que estar no escopo global para serem pickable\n",
        "def sha256(data):\n",
        "    \"\"\"Calcula SHA-256\"\"\"\n",
        "    return hashlib.sha256(data).digest()\n",
        "\n",
        "def ripemd160(data):\n",
        "    \"\"\"Calcula RIPEMD-160 com suporte a diferentes implementaÃ§Ãµes\"\"\"\n",
        "    try:\n",
        "        from Crypto.Hash import RIPEMD160\n",
        "        h = RIPEMD160.new()\n",
        "        h.update(data)\n",
        "        return h.digest()\n",
        "    except ImportError:\n",
        "        # Fallback para hashlib se disponÃ­vel\n",
        "        try:\n",
        "            h = hashlib.new('ripemd160')\n",
        "            h.update(data)\n",
        "            return h.digest()\n",
        "        except:\n",
        "            # Ãšltimo recurso (nÃ£o recomendado para produÃ§Ã£o)\n",
        "            return hashlib.sha1(data).digest()\n",
        "\n",
        "def bitcoin_hash160(public_key):\n",
        "    \"\"\"ImplementaÃ§Ã£o padrÃ£o Bitcoin: SHA-256 seguido de RIPEMD-160\"\"\"\n",
        "    h = sha256(public_key)\n",
        "    return ripemd160(h)\n",
        "\n",
        "def process_keys_chunk(chunk_data):\n",
        "    \"\"\"\n",
        "    Processa um conjunto de chaves em paralelo.\n",
        "\n",
        "    Args:\n",
        "        chunk_data: Tupla (keys, start_idx, end_idx)\n",
        "\n",
        "    Returns:\n",
        "        ndarray: Array NumPy contendo os hash160 dos endereÃ§os\n",
        "    \"\"\"\n",
        "    keys, start_idx, end_idx = chunk_data\n",
        "    chunk_size = end_idx - start_idx\n",
        "    addresses = np.zeros((chunk_size, 20), dtype=np.uint8)\n",
        "\n",
        "    # PrÃ©-inicializar objetos para evitar recriaÃ§Ã£o constante\n",
        "    try:\n",
        "        from Crypto.Hash import RIPEMD160\n",
        "        ripemd = RIPEMD160.new\n",
        "        has_pycrypto = True\n",
        "\n",
        "        # PrÃ©-inicializar funÃ§Ã£o PublicKey para melhor performance\n",
        "        from coincurve import PublicKey\n",
        "        get_public_key = lambda priv_bytes: PublicKey.from_valid_secret(priv_bytes).format(compressed=False)[1:]\n",
        "\n",
        "        # PrÃ©-inicializar SHA256\n",
        "        import hashlib\n",
        "        sha256_func = hashlib.sha256\n",
        "    except ImportError:\n",
        "        has_pycrypto = False\n",
        "\n",
        "    # OtimizaÃ§Ã£o: Processar em blocos para melhorar cache locality\n",
        "    block_size = 128  # Tamanho do bloco\n",
        "\n",
        "    for block_start in range(0, chunk_size, block_size):\n",
        "        block_end = min(block_start + block_size, chunk_size)\n",
        "\n",
        "        # Processar bloco\n",
        "        for i in range(block_start, block_end):\n",
        "            idx = i + start_idx\n",
        "            if idx >= len(keys):\n",
        "                break\n",
        "\n",
        "            try:\n",
        "                key = keys[idx]\n",
        "                # Converter para bytes e calcular endereÃ§o\n",
        "                key_hex = f\"{key:064x}\"\n",
        "                pk_bytes = bytes.fromhex(key_hex)\n",
        "\n",
        "                # Criar chave pÃºblica (sem copiar dados desnecessÃ¡rios)\n",
        "                public_key = get_public_key(pk_bytes)\n",
        "\n",
        "                # Hash SHA-256 otimizado\n",
        "                h = sha256_func(public_key).digest()\n",
        "\n",
        "                # RIPEMD-160 otimizado\n",
        "                if has_pycrypto:\n",
        "                    # VersÃ£o mais rÃ¡pida com pycryptodome\n",
        "                    r = ripemd()\n",
        "                    r.update(h)\n",
        "                    hash_bytes = r.digest()\n",
        "                else:\n",
        "                    hash_bytes = ripemd160(h)\n",
        "\n",
        "                # Armazenar resultado sem cÃ³pias desnecessÃ¡rias\n",
        "                addresses[i] = np.frombuffer(hash_bytes, dtype=np.uint8)\n",
        "            except Exception:\n",
        "                # Manter zeros em caso de erro\n",
        "                pass\n",
        "\n",
        "    return addresses\n",
        "\n",
        "def batch_generate_addresses(keys, max_workers=8, chunk_size=None):\n",
        "    \"\"\"\n",
        "    FunÃ§Ã£o wrapper para facilitar o uso do processamento paralelo\n",
        "\n",
        "    Args:\n",
        "        keys: Lista de chaves privadas\n",
        "        max_workers: NÃºmero mÃ¡ximo de workers\n",
        "        chunk_size: Tamanho de cada chunk (se None, calcula automaticamente)\n",
        "\n",
        "    Returns:\n",
        "        ndarray: Array NumPy (n_keys, 20) contendo os hash160 dos endereÃ§os\n",
        "    \"\"\"\n",
        "    from concurrent.futures import ProcessPoolExecutor\n",
        "    import multiprocessing\n",
        "    import os\n",
        "\n",
        "    # Definir variÃ¡veis de ambiente para melhorar performance das libs\n",
        "    os.environ[\"OMP_NUM_THREADS\"] = \"1\"  # Evitar que numpy crie threads em cada processo\n",
        "\n",
        "    if max_workers is None or max_workers <= 0:\n",
        "        max_workers = max(1, multiprocessing.cpu_count())\n",
        "\n",
        "    batch_size = len(keys)\n",
        "    addresses = np.zeros((batch_size, 20), dtype=np.uint8)\n",
        "\n",
        "    # Calcular tamanho dos chunks - otimizado para reduzir overhead\n",
        "    if chunk_size is None:\n",
        "        # Para A100, mais workers com chunks menores funcionam melhor\n",
        "        chunk_size = 2000  # Valor otimizado para A100\n",
        "\n",
        "    # Preparar chunks para processamento\n",
        "    chunks_data = []\n",
        "    for start in range(0, batch_size, chunk_size):\n",
        "        end = min(start + chunk_size, batch_size)\n",
        "        chunks_data.append((keys, start, end))\n",
        "\n",
        "    # OtimizaÃ§Ã£o: usar start_method='spawn' para evitar problemas de fork\n",
        "    context = multiprocessing.get_context('spawn')\n",
        "\n",
        "    # Processar em paralelo com um timeout maior e controle de falhas\n",
        "    with ProcessPoolExecutor(max_workers=max_workers, mp_context=context) as executor:\n",
        "        try:\n",
        "            # Usar chunksize=1 para melhor balanceamento\n",
        "            results = list(executor.map(process_keys_chunk, chunks_data, chunksize=1, timeout=180))\n",
        "        except Exception as e:\n",
        "            # Em caso de falha, processar sequencialmente\n",
        "            print(f\"âš ï¸ Falha no processamento paralelo: {e}\")\n",
        "            print(f\"âš ï¸ Tentando mÃ©todo sequencial...\")\n",
        "            addresses = np.zeros((len(keys), 20), dtype=np.uint8)\n",
        "            for i, key in enumerate(keys):\n",
        "                try:\n",
        "                    key_hex = f\"{key:064x}\"\n",
        "                    pk_bytes = bytes.fromhex(key_hex)\n",
        "                    public_key = PublicKey.from_valid_secret(pk_bytes).format(compressed=False)[1:]\n",
        "                    hash_bytes = bitcoin_hash160(public_key)\n",
        "                    addresses[i] = np.frombuffer(hash_bytes, dtype=np.uint8)\n",
        "                except Exception:\n",
        "                    pass  # Manter zeros em caso de erro\n",
        "            return addresses\n",
        "\n",
        "    # Unificar resultados\n",
        "    for i, chunk_result in enumerate(results):\n",
        "        start_idx = i * chunk_size\n",
        "        end_idx = min(start_idx + chunk_size, batch_size)\n",
        "        if start_idx < batch_size:  # Verificar limites\n",
        "            actual_chunk_size = min(chunk_size, batch_size - start_idx)\n",
        "            addresses[start_idx:end_idx] = chunk_result[:actual_chunk_size]\n",
        "\n",
        "    return addresses\n"
      ],
      "metadata": {
        "id": "f6MZG65dnMED"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!apt install batch_generate_addresses"
      ],
      "metadata": {
        "id": "L4eAvrcWpre_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "MÃ³dulo para prÃ©-computaÃ§Ã£o de endereÃ§os Bitcoin em background\n",
        "Implementa um modelo produtor-consumidor para reduzir o gargalo de CPU\n",
        "\"\"\"\n",
        "import threading\n",
        "import queue\n",
        "import time\n",
        "import numpy as np\n",
        "# from fixed_multiprocess import batch_generate_addresses\n",
        "import multiprocessing\n",
        "\n",
        "class AddressPrecomputer:\n",
        "    \"\"\"\n",
        "    Classe para prÃ©-computar endereÃ§os Bitcoin em threads de background.\n",
        "    Usa um modelo produtor-consumidor para alimentar o processamento GPU.\n",
        "    \"\"\"\n",
        "    def __init__(self, batch_size=32768, buffer_size=3, max_workers=None):\n",
        "        \"\"\"\n",
        "        Inicializa o sistema de prÃ©-computaÃ§Ã£o de endereÃ§os.\n",
        "\n",
        "        Args:\n",
        "            batch_size: Tamanho de cada lote de endereÃ§os\n",
        "            buffer_size: NÃºmero de lotes prÃ©-computados a manter em buffer\n",
        "            max_workers: NÃºmero mÃ¡ximo de workers para o processamento paralelo\n",
        "        \"\"\"\n",
        "        self.batch_size = batch_size\n",
        "        self.address_queue = queue.Queue(maxsize=buffer_size)\n",
        "        self.stop_event = threading.Event()\n",
        "        self.max_workers = max_workers or max(1, multiprocessing.cpu_count() - 1)\n",
        "        self.producer_thread = None\n",
        "        self.active = False\n",
        "\n",
        "        # EstatÃ­sticas\n",
        "        self.total_generated = 0\n",
        "        self.total_consumed = 0\n",
        "        self.start_time = 0\n",
        "\n",
        "    def start(self, range_start, range_end):\n",
        "        \"\"\"\n",
        "        Inicia o thread produtor para gerar endereÃ§os em background.\n",
        "\n",
        "        Args:\n",
        "            range_start: InÃ­cio do intervalo de chaves\n",
        "            range_end: Fim do intervalo de chaves\n",
        "        \"\"\"\n",
        "        if self.active:\n",
        "            return\n",
        "\n",
        "        self.range_start = range_start\n",
        "        self.range_end = range_end\n",
        "        self.stop_event.clear()\n",
        "        self.active = True\n",
        "        self.start_time = time.time()\n",
        "\n",
        "        # Iniciar thread produtor\n",
        "        self.producer_thread = threading.Thread(\n",
        "            target=self._producer_task,\n",
        "            args=(range_start, range_end),\n",
        "            daemon=True\n",
        "        )\n",
        "        self.producer_thread.start()\n",
        "\n",
        "        print(f\"âœ… Iniciado prÃ©-computador de endereÃ§os com buffer de {self.address_queue.maxsize} lotes\")\n",
        "\n",
        "    def stop(self):\n",
        "        \"\"\"Para o thread produtor e limpa o buffer.\"\"\"\n",
        "        self.stop_event.set()\n",
        "        self.active = False\n",
        "\n",
        "        # Esvaziar a fila\n",
        "        while not self.address_queue.empty():\n",
        "            try:\n",
        "                self.address_queue.get_nowait()\n",
        "                self.address_queue.task_done()\n",
        "            except queue.Empty:\n",
        "                break\n",
        "\n",
        "    def _producer_task(self, range_start, range_end):\n",
        "        \"\"\"Tarefa de thread produtor que gera endereÃ§os continuamente.\"\"\"\n",
        "        # Calcular o tamanho do intervalo como bigint para evitar overflow\n",
        "        sub_size = range_end - range_start + 1\n",
        "        batch_idx = 0\n",
        "\n",
        "        # OtimizaÃ§Ã£o: usar multiprocessing.set_start_method('spawn') para evitar problemas\n",
        "        import multiprocessing\n",
        "        try:\n",
        "            multiprocessing.set_start_method('spawn', force=True)\n",
        "        except RuntimeError:\n",
        "            # JÃ¡ foi configurado\n",
        "            pass\n",
        "\n",
        "        # Verificar e informar sobre o tamanho do intervalo\n",
        "        range_too_large_for_uint32 = sub_size > 0xFFFFFFFF  # Maior que 2^32 - 1\n",
        "        range_too_large_for_uint64 = sub_size > 0xFFFFFFFFFFFFFFFF  # Maior que 2^64 - 1\n",
        "\n",
        "        if range_too_large_for_uint32:\n",
        "            if range_too_large_for_uint64:\n",
        "                print(f\"âš ï¸ Range extremamente grande: {sub_size} (> uint64, usando mÃ©todo bytes)\")\n",
        "            else:\n",
        "                print(f\"âš ï¸ Range grande: {sub_size} (> uint32, usando uint64)\")\n",
        "\n",
        "        while not self.stop_event.is_set():\n",
        "            try:\n",
        "                # Verificar se a fila jÃ¡ estÃ¡ cheia\n",
        "                if self.address_queue.qsize() >= self.address_queue.maxsize:\n",
        "                    # Pausar brevemente se o buffer estiver cheio\n",
        "                    time.sleep(0.5)\n",
        "                    continue\n",
        "\n",
        "                # Gerar chaves aleatÃ³rias - usando a estratÃ©gia apropriada para o tamanho do intervalo\n",
        "                keys = []\n",
        "\n",
        "                # EstratÃ©gia baseada no tamanho do intervalo\n",
        "                if not range_too_large_for_uint32:\n",
        "                    # CASO 1: Intervalo cabe em uint32 - usar mÃ©todo padrÃ£o randint\n",
        "                    offsets = np.random.randint(0, sub_size, size=self.batch_size, dtype=np.uint32)\n",
        "                    keys = [range_start + int(offset) for offset in offsets]\n",
        "\n",
        "                elif not range_too_large_for_uint64:\n",
        "                    # CASO 2: Intervalo maior que uint32 mas cabe em uint64\n",
        "                    try:\n",
        "                        # Primeiro, tentar usar uint64 diretamente\n",
        "                        offsets = np.random.randint(0, sub_size, size=self.batch_size, dtype=np.uint64)\n",
        "                        keys = [range_start + int(offset) for offset in offsets]\n",
        "                    except OverflowError:\n",
        "                        # Fallback para o mÃ©todo de bytes individuais\n",
        "                        for _ in range(self.batch_size):\n",
        "                            # Usar mÃ©todo bit a bit (atÃ© 64 bits)\n",
        "                            max_bits = 64\n",
        "                            random_bits = np.random.randint(0, 2, size=max_bits, dtype=np.uint8)\n",
        "                            random_value = 0\n",
        "                            for i, bit in enumerate(random_bits):\n",
        "                                if bit:\n",
        "                                    random_value |= (1 << i)\n",
        "\n",
        "                            # Aplicar mÃ³dulo para ficar no intervalo correto\n",
        "                            random_value = random_value % sub_size\n",
        "                            keys.append(range_start + random_value)\n",
        "\n",
        "                else:\n",
        "                    # CASO 3: Intervalo extremamente grande (> uint64)\n",
        "                    for _ in range(self.batch_size):\n",
        "                        # Usar mÃ©todo de bytes aleatÃ³rios (funciona para qualquer tamanho)\n",
        "                        num_bytes = (sub_size.bit_length() + 7) // 8\n",
        "                        num_bytes = max(num_bytes, 16)  # Pelo menos 16 bytes (128 bits)\n",
        "\n",
        "                        # Gerar bytes aleatÃ³rios e converter para inteiro\n",
        "                        random_bytes = np.random.bytes(num_bytes)\n",
        "                        random_value = int.from_bytes(random_bytes, byteorder='big')\n",
        "\n",
        "                        # Garantir que estÃ¡ dentro do intervalo\n",
        "                        random_value = random_value % sub_size\n",
        "                        keys.append(range_start + random_value)\n",
        "\n",
        "                # Gerar endereÃ§os em paralelo\n",
        "                start_time = time.time()\n",
        "                addresses = batch_generate_addresses(\n",
        "                    keys,\n",
        "                    max_workers=self.max_workers,\n",
        "                    chunk_size=2000  # Otimizado para A100\n",
        "                )\n",
        "                gen_time = time.time() - start_time\n",
        "\n",
        "                # Adicionar ao buffer\n",
        "                self.address_queue.put((keys, addresses, gen_time), block=True)\n",
        "\n",
        "                self.total_generated += self.batch_size\n",
        "                batch_idx += 1\n",
        "\n",
        "                rate = self.batch_size / gen_time if gen_time > 0 else 0\n",
        "                if batch_idx % 5 == 0:  # Log a cada 5 batches\n",
        "                    print(f\"ðŸ”„ PrÃ©-computado lote {batch_idx}: {rate/1e6:.2f} Mend/s (buffer: {self.address_queue.qsize()}/{self.address_queue.maxsize})\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"âš ï¸ Erro no produtor de endereÃ§os: {e}\")\n",
        "                import traceback\n",
        "                traceback.print_exc()\n",
        "                # Pausa para nÃ£o sobrecarregar em caso de erros\n",
        "                time.sleep(1.0)\n",
        "\n",
        "    def get_next_batch(self, timeout=None):\n",
        "        \"\"\"\n",
        "        Retorna o prÃ³ximo lote de endereÃ§os prÃ©-computados.\n",
        "\n",
        "        Args:\n",
        "            timeout: Tempo mÃ¡ximo de espera em segundos (None = esperar indefinidamente)\n",
        "\n",
        "        Returns:\n",
        "            tuple: (keys, addresses, generation_time) ou None se timeout\n",
        "        \"\"\"\n",
        "        if not self.active:\n",
        "            return None\n",
        "\n",
        "        try:\n",
        "            # Obter prÃ³ximo lote (bloqueia atÃ© que um esteja disponÃ­vel)\n",
        "            next_batch = self.address_queue.get(block=True, timeout=timeout)\n",
        "            self.address_queue.task_done()\n",
        "\n",
        "            # Atualizar estatÃ­sticas\n",
        "            self.total_consumed += self.batch_size\n",
        "\n",
        "            # Mostrar estatÃ­sticas gerais\n",
        "            elapsed = time.time() - self.start_time\n",
        "            if elapsed > 0:\n",
        "                avg_speed = self.total_consumed / elapsed / 1e6  # Mend/s\n",
        "                print(f\"ðŸ“Š Taxa mÃ©dia: {avg_speed:.2f} Mend/s | Gerados: {self.total_generated:,} | Consumidos: {self.total_consumed:,}\")\n",
        "\n",
        "            return next_batch\n",
        "        except queue.Empty:\n",
        "            print(\"âš ï¸ Timeout ao aguardar por endereÃ§os prÃ©-computados\")\n",
        "            return None\n",
        "\n",
        "    def get_stats(self):\n",
        "        \"\"\"Retorna estatÃ­sticas do prÃ©-computador.\"\"\"\n",
        "        elapsed = time.time() - self.start_time if self.start_time > 0 else 0\n",
        "        return {\n",
        "            \"total_generated\": self.total_generated,\n",
        "            \"total_consumed\": self.total_consumed,\n",
        "            \"elapsed_time\": elapsed,\n",
        "            \"average_speed\": self.total_consumed / elapsed if elapsed > 0 else 0,\n",
        "            \"buffer_status\": f\"{self.address_queue.qsize()}/{self.address_queue.maxsize}\"\n",
        "        }\n"
      ],
      "metadata": {
        "id": "j9y_abxLnfSE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!apt install multiprocessing"
      ],
      "metadata": {
        "id": "U9SJe-YyoD_t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Script para criar manualmente os arquivos de mÃ³dulo no Google Colab\n",
        "\"\"\"\n",
        "import os\n",
        "\n",
        "def create_fixed_multiprocess():\n",
        "    \"\"\"Cria o arquivo fixed_multiprocess.py no diretÃ³rio atual\"\"\"\n",
        "    code = '''\"\"\"\n",
        "MÃ³dulo auxiliar para processamento paralelo de endereÃ§os Bitcoin\n",
        "Resolve o erro de pickling em funÃ§Ãµes aninhadas\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "from coincurve import PublicKey\n",
        "import hashlib\n",
        "\n",
        "# FunÃ§Ãµes de hashing tÃªm que estar no escopo global para serem pickable\n",
        "def sha256(data):\n",
        "    \"\"\"Calcula SHA-256\"\"\"\n",
        "    return hashlib.sha256(data).digest()\n",
        "\n",
        "def ripemd160(data):\n",
        "    \"\"\"Calcula RIPEMD-160 com suporte a diferentes implementaÃ§Ãµes\"\"\"\n",
        "    try:\n",
        "        from Crypto.Hash import RIPEMD160\n",
        "        h = RIPEMD160.new()\n",
        "        h.update(data)\n",
        "        return h.digest()\n",
        "    except ImportError:\n",
        "        # Fallback para hashlib se disponÃ­vel\n",
        "        try:\n",
        "            h = hashlib.new('ripemd160')\n",
        "            h.update(data)\n",
        "            return h.digest()\n",
        "        except:\n",
        "            # Ãšltimo recurso (nÃ£o recomendado para produÃ§Ã£o)\n",
        "            return hashlib.sha1(data).digest()\n",
        "\n",
        "def bitcoin_hash160(public_key):\n",
        "    \"\"\"ImplementaÃ§Ã£o padrÃ£o Bitcoin: SHA-256 seguido de RIPEMD-160\"\"\"\n",
        "    h = sha256(public_key)\n",
        "    return ripemd160(h)\n",
        "\n",
        "def process_keys_chunk(chunk_data):\n",
        "    \"\"\"\n",
        "    Processa um conjunto de chaves em paralelo.\n",
        "\n",
        "    Args:\n",
        "        chunk_data: Tupla (keys, start_idx, end_idx)\n",
        "\n",
        "    Returns:\n",
        "        ndarray: Array NumPy contendo os hash160 dos endereÃ§os\n",
        "    \"\"\"\n",
        "    keys, start_idx, end_idx = chunk_data\n",
        "    chunk_size = end_idx - start_idx\n",
        "    addresses = np.zeros((chunk_size, 20), dtype=np.uint8)\n",
        "\n",
        "    # PrÃ©-inicializar objetos para evitar recriaÃ§Ã£o constante\n",
        "    try:\n",
        "        from Crypto.Hash import RIPEMD160\n",
        "        ripemd = RIPEMD160.new\n",
        "        has_pycrypto = True\n",
        "\n",
        "        # PrÃ©-inicializar funÃ§Ã£o PublicKey para melhor performance\n",
        "        from coincurve import PublicKey\n",
        "        get_public_key = lambda priv_bytes: PublicKey.from_valid_secret(priv_bytes).format(compressed=False)[1:]\n",
        "\n",
        "        # PrÃ©-inicializar SHA256\n",
        "        import hashlib\n",
        "        sha256_func = hashlib.sha256\n",
        "    except ImportError:\n",
        "        has_pycrypto = False\n",
        "\n",
        "    # OtimizaÃ§Ã£o: Processar em blocos para melhorar cache locality\n",
        "    block_size = 128  # Tamanho do bloco\n",
        "\n",
        "    for block_start in range(0, chunk_size, block_size):\n",
        "        block_end = min(block_start + block_size, chunk_size)\n",
        "\n",
        "        # Processar bloco\n",
        "        for i in range(block_start, block_end):\n",
        "            idx = i + start_idx\n",
        "            if idx >= len(keys):\n",
        "                break\n",
        "\n",
        "            try:\n",
        "                key = keys[idx]\n",
        "                # Converter para bytes e calcular endereÃ§o\n",
        "                key_hex = f\"{key:064x}\"\n",
        "                pk_bytes = bytes.fromhex(key_hex)\n",
        "\n",
        "                # Criar chave pÃºblica (sem copiar dados desnecessÃ¡rios)\n",
        "                public_key = get_public_key(pk_bytes)\n",
        "\n",
        "                # Hash SHA-256 otimizado\n",
        "                h = sha256_func(public_key).digest()\n",
        "\n",
        "                # RIPEMD-160 otimizado\n",
        "                if has_pycrypto:\n",
        "                    # VersÃ£o mais rÃ¡pida com pycryptodome\n",
        "                    r = ripemd()\n",
        "                    r.update(h)\n",
        "                    hash_bytes = r.digest()\n",
        "                else:\n",
        "                    hash_bytes = ripemd160(h)\n",
        "\n",
        "                # Armazenar resultado sem cÃ³pias desnecessÃ¡rias\n",
        "                addresses[i] = np.frombuffer(hash_bytes, dtype=np.uint8)\n",
        "            except Exception:\n",
        "                # Manter zeros em caso de erro\n",
        "                pass\n",
        "\n",
        "    return addresses\n",
        "\n",
        "def batch_generate_addresses(keys, max_workers=8, chunk_size=None):\n",
        "    \"\"\"\n",
        "    FunÃ§Ã£o wrapper para facilitar o uso do processamento paralelo\n",
        "\n",
        "    Args:\n",
        "        keys: Lista de chaves privadas\n",
        "        max_workers: NÃºmero mÃ¡ximo de workers\n",
        "        chunk_size: Tamanho de cada chunk (se None, calcula automaticamente)\n",
        "\n",
        "    Returns:\n",
        "        ndarray: Array NumPy (n_keys, 20) contendo os hash160 dos endereÃ§os\n",
        "    \"\"\"\n",
        "    from concurrent.futures import ProcessPoolExecutor\n",
        "    import multiprocessing\n",
        "    import os\n",
        "\n",
        "    # Definir variÃ¡veis de ambiente para melhorar performance das libs\n",
        "    os.environ[\"OMP_NUM_THREADS\"] = \"1\"  # Evitar que numpy crie threads em cada processo\n",
        "\n",
        "    if max_workers is None or max_workers <= 0:\n",
        "        max_workers = max(1, multiprocessing.cpu_count())\n",
        "\n",
        "    batch_size = len(keys)\n",
        "    addresses = np.zeros((batch_size, 20), dtype=np.uint8)\n",
        "\n",
        "    # Calcular tamanho dos chunks - otimizado para reduzir overhead\n",
        "    if chunk_size is None:\n",
        "        # Para A100, mais workers com chunks menores funcionam melhor\n",
        "        chunk_size = 2000  # Valor otimizado para A100\n",
        "\n",
        "    # Preparar chunks para processamento\n",
        "    chunks_data = []\n",
        "    for start in range(0, batch_size, chunk_size):\n",
        "        end = min(start + chunk_size, batch_size)\n",
        "        chunks_data.append((keys, start, end))\n",
        "\n",
        "    # OtimizaÃ§Ã£o: usar start_method='spawn' para evitar problemas de fork\n",
        "    context = multiprocessing.get_context('spawn')\n",
        "\n",
        "    # Processar em paralelo com um timeout maior e controle de falhas\n",
        "    with ProcessPoolExecutor(max_workers=max_workers, mp_context=context) as executor:\n",
        "        try:\n",
        "            # Usar chunksize=1 para melhor balanceamento\n",
        "            results = list(executor.map(process_keys_chunk, chunks_data, chunksize=1, timeout=180))\n",
        "        except Exception as e:\n",
        "            # Em caso de falha, processar sequencialmente\n",
        "            print(f\"âš ï¸ Falha no processamento paralelo: {e}\")\n",
        "            print(f\"âš ï¸ Tentando mÃ©todo sequencial...\")\n",
        "            addresses = np.zeros((len(keys), 20), dtype=np.uint8)\n",
        "            for i, key in enumerate(keys):\n",
        "                try:\n",
        "                    key_hex = f\"{key:064x}\"\n",
        "                    pk_bytes = bytes.fromhex(key_hex)\n",
        "                    public_key = PublicKey.from_valid_secret(pk_bytes).format(compressed=False)[1:]\n",
        "                    hash_bytes = bitcoin_hash160(public_key)\n",
        "                    addresses[i] = np.frombuffer(hash_bytes, dtype=np.uint8)\n",
        "                except Exception:\n",
        "                    pass  # Manter zeros em caso de erro\n",
        "            return addresses\n",
        "\n",
        "    # Unificar resultados\n",
        "    for i, chunk_result in enumerate(results):\n",
        "        start_idx = i * chunk_size\n",
        "        end_idx = min(start_idx + chunk_size, batch_size)\n",
        "        if start_idx < batch_size:  # Verificar limites\n",
        "            actual_chunk_size = min(chunk_size, batch_size - start_idx)\n",
        "            addresses[start_idx:end_idx] = chunk_result[:actual_chunk_size]\n",
        "\n",
        "    return addresses\n",
        "'''\n",
        "\n",
        "    with open(\"fixed_multiprocess.py\", \"w\") as f:\n",
        "        f.write(code)\n",
        "\n",
        "    print(\"âœ… Arquivo fixed_multiprocess.py criado com sucesso no diretÃ³rio atual.\")\n",
        "\n",
        "def create_address_precomputing():\n",
        "    \"\"\"Cria o arquivo address_precomputing.py no diretÃ³rio atual\"\"\"\n",
        "    code = '''\"\"\"\n",
        "MÃ³dulo para prÃ©-computaÃ§Ã£o de endereÃ§os Bitcoin em background\n",
        "Implementa um modelo produtor-consumidor para reduzir o gargalo de CPU\n",
        "\"\"\"\n",
        "import threading\n",
        "import queue\n",
        "import time\n",
        "import numpy as np\n",
        "from fixed_multiprocess import batch_generate_addresses\n",
        "import multiprocessing\n",
        "\n",
        "class AddressPrecomputer:\n",
        "    \"\"\"\n",
        "    Classe para prÃ©-computar endereÃ§os Bitcoin em threads de background.\n",
        "    Usa um modelo produtor-consumidor para alimentar o processamento GPU.\n",
        "    \"\"\"\n",
        "    def __init__(self, batch_size=32768, buffer_size=3, max_workers=None):\n",
        "        \"\"\"\n",
        "        Inicializa o sistema de prÃ©-computaÃ§Ã£o de endereÃ§os.\n",
        "\n",
        "        Args:\n",
        "            batch_size: Tamanho de cada lote de endereÃ§os\n",
        "            buffer_size: NÃºmero de lotes prÃ©-computados a manter em buffer\n",
        "            max_workers: NÃºmero mÃ¡ximo de workers para o processamento paralelo\n",
        "        \"\"\"\n",
        "        self.batch_size = batch_size\n",
        "        self.address_queue = queue.Queue(maxsize=buffer_size)\n",
        "        self.stop_event = threading.Event()\n",
        "        self.max_workers = max_workers or max(1, multiprocessing.cpu_count() - 1)\n",
        "        self.producer_thread = None\n",
        "        self.active = False\n",
        "\n",
        "        # EstatÃ­sticas\n",
        "        self.total_generated = 0\n",
        "        self.total_consumed = 0\n",
        "        self.start_time = 0\n",
        "\n",
        "    def start(self, range_start, range_end):\n",
        "        \"\"\"\n",
        "        Inicia o thread produtor para gerar endereÃ§os em background.\n",
        "\n",
        "        Args:\n",
        "            range_start: InÃ­cio do intervalo de chaves\n",
        "            range_end: Fim do intervalo de chaves\n",
        "        \"\"\"\n",
        "        if self.active:\n",
        "            return\n",
        "\n",
        "        self.range_start = range_start\n",
        "        self.range_end = range_end\n",
        "        self.stop_event.clear()\n",
        "        self.active = True\n",
        "        self.start_time = time.time()\n",
        "\n",
        "        # Iniciar thread produtor\n",
        "        self.producer_thread = threading.Thread(\n",
        "            target=self._producer_task,\n",
        "            args=(range_start, range_end),\n",
        "            daemon=True\n",
        "        )\n",
        "        self.producer_thread.start()\n",
        "\n",
        "        print(f\"âœ… Iniciado prÃ©-computador de endereÃ§os com buffer de {self.address_queue.maxsize} lotes\")\n",
        "\n",
        "    def stop(self):\n",
        "        \"\"\"Para o thread produtor e limpa o buffer.\"\"\"\n",
        "        self.stop_event.set()\n",
        "        self.active = False\n",
        "\n",
        "        # Esvaziar a fila\n",
        "        while not self.address_queue.empty():\n",
        "            try:\n",
        "                self.address_queue.get_nowait()\n",
        "                self.address_queue.task_done()\n",
        "            except queue.Empty:\n",
        "                break\n",
        "\n",
        "    def _producer_task(self, range_start, range_end):\n",
        "        \"\"\"Tarefa de thread produtor que gera endereÃ§os continuamente.\"\"\"\n",
        "        # Calcular o tamanho do intervalo como bigint para evitar overflow\n",
        "        sub_size = range_end - range_start + 1\n",
        "        batch_idx = 0\n",
        "\n",
        "        # OtimizaÃ§Ã£o: usar multiprocessing.set_start_method('spawn') para evitar problemas\n",
        "        import multiprocessing\n",
        "        try:\n",
        "            multiprocessing.set_start_method('spawn', force=True)\n",
        "        except RuntimeError:\n",
        "            # JÃ¡ foi configurado\n",
        "            pass\n",
        "\n",
        "        # Verificar tamanho do range para determinar a estratÃ©gia\n",
        "        range_too_large = sub_size > 0xFFFFFFFF  # Maior que max uint32\n",
        "        if range_too_large:\n",
        "            print(f\"âš ï¸ Range muito grande para uint32: {sub_size} (Usando mÃ©todo alternativo)\")\n",
        "\n",
        "        while not self.stop_event.is_set():\n",
        "            try:\n",
        "                # Verificar se a fila jÃ¡ estÃ¡ cheia\n",
        "                if self.address_queue.qsize() >= self.address_queue.maxsize:\n",
        "                    # Pausar brevemente se o buffer estiver cheio\n",
        "                    time.sleep(0.5)\n",
        "                    continue\n",
        "\n",
        "                # Gerar chaves aleatÃ³rias - abordagem segura independente do tamanho\n",
        "                keys = []\n",
        "                np.random.seed()  # Renovar seed para melhor aleatoriedade\n",
        "\n",
        "                # MÃ©todo 100% seguro usando geraÃ§Ã£o de nÃºmeros diretamente\n",
        "                for _ in range(self.batch_size):\n",
        "                    # Gerar um nÃºmero aleatÃ³rio no range [0, sub_size)\n",
        "                    if range_too_large:\n",
        "                        # Para intervalos muito grandes, gerar bytes aleatÃ³rios e convertÃª-los para um inteiro\n",
        "                        # Calcular quantos bytes precisamos para representar sub_size\n",
        "                        num_bytes = (sub_size.bit_length() + 7) // 8\n",
        "\n",
        "                        # Gerar um valor aleatÃ³rio usando bytes aleatÃ³rios\n",
        "                        while True:\n",
        "                            # Gerar bytes suficientes para cobrir o range\n",
        "                            random_bytes = np.random.bytes(num_bytes)\n",
        "                            random_value = int.from_bytes(random_bytes, byteorder='little')\n",
        "\n",
        "                            # Aplicar mÃ³dulo para ficar no range correto\n",
        "                            random_value = random_value % sub_size\n",
        "\n",
        "                            if random_value < sub_size:\n",
        "                                break\n",
        "                    else:\n",
        "                        # Para intervalos menores, usar randint diretamente\n",
        "                        random_value = np.random.randint(0, sub_size, dtype=np.uint64)\n",
        "\n",
        "                    # Calcular chave final\n",
        "                    key = range_start + random_value\n",
        "                    keys.append(key)\n",
        "\n",
        "                # Gerar endereÃ§os em paralelo\n",
        "                start_time = time.time()\n",
        "                addresses = batch_generate_addresses(\n",
        "                    keys,\n",
        "                    max_workers=self.max_workers,\n",
        "                    chunk_size=2000  # Otimizado para A100\n",
        "                )\n",
        "                gen_time = time.time() - start_time\n",
        "\n",
        "                # Adicionar ao buffer\n",
        "                self.address_queue.put((keys, addresses, gen_time), block=True)\n",
        "\n",
        "                self.total_generated += self.batch_size\n",
        "                batch_idx += 1\n",
        "\n",
        "                rate = self.batch_size / gen_time if gen_time > 0 else 0\n",
        "                if batch_idx % 5 == 0:  # Log a cada 5 batches\n",
        "                    print(f\"ðŸ”„ PrÃ©-computado lote {batch_idx}: {rate/1e6:.2f} Mend/s (buffer: {self.address_queue.qsize()}/{self.address_queue.maxsize})\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"âš ï¸ Erro no produtor de endereÃ§os: {e}\")\n",
        "                import traceback\n",
        "                traceback.print_exc()\n",
        "                # Pausa para nÃ£o sobrecarregar em caso de erros\n",
        "                time.sleep(1.0)\n",
        "\n",
        "    def get_next_batch(self, timeout=None):\n",
        "        \"\"\"\n",
        "        Retorna o prÃ³ximo lote de endereÃ§os prÃ©-computados.\n",
        "\n",
        "        Args:\n",
        "            timeout: Tempo mÃ¡ximo de espera em segundos (None = esperar indefinidamente)\n",
        "\n",
        "        Returns:\n",
        "            tuple: (keys, addresses, generation_time) ou None se timeout\n",
        "        \"\"\"\n",
        "        if not self.active:\n",
        "            return None\n",
        "\n",
        "        try:\n",
        "            # Obter prÃ³ximo lote (bloqueia atÃ© que um esteja disponÃ­vel)\n",
        "            next_batch = self.address_queue.get(block=True, timeout=timeout)\n",
        "            self.address_queue.task_done()\n",
        "\n",
        "            # Atualizar estatÃ­sticas\n",
        "            self.total_consumed += self.batch_size\n",
        "\n",
        "            # Mostrar estatÃ­sticas gerais\n",
        "            elapsed = time.time() - self.start_time\n",
        "            if elapsed > 0:\n",
        "                avg_speed = self.total_consumed / elapsed / 1e6  # Mend/s\n",
        "                print(f\"ðŸ“Š Taxa mÃ©dia: {avg_speed:.2f} Mend/s | Gerados: {self.total_generated:,} | Consumidos: {self.total_consumed:,}\")\n",
        "\n",
        "            return next_batch\n",
        "        except queue.Empty:\n",
        "            print(\"âš ï¸ Timeout ao aguardar por endereÃ§os prÃ©-computados\")\n",
        "            return None\n",
        "\n",
        "    def get_stats(self):\n",
        "        \"\"\"Retorna estatÃ­sticas do prÃ©-computador.\"\"\"\n",
        "        elapsed = time.time() - self.start_time if self.start_time > 0 else 0\n",
        "        return {\n",
        "            \"total_generated\": self.total_generated,\n",
        "            \"total_consumed\": self.total_consumed,\n",
        "            \"elapsed_time\": elapsed,\n",
        "            \"average_speed\": self.total_consumed / elapsed if elapsed > 0 else 0,\n",
        "            \"buffer_status\": f\"{self.address_queue.qsize()}/{self.address_queue.maxsize}\"\n",
        "        }\n",
        "'''\n",
        "\n",
        "    with open(\"address_precomputing.py\", \"w\") as f:\n",
        "        f.write(code)\n",
        "\n",
        "    print(\"âœ… Arquivo address_precomputing.py criado com sucesso no diretÃ³rio atual.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Verificar se os arquivos jÃ¡ existem\n",
        "    if os.path.exists(\"fixed_multiprocess.py\"):\n",
        "        print(\"âš ï¸ O arquivo fixed_multiprocess.py jÃ¡ existe.\")\n",
        "        overwrite = input(\"Sobrescrever? (s/n): \").strip().lower() == 's'\n",
        "        if overwrite:\n",
        "            create_fixed_multiprocess()\n",
        "    else:\n",
        "        create_fixed_multiprocess()\n",
        "\n",
        "    if os.path.exists(\"address_precomputing.py\"):\n",
        "        print(\"âš ï¸ O arquivo address_precomputing.py jÃ¡ existe.\")\n",
        "        overwrite = input(\"Sobrescrever? (s/n): \").strip().lower() == 's'\n",
        "        if overwrite:\n",
        "            create_address_precomputing()\n",
        "    else:\n",
        "        create_address_precomputing()\n",
        "\n",
        "    print(\"\\nâœ… MÃ³dulos criados com sucesso!\")\n",
        "    print(\"   Agora vocÃª pode importÃ¡-los em seus scripts:\")\n",
        "    print(\"   from fixed_multiprocess import batch_generate_addresses\")\n",
        "    print(\"   from address_precomputing import AddressPrecomputer\")\n"
      ],
      "metadata": {
        "id": "Rq3fcA0CweJ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from fixed_multiprocess import batch_generate_addresses\n",
        "from address_precomputing import AddressPrecomputer\n"
      ],
      "metadata": {
        "id": "Ay3OX0LgwrjT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "BitcoinFlix Miner - VersÃ£o CUDA para mÃ¡ximo desempenho GPU (Alternativa)\n",
        "Usa CuPy para GPU sem depender das funÃ§Ãµes Numba que estÃ£o causando problemas de compatibilidade\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import time\n",
        "import sys\n",
        "import requests\n",
        "import numpy as np\n",
        "import base58\n",
        "from coincurve import PublicKey\n",
        "from eth_utils import keccak\n",
        "import hashlib\n",
        "import multiprocessing\n",
        "from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor\n",
        "import threading\n",
        "\n",
        "# Detecta ambiente Colab\n",
        "IS_COLAB = 'google.colab' in sys.modules\n",
        "\n",
        "# Importar CuPy com tratamento de erro\n",
        "print(\"ðŸ”„ Inicializando bibliotecas CUDA...\")\n",
        "try:\n",
        "    import cupy as cp\n",
        "    # Configurar LD_LIBRARY_PATH se necessÃ¡rio\n",
        "    if 'google.colab' in sys.modules:\n",
        "        import os\n",
        "        cuda_link_dir = '/tmp/cuda_links'\n",
        "        if os.path.exists(cuda_link_dir):\n",
        "            current_ld_path = os.environ.get('LD_LIBRARY_PATH', '')\n",
        "            if cuda_link_dir not in current_ld_path:\n",
        "                os.environ['LD_LIBRARY_PATH'] = f\"{cuda_link_dir}:{current_ld_path}\"\n",
        "                print(f\"âœ… LD_LIBRARY_PATH atualizado: {os.environ['LD_LIBRARY_PATH']}\")\n",
        "\n",
        "    HAS_CUDA = cp.cuda.is_available()\n",
        "    if HAS_CUDA:\n",
        "        # Obter informaÃ§Ãµes da GPU usando CuPy\n",
        "        dev_id = cp.cuda.Device()\n",
        "        try:\n",
        "            dev_props = cp.cuda.runtime.getDeviceProperties(dev_id.id)\n",
        "            print(f\"âœ… CUDA disponÃ­vel via CuPy: {dev_props['name'].decode()}\")\n",
        "            print(f\"   - MemÃ³ria total: {dev_props['totalGlobalMem'] / (1024**3):.2f} GB\")\n",
        "            print(f\"   - Compute capability: {dev_props['major']}.{dev_props['minor']}\")\n",
        "            print(f\"   - Multiprocessadores: {dev_props['multiProcessorCount']}\")\n",
        "        except Exception as e:\n",
        "            # Fallback para informaÃ§Ãµes bÃ¡sicas se houver erro\n",
        "            print(f\"âœ… CUDA disponÃ­vel via CuPy (informaÃ§Ãµes limitadas)\")\n",
        "            print(f\"   - Erro ao obter propriedades detalhadas: {e}\")\n",
        "            mem = cp.cuda.runtime.memGetInfo()\n",
        "            print(f\"   - MemÃ³ria livre/total: {mem[0]/1024**3:.2f}GB/{mem[1]/1024**3:.2f}GB\")\n",
        "    else:\n",
        "        print(\"âŒ CUDA nÃ£o estÃ¡ disponÃ­vel\")\n",
        "except ImportError as e:\n",
        "    HAS_CUDA = False\n",
        "    print(f\"âš ï¸ CuPy nÃ£o encontrado: {e}\")\n",
        "    print(\"âš ï¸ Execute install_cuda_deps.py para instalar as dependÃªncias necessÃ¡rias\")\n",
        "\n",
        "    # Auto-instalaÃ§Ã£o das dependÃªncias\n",
        "    if IS_COLAB:\n",
        "        print(\"\\nâš ï¸ Para corrigir os problemas CUDA, execute primeiro:\")\n",
        "        print(\"!python install_cuda_deps.py\")\n",
        "        print(\"E entÃ£o reinicie o runtime (Runtime > Restart runtime) antes de executar este script novamente.\")\n",
        "        sys.exit(1)\n",
        "\n",
        "# ImportaÃ§Ãµes para suporte RIPEMD160\n",
        "try:\n",
        "    from Crypto.Hash import RIPEMD160\n",
        "    HAS_PYCRYPTO = True\n",
        "except ImportError:\n",
        "    HAS_PYCRYPTO = False\n",
        "    print(\"âš ï¸ Crypto.Hash.RIPEMD160 nÃ£o disponÃ­vel, instalando pycryptodome...\")\n",
        "    try:\n",
        "        import subprocess\n",
        "        subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"pycryptodome\"], check=True)\n",
        "        from Crypto.Hash import RIPEMD160\n",
        "        HAS_PYCRYPTO = True\n",
        "        print(\"âœ… pycryptodome instalado com sucesso\")\n",
        "    except:\n",
        "        print(\"âŒ NÃ£o foi possÃ­vel instalar pycryptodome\")\n",
        "        HAS_PYCRYPTO = False\n",
        "\n",
        "# Adicionar endereÃ§o da Golden Key\n",
        "ADDITIONAL_ADDRESS = \"1MVDYgVaSN6iKKEsbzRUAYFrYJadLYZvvZ\"\n",
        "\n",
        "# ConfiguraÃ§Ãµes da API\n",
        "POOL_TOKEN = \"076a6a4636e1b70eb5105e609a2a9b59bcff5858f305daec5ee7b18095c6a48f\"\n",
        "API_URL = \"https://bitcoinflix.replit.app/api/big_block\"\n",
        "\n",
        "# ConfiguraÃ§Ãµes de processamento otimizadas com base nos resultados do teste de batch size\n",
        "BATCH_SIZE = 32768 if HAS_CUDA else 8192     # Aumentado para melhorar ocupaÃ§Ã£o da GPU\n",
        "SUBBATCH_SIZE = 67108864 if HAS_CUDA else 2**20  # 64M chaves por sub-lote com GPU, 1M para CPU\n",
        "GPU_MEMORY_FRACTION = 0.95    # Usar atÃ© 95% da memÃ³ria GPU disponÃ­vel\n",
        "CPU_FALLBACK = False         # Flag para forÃ§ar uso da CPU mesmo com GPU disponÃ­vel\n",
        "MAX_PARALLEL_WORKERS = 32    # Usar mais workers para A100\n",
        "PIPELINE_BUFFER_SIZE = 5     # Aumentar buffer de pipeline para manter GPU ocupada\n",
        "\n",
        "# ParÃ¢metros de otimizaÃ§Ã£o de GPU\n",
        "GPU_BATCH_SIZE = 256        # Reduzido ainda mais para aumentar o nÃºmero de kernels concorrentes\n",
        "FORCE_GPU_SYNC = True        # ForÃ§ar sincronizaÃ§Ã£o ocasional para manter GPU ativa\n",
        "GPU_WARMUP_ITERS = 10        # NÃºmero de iteraÃ§Ãµes de aquecimento inicial\n",
        "CUDA_STREAMS = 16            # Aumentado significativamente para maximum concurrency\n",
        "GPU_STRESS_ENABLE = True     # Ativar operaÃ§Ãµes de stress para aumentar clock da GPU\n",
        "INTENSIVE_MATH_OPS = True    # Ativar operaÃ§Ãµes matemÃ¡ticas intensivas\n",
        "CONTINUOUS_STRESS = True     # Ativar thread de stress contÃ­nuo\n",
        "KERNEL_LOOPS = 50            # Aumentado drasticamente para mais operaÃ§Ãµes por kernel\n",
        "MAXIMUM_OCCUPANCY = True     # Nova flag para maximizar ocupaÃ§Ã£o de SMs\n",
        "CUDA_GRAPH_ENABLE = True     # Habilitar CUDA Graphs para kernels repetitivos\n",
        "DISABLE_CACHING = True       # Desabilitar caching para forÃ§ar recomputaÃ§Ã£o\n",
        "\n",
        "# Agora podemos importar o mÃ³dulo com seguranÃ§a\n",
        "from fixed_multiprocess import batch_generate_addresses\n",
        "\n",
        "# FunÃ§Ãµes de utilidade\n",
        "def sha256(data):\n",
        "    \"\"\"Calcula SHA-256\"\"\"\n",
        "    return hashlib.sha256(data).digest()\n",
        "\n",
        "def ripemd160(data):\n",
        "    \"\"\"Calcula RIPEMD-160 com suporte a diferentes implementaÃ§Ãµes\"\"\"\n",
        "    if HAS_PYCRYPTO:\n",
        "        h = RIPEMD160.new()\n",
        "        h.update(data)\n",
        "        return h.digest()\n",
        "    else:\n",
        "        # Usar Keccak como fallback se RIPEMD160 nÃ£o estiver disponÃ­vel\n",
        "        print(\"âš ï¸ Usando Keccak como fallback para RIPEMD160 (menos compatÃ­vel)\")\n",
        "        return custom_keccak(data)[-20:]\n",
        "\n",
        "def bitcoin_hash160(public_key):\n",
        "    \"\"\"ImplementaÃ§Ã£o correta do hash160 usado no Bitcoin (SHA256 + RIPEMD160)\"\"\"\n",
        "    sha = sha256(public_key)\n",
        "    ripe = ripemd160(sha)\n",
        "    return ripe\n",
        "\n",
        "def custom_keccak(data):\n",
        "    \"\"\"Calcula Keccak-256 com tratamento de erros.\"\"\"\n",
        "    try:\n",
        "        if isinstance(data, str):\n",
        "            data = bytes.fromhex(data.replace('0x', ''))\n",
        "        return keccak(data)\n",
        "    except Exception:\n",
        "        return b'\\x00' * 32\n",
        "\n",
        "def decode_bitcoin_address(address):\n",
        "    \"\"\"Decodifica endereÃ§o Bitcoin para array numpy.\"\"\"\n",
        "    try:\n",
        "        if not address or not isinstance(address, str):\n",
        "            return None\n",
        "\n",
        "        decoded = base58.b58decode(address)\n",
        "        if len(decoded) != 25:\n",
        "            return None\n",
        "\n",
        "        hash_bytes = decoded[1:-4]\n",
        "        hash_array = np.frombuffer(hash_bytes, dtype=np.uint8)\n",
        "        return hash_array\n",
        "    except Exception as e:\n",
        "        print(f\"âš ï¸ Erro ao decodificar {address}: {e}\")\n",
        "        return None\n",
        "\n",
        "# FunÃ§Ã£o para validar se um endereÃ§o Bitcoin Ã© vÃ¡lido\n",
        "def is_valid_bitcoin_address(address):\n",
        "    \"\"\"Verifica se um endereÃ§o Bitcoin Ã© vÃ¡lido\"\"\"\n",
        "    if not address or not isinstance(address, str):\n",
        "        return False\n",
        "\n",
        "    try:\n",
        "        # Um endereÃ§o Bitcoin decodificado deve ter 25 bytes\n",
        "        # (1 byte versÃ£o + 20 bytes hash + 4 bytes checksum)\n",
        "        decoded = base58.b58decode(address)\n",
        "        if len(decoded) != 25:\n",
        "            return False\n",
        "\n",
        "        # Verificar o checksum (os Ãºltimos 4 bytes)\n",
        "        # ModificaÃ§Ã£o: usar sha256(sha256(payload)) em vez de Keccak\n",
        "        payload = decoded[:-4]\n",
        "        checksum = sha256(sha256(payload))[:4]\n",
        "        provided_checksum = decoded[-4:]\n",
        "\n",
        "        return checksum == provided_checksum\n",
        "    except Exception as e:\n",
        "        print(f\"âš ï¸ Erro na validaÃ§Ã£o do endereÃ§o {address}: {e}\")\n",
        "        return False\n",
        "\n",
        "# FunÃ§Ã£o para buscar dados do bloco\n",
        "def fetch_block_data():\n",
        "    \"\"\"Busca dados do bloco atual da API.\"\"\"\n",
        "    print(\"ðŸ”„ Buscando dados do bloco da API...\")\n",
        "    headers = {\"pool-token\": POOL_TOKEN}\n",
        "    try:\n",
        "        response = requests.get(API_URL, headers=headers)\n",
        "        if response.status_code == 200:\n",
        "            data = response.json()\n",
        "            # Processar range\n",
        "            range_data = data.get(\"range\", {})\n",
        "            start = range_data.get(\"start\", \"\").replace(\"0x\", \"\")\n",
        "            end = range_data.get(\"end\", \"\").replace(\"0x\", \"\")\n",
        "            print(f\"âœ… Range recebido: {start} atÃ© {end}\")\n",
        "\n",
        "            # Mostrar carteiras alvo\n",
        "            addresses = data.get(\"checkwork_addresses\", [])\n",
        "            print(f\"ðŸ“‹ Carteiras recebidas ({len(addresses)}):\")\n",
        "            for i, addr in enumerate(addresses):\n",
        "                if addr:\n",
        "                    print(f\"  {i+1}. {addr}\")\n",
        "\n",
        "            return data\n",
        "        else:\n",
        "            print(f\"âŒ Erro: {response.status_code} - {response.text}\")\n",
        "            return None\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Erro na requisiÃ§Ã£o: {e}\")\n",
        "        return None\n",
        "\n",
        "# Obter dados do bloco\n",
        "BLOCK_DATA = fetch_block_data() or {\n",
        "    \"id\": 483545,\n",
        "    \"position\": 17895,\n",
        "    \"status\": 0,\n",
        "    \"range\": {\n",
        "        \"start\": \"0x9108ba3d21e522400\",\n",
        "        \"end\": \"0x9108ba3d25e5223ff\"\n",
        "    },\n",
        "    \"checkwork_addresses\": [\"\", \"\"],\n",
        "    \"message\": \"Retrieved existing block\"\n",
        "}\n",
        "\n",
        "# FunÃ§Ã£o para monitorar uso da GPU\n",
        "def monitor_gpu():\n",
        "    if not IS_COLAB or not HAS_CUDA:\n",
        "        return\n",
        "\n",
        "    try:\n",
        "        import subprocess\n",
        "        result = subprocess.run('nvidia-smi --query-gpu=utilization.gpu,memory.used,memory.total --format=csv,noheader',\n",
        "                               shell=True, stdout=subprocess.PIPE).stdout.decode('utf-8').strip()\n",
        "        gpu_util, mem_used, mem_total = result.split(',')\n",
        "        print(f\"ðŸ“Š GPU: {gpu_util.strip()} | MemÃ³ria: {mem_used.strip()}/{mem_total.strip()}\")\n",
        "    except:\n",
        "        print(\"âš ï¸ NÃ£o foi possÃ­vel monitorar GPU\")\n",
        "\n",
        "class CupyBitcoinMiner:\n",
        "    \"\"\"Minerador Bitcoin otimizado para CUDA usando apenas CuPy\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"Inicializa o minerador\"\"\"\n",
        "        self.current_block = BLOCK_DATA\n",
        "\n",
        "        # Processa os targets\n",
        "        self.targets_list = []\n",
        "        self.target_addresses = []\n",
        "\n",
        "        # Golden Key (endereÃ§o adicional)\n",
        "        self.golden_key_address = ADDITIONAL_ADDRESS\n",
        "        self.golden_key_hash = decode_bitcoin_address(ADDITIONAL_ADDRESS)\n",
        "        if self.golden_key_hash is not None:\n",
        "            print(f\"ðŸŒŸ Golden Key adicionada: {ADDITIONAL_ADDRESS}\")\n",
        "\n",
        "        # Decodificar endereÃ§os alvo\n",
        "        for addr in self.current_block.get('checkwork_addresses', []):\n",
        "            if isinstance(addr, str) and addr:\n",
        "                # ValidaÃ§Ã£o adicional para confirmar que o endereÃ§o Ã© vÃ¡lido\n",
        "                if is_valid_bitcoin_address(addr):\n",
        "                    self.target_addresses.append(addr)\n",
        "                    hash_array = decode_bitcoin_address(addr)\n",
        "                    if hash_array is not None:\n",
        "                        self.targets_list.append(hash_array)\n",
        "                else:\n",
        "                    print(f\"âš ï¸ EndereÃ§o invÃ¡lido ignorado: {addr}\")\n",
        "\n",
        "        # Adicionar Golden Key aos targets se nÃ£o estiver jÃ¡ incluÃ­da\n",
        "        if self.golden_key_hash is not None:\n",
        "            if not any(np.array_equal(self.golden_key_hash, target) for target in self.targets_list):\n",
        "                self.targets_list.append(self.golden_key_hash)\n",
        "                self.target_addresses.append(self.golden_key_address)\n",
        "                print(\"âœ… Golden Key adicionada aos targets\")\n",
        "\n",
        "        self.n_targets = len(self.targets_list)\n",
        "        print(f\"ðŸŽ¯ Total de targets vÃ¡lidos: {self.n_targets}\")\n",
        "\n",
        "        # Para uso com GPU, converter para arrays CuPy e otimizar memÃ³ria\n",
        "        if HAS_CUDA and self.n_targets > 0 and not CPU_FALLBACK:\n",
        "            # Preparar array de targets para GPU\n",
        "            self.targets_array_np = np.vstack(self.targets_list).astype(np.uint8)\n",
        "\n",
        "            # Transferir para a GPU com CuPy\n",
        "            self.targets_array = cp.asarray(self.targets_array_np)\n",
        "            print(\"âœ… Targets transferidos para GPU\")\n",
        "\n",
        "            # Pre-alocar buffers para reduzir fragmentaÃ§Ã£o de memÃ³ria\n",
        "            try:\n",
        "                # ObtÃ©m informaÃ§Ã£o de memÃ³ria disponÃ­vel\n",
        "                free_mem, total_mem = cp.cuda.runtime.memGetInfo()\n",
        "                available_mem = int(free_mem * GPU_MEMORY_FRACTION)\n",
        "\n",
        "                # Alocar buffers para endereÃ§os e resultados\n",
        "                self.address_buffer = cp.zeros((BATCH_SIZE, 20), dtype=cp.uint8)\n",
        "                self.result_buffer = cp.zeros(BATCH_SIZE, dtype=cp.int32)\n",
        "                print(f\"âœ… Buffers prÃ©-alocados: {BATCH_SIZE} endereÃ§os\")\n",
        "\n",
        "                # Ajustar batch size se necessÃ¡rio baseado na memÃ³ria disponÃ­vel\n",
        "                meminfo_str = f\"MemÃ³ria GPU: {free_mem/(1024**3):.1f}GB livre de {total_mem/(1024**3):.1f}GB\"\n",
        "                print(f\"ðŸ“Š {meminfo_str}\")\n",
        "            except Exception as e:\n",
        "                print(f\"âš ï¸ NÃ£o foi possÃ­vel prÃ©-alocar buffers: {e}\")\n",
        "\n",
        "            # Aquecer a GPU para melhor desempenho\n",
        "            self._warmup_gpu()\n",
        "        else:\n",
        "            self.targets_array_np = np.vstack(self.targets_list).astype(np.uint8) if self.targets_list else None\n",
        "            self.targets_array = None\n",
        "\n",
        "    def _warmup_gpu(self):\n",
        "        \"\"\"Aquece a GPU para melhor desempenho - versÃ£o extremamente agressiva\"\"\"\n",
        "        if not HAS_CUDA or CPU_FALLBACK:\n",
        "            return\n",
        "\n",
        "        try:\n",
        "            print(\"ðŸ”¥ Aquecendo GPU e otimizando para desempenho mÃ¡ximo...\")\n",
        "\n",
        "            # Configurar GPU para desempenho mÃ¡ximo - ajustes extremos para memÃ³ria\n",
        "            try:\n",
        "                # Desativar limites para computaÃ§Ã£o mÃ¡xima\n",
        "                cp.cuda.runtime.deviceSetLimit(0, 8192)  # cudaLimitStackSize aumentado\n",
        "                cp.cuda.runtime.deviceSetLimit(8, 128)   # cudaLimitMaxL2FetchGranularity aumentado\n",
        "\n",
        "                # ConfiguraÃ§Ãµes adicionais para maximizar throughput\n",
        "                if hasattr(cp.cuda.runtime, 'deviceSetCacheConfig'):\n",
        "                    cp.cuda.runtime.deviceSetCacheConfig(2)  # cudaFuncCachePreferL1\n",
        "\n",
        "                # Aumentar tamanho de heap para operaÃ§Ãµes dinÃ¢micas\n",
        "                if hasattr(cp.cuda.runtime, 'deviceSetLimit'):\n",
        "                    cp.cuda.runtime.deviceSetLimit(1, 128*1024*1024)  # cudaLimitMallocHeapSize\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "            # PrÃ©-alocar streams CUDA para operaÃ§Ãµes paralelas\n",
        "            self.cuda_streams = []\n",
        "            self.cuda_events = []\n",
        "            for i in range(CUDA_STREAMS):\n",
        "                try:\n",
        "                    # Criar streams nÃ£o bloqueantes com alta prioridade\n",
        "                    self.cuda_streams.append(cp.cuda.Stream(non_blocking=True, priority=0))\n",
        "\n",
        "                    # Criar eventos para sincronizaÃ§Ã£o fina\n",
        "                    self.cuda_events.append(cp.cuda.Event())\n",
        "                except:\n",
        "                    pass\n",
        "\n",
        "            # WARMUP ULTRA AGRESSIVO: Executar kernels massivos em todas as streams\n",
        "            print(\"   Executando warmup ultra agressivo para maximizar clocks...\")\n",
        "\n",
        "            # Criar grÃ¡ficos CUDA para operaÃ§Ãµes repetitivas\n",
        "            if CUDA_GRAPH_ENABLE:\n",
        "                try:\n",
        "                    # Tentar configurar CUDA Graphs\n",
        "                    self.cuda_graphs = []\n",
        "                    self.cuda_graph_execs = []\n",
        "\n",
        "                    # Criar um graph por stream para operaÃ§Ãµes repetitivas\n",
        "                    for stream in self.cuda_streams[:4]:  # Limitar a 4 graphs\n",
        "                        with stream:\n",
        "                            # Capturar um graph para operaÃ§Ãµes comuns\n",
        "                            graph = cp.cuda.graph.CUDAGraph()\n",
        "                            with graph:\n",
        "                                a = cp.random.normal(0, 1, (5000, 5000), dtype=cp.float32)\n",
        "                                b = cp.random.normal(0, 1, (5000, 5000), dtype=cp.float32)\n",
        "                                c = cp.matmul(a, b)\n",
        "                                d = cp.exp(cp.sin(c) + cp.cos(c))\n",
        "                                e = cp.linalg.cholesky(cp.matmul(d[:1000,:1000], d[:1000,:1000].T) + cp.eye(1000) * 0.01)\n",
        "\n",
        "                            # Armazenar o graph e seu executor\n",
        "                            self.cuda_graphs.append(graph)\n",
        "                            self.cuda_graph_execs.append(graph.compile())\n",
        "\n",
        "                    print(\"   âœ… CUDA Graphs configurados para execuÃ§Ã£o rÃ¡pida\")\n",
        "                except Exception as e:\n",
        "                    print(f\"   âš ï¸ CUDA Graphs nÃ£o disponÃ­veis: {e}\")\n",
        "\n",
        "            # Iniciar thread separado para stress constante com alta prioridade\n",
        "            if CONTINUOUS_STRESS:\n",
        "                self.stress_thread_active = True\n",
        "                self.stress_thread = threading.Thread(target=self._continuous_stress_thread, daemon=True)\n",
        "                self.stress_thread.start()\n",
        "\n",
        "            # AQUECIMENTO DE ALTA INTENSIDADE: Realizar operaÃ§Ãµes em todas as streams em sequÃªncia\n",
        "            for i in range(GPU_WARMUP_ITERS):\n",
        "                # Para cada stream, executar operaÃ§Ãµes diferentes\n",
        "                for sidx, stream in enumerate(self.cuda_streams):\n",
        "                    with stream:\n",
        "                        # Tamanho diferente para cada stream para exercitar diferentes SMs\n",
        "                        size = 5000 + (sidx % 5) * 1000\n",
        "\n",
        "                        # OperaÃ§Ãµes diferentes para exercitar diferentes unidades\n",
        "                        if sidx % 4 == 0:\n",
        "                            # GEMM (operaÃ§Ãµes matriciais) - exercita unidades tensores\n",
        "                            a = cp.random.random((size, size), dtype=cp.float32)\n",
        "                            b = cp.random.random((size, size), dtype=cp.float32)\n",
        "                            c = cp.matmul(a, b)\n",
        "                            del a, b, c\n",
        "\n",
        "                        elif sidx % 4 == 1:\n",
        "                            # FFT (exercita unidades especiais)\n",
        "                            size = min(size, 4096)  # FFT Ã© mais pesado\n",
        "                            a = cp.random.random((size, size), dtype=cp.float32)\n",
        "                            b = cp.fft.fft2(a)\n",
        "                            c = cp.fft.ifft2(b)\n",
        "                            del a, b, c\n",
        "\n",
        "                        elif sidx % 4 == 2:\n",
        "                            # Elementwise operations (exercita CUDA cores)\n",
        "                            n = size * size * 2\n",
        "                            a = cp.random.random(n, dtype=cp.float32)\n",
        "                            for _ in range(20):  # Loop intenso\n",
        "                                a = cp.sin(a) * cp.cos(a)\n",
        "                                a = cp.sqrt(cp.square(a) + 1.0)\n",
        "                                a = cp.exp(a * 0.01)\n",
        "                            del a\n",
        "\n",
        "                        else:\n",
        "                            # OperaÃ§Ãµes de Ã¡lgebra linear (exercita unidades especÃ­ficas)\n",
        "                            size = min(size, 3000)  # Ãlgebra linear Ã© pesada\n",
        "                            a = cp.random.random((size, size), dtype=cp.float32)\n",
        "                            u, s, v = cp.linalg.svd(a, full_matrices=False)  # SVD Ã© extremamente intensivo\n",
        "                            del a, u, s, v\n",
        "\n",
        "                    # Registrar evento para detectar conclusÃ£o\n",
        "                    self.cuda_events[sidx].record(stream)\n",
        "\n",
        "                # Sincronizar para garantir que todas as operaÃ§Ãµes foram completadas\n",
        "                for event in self.cuda_events:\n",
        "                    event.synchronize()\n",
        "\n",
        "                print(f\"   Aquecimento intenso {i+1}/{GPU_WARMUP_ITERS} concluÃ­do\")\n",
        "\n",
        "            # Executar CUDA Graphs compilados para verificar desempenho\n",
        "            if CUDA_GRAPH_ENABLE and hasattr(self, 'cuda_graph_execs') and self.cuda_graph_execs:\n",
        "                print(\"   Executando CUDA Graphs compilados para teste de performance...\")\n",
        "                for i, graph_exec in enumerate(self.cuda_graph_execs):\n",
        "                    start_time = time.time()\n",
        "                    for _ in range(5):  # Executar 5 vezes para medir\n",
        "                        graph_exec.launch()\n",
        "                    cp.cuda.runtime.deviceSynchronize()\n",
        "                    elapsed = time.time() - start_time\n",
        "                    print(f\"   Graph {i+1}: {elapsed/5*1000:.2f}ms por execuÃ§Ã£o\")\n",
        "\n",
        "            # Liberar memÃ³ria\n",
        "            cp.get_default_memory_pool().free_all_blocks()\n",
        "            print(\"âœ… GPU totalmente preparada para desempenho mÃ¡ximo\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"âš ï¸ Erro ao aquecer GPU: {e}\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "\n",
        "# Atualizar o runtime para usar mais CPU cores para processamento\n",
        "def optimize_runtime_settings():\n",
        "    \"\"\"Otimiza configuraÃ§Ãµes do runtime para melhor desempenho\"\"\"\n",
        "    # Desativar GC durante o processamento intensivo\n",
        "    import gc\n",
        "    gc.disable()\n",
        "\n",
        "    # Aumentar prioridade do processo\n",
        "    try:\n",
        "        os.nice(-10)  # Tenta aumentar prioridade em sistemas Unix\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    # Configurar variÃ¡veis de ambiente para otimizaÃ§Ã£o\n",
        "    os.environ[\"OMP_NUM_THREADS\"] = str(MAX_PARALLEL_WORKERS)\n",
        "    os.environ[\"MKL_NUM_THREADS\"] = str(MAX_PARALLEL_WORKERS)\n",
        "    os.environ[\"NUMEXPR_NUM_THREADS\"] = str(MAX_PARALLEL_WORKERS)\n",
        "    os.environ[\"OPENBLAS_NUM_THREADS\"] = str(MAX_PARALLEL_WORKERS)\n",
        "    os.environ[\"VECLIB_MAXIMUM_THREADS\"] = str(MAX_PARALLEL_WORKERS)\n",
        "\n",
        "    # ConfiguraÃ§Ãµes especÃ­ficas para CUDA\n",
        "    if HAS_CUDA:\n",
        "        # Configurar para desmapeamento agressivo de memÃ³ria para evitar fragmentaÃ§Ã£o\n",
        "        os.environ[\"CUPY_GPU_MEMORY_LIMIT\"] = \"90%\"\n",
        "        os.environ[\"CUPY_MALLOC_MANAGED\"] = \"1\"  # Usar malloc gerenciado\n",
        "\n",
        "        # Ajuste fino para melhorar a persistÃªncia do kernel\n",
        "        try:\n",
        "            cp.cuda.runtime.setDeviceFlags(8)  # cudaDeviceScheduleYield\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "        # ConfiguraÃ§Ãµes para melhorar throughput\n",
        "        try:\n",
        "            # Desativar autosync\n",
        "            cp.cuda.runtime.setDeviceFlags(4)  # cudaDeviceScheduleBlockingSync\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "        # ConfiguraÃ§Ãµes adicionais mais agressivas para CUDA\n",
        "        os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"0\"\n",
        "        os.environ[\"CUDA_DEVICE_MAX_CONNECTIONS\"] = \"128\"  # Aumentado para mÃ¡xima concorrÃªncia\n",
        "        os.environ[\"CUDA_CACHE_DISABLE\"] = \"1\" if DISABLE_CACHING else \"0\"  # ForÃ§ar computaÃ§Ã£o sem cache\n",
        "        os.environ[\"CUDA_FORCE_PTX_JIT\"] = \"1\"  # ForÃ§ar compilaÃ§Ã£o JIT para otimizaÃ§Ã£o especÃ­fica da GPU\n",
        "\n",
        "        # Configurar para usar FMA (Fused Multiply-Add) de precisÃ£o simples\n",
        "        os.environ[\"CUPY_FAST_MATH\"] = \"1\"\n",
        "\n",
        "        # ForÃ§ar modo de performance em GPUs NVIDIA - configuraÃ§Ãµes mais agressivas\n",
        "        try:\n",
        "            import subprocess\n",
        "            # Modo persistente\n",
        "            subprocess.run(\"nvidia-smi -pm 1\", shell=True,\n",
        "                           stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
        "            # MÃ¡xima frequÃªncia de memÃ³ria e GPU - valores especÃ­ficos para A100\n",
        "            subprocess.run(\"nvidia-smi -ac 1215,1410\", shell=True,\n",
        "                           stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
        "            # Sem limites de potÃªncia\n",
        "            subprocess.run(\"nvidia-smi -pl 400\", shell=True,\n",
        "                           stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
        "            # Prioridade mÃ¡xima para o processo\n",
        "            subprocess.run(\"nvidia-smi -c 3\", shell=True,  # Modo COMPUTE_EXCLUSIVE\n",
        "                           stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
        "            print(\"ðŸ”¥ GPU configurada para MÃXIMO DESEMPENHO\")\n",
        "        except Exception as e:\n",
        "            print(f\"â„¹ï¸ NÃ£o foi possÃ­vel definir configuraÃ§Ãµes avanÃ§adas da GPU: {e}\")\n",
        "\n",
        "    # Contornar limitaÃ§Ãµes de fork/subprocesso no Linux\n",
        "    if sys.platform.startswith('linux'):\n",
        "        import multiprocessing\n",
        "        multiprocessing.set_start_method('spawn', force=True)\n",
        "\n",
        "# FunÃ§Ã£o principal\n",
        "if __name__ == \"__main__\":\n",
        "    if not HAS_CUDA:\n",
        "        print(\"\\nâš ï¸ CUDA nÃ£o disponÃ­vel. O processamento serÃ¡ feito na CPU (lento).\")\n",
        "        print(\"   Para usar GPU, verifique se:\")\n",
        "        print(\"   1. Ambiente estÃ¡ configurado para GPU (Runtime > Change runtime type)\")\n",
        "        print(\"   2. CuPy estÃ¡ instalado corretamente\")\n",
        "\n",
        "        if IS_COLAB:\n",
        "            print(\"\\nComo estamos no Colab, verifique se escolheu GPU em Runtime > Change runtime type\")\n",
        "\n",
        "        proceed = input(\"\\nContinuar mesmo assim? (s/n): \")\n",
        "        if proceed.lower() != 's':\n",
        "            sys.exit(0)\n",
        "\n",
        "    # Otimizar configuraÃ§Ãµes de runtime antes de iniciar\n",
        "    optimize_runtime_settings()\n",
        "\n",
        "    miner = CupyBitcoinMiner()\n",
        "    miner.run()\n"
      ],
      "metadata": {
        "id": "Lc1cCnyqzKx1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://developer.nvidia.com/compute/cuda/9.2/Prod/local_installers/cuda-repo-ubuntu1604-9-2-local_9.2.88-1_amd64 -O cuda-repo-ubuntu1604-9-2-local_9.2.88-1_amd64.deb\n",
        "!dpkg -i cuda-repo-ubuntu1604-9-2-local_9.2.88-1_amd64.deb\n",
        "!apt-key add /var/cuda-repo-9-2-local/7fa2af80.pub\n",
        "!apt-get update\n",
        "!apt-get install cuda\n",
        "\n"
      ],
      "metadata": {
        "id": "zTpQv2qFpAS9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ================== USO CPU ==================\n",
        "\n",
        "import os\n",
        "import torch\n",
        "import time\n",
        "import numpy as np\n",
        "from coincurve import PublicKey\n",
        "from eth_utils import keccak\n",
        "import base58\n",
        "import requests\n",
        "import sys\n",
        "\n",
        "# ================== CONFIGURAÃ‡ÃƒO ==================\n",
        "os.environ['CUDA_HOME'] = '/usr/local/cuda'\n",
        "\n",
        "POOL_TOKEN = \"076a6a4636e1b70eb5105e609a2a9b59bcff5858f305daec5ee7b18095c6a48f\"  # Token correto do pool\n",
        "API_URL = \"https://bitcoinflix.replit.app/api/big_block\"  # URL da API\n",
        "\n",
        "# FunÃ§Ã£o para buscar automaticamente os dados do bloco da API\n",
        "def fetch_block_data():\n",
        "    print(\"ðŸ”„ Buscando dados do bloco da API...\")\n",
        "    headers = {\"pool-token\": POOL_TOKEN}\n",
        "    try:\n",
        "        response = requests.get(API_URL, headers=headers)\n",
        "        if response.status_code == 200:\n",
        "            data = response.json()\n",
        "            # Log para depuraÃ§Ã£o do range\n",
        "            range_data = data.get(\"range\", {})\n",
        "            start = range_data.get(\"start\", \"\").replace(\"0x\", \"\")\n",
        "            end = range_data.get(\"end\", \"\").replace(\"0x\", \"\")\n",
        "            print(f\"âœ… Range recebido da API: start={start}, end={end}\")\n",
        "\n",
        "            # Exibir dados dos endereÃ§os recebidos\n",
        "            addresses = data.get(\"checkwork_addresses\", [])\n",
        "            print(f\"ðŸ“‹ Carteiras recebidas da API ({len(addresses)}):\")\n",
        "            for i, addr in enumerate(addresses):\n",
        "                if addr: # SÃ³ mostra se nÃ£o for vazio\n",
        "                    print(f\"  {i+1}. {addr}\")\n",
        "\n",
        "            # Exibir ID do bloco e outras informaÃ§Ãµes relevantes\n",
        "            print(f\"ðŸ†” Bloco ID: {data.get('id')}\")\n",
        "            print(f\"ðŸ“Š PosiÃ§Ã£o: {data.get('position')}\")\n",
        "\n",
        "            return data\n",
        "        else:\n",
        "            print(f\"âŒ Erro ao buscar dados do bloco: {response.status_code} - {response.text}\")\n",
        "            return None\n",
        "    except requests.RequestException as e:\n",
        "        print(f\"âŒ Erro ao fazer a requisiÃ§Ã£o: {e}\")\n",
        "        return None\n",
        "\n",
        "# FunÃ§Ã£o para obter informaÃ§Ãµes da GPU\n",
        "def get_gpu_info():\n",
        "    \"\"\"ObtÃ©m informaÃ§Ãµes detalhadas sobre as GPUs disponÃ­veis.\"\"\"\n",
        "    info = {\n",
        "        \"disponÃ­vel\": torch.cuda.is_available(),\n",
        "        \"dispositivos\": 0,\n",
        "        \"modelo\": \"N/A\",\n",
        "        \"memÃ³ria_total_gb\": 0\n",
        "    }\n",
        "\n",
        "    if info[\"disponÃ­vel\"]:\n",
        "        try:\n",
        "            info[\"dispositivos\"] = torch.cuda.device_count()\n",
        "            info[\"modelo\"] = torch.cuda.get_device_name(0)\n",
        "            info[\"memÃ³ria_total_gb\"] = torch.cuda.get_device_properties(0).total_memory / (1024**3)\n",
        "\n",
        "            # Tenta obter informaÃ§Ãµes adicionais com nvidia-smi\n",
        "            try:\n",
        "                import subprocess\n",
        "                result = subprocess.run([\"nvidia-smi\", \"--query-gpu=utilization.gpu,temperature.gpu\", \"--format=csv,noheader\"],\n",
        "                                       capture_output=True, text=True)\n",
        "                if result.returncode == 0:\n",
        "                    util, temp = result.stdout.strip().split(\",\")\n",
        "                    info[\"utilizaÃ§Ã£o\"] = util.strip()\n",
        "                    info[\"temperatura\"] = temp.strip()\n",
        "            except:\n",
        "                pass\n",
        "        except Exception as e:\n",
        "            print(f\"Erro ao obter detalhes da GPU: {e}\")\n",
        "\n",
        "    return info\n",
        "\n",
        "# ObtÃ©m dados do bloco automaticamente ou usa fallback estÃ¡tico\n",
        "BLOCK_DATA = fetch_block_data() or {\n",
        "    \"id\": 483545,\n",
        "    \"position\": 17895,\n",
        "    \"status\": 0,\n",
        "    \"range\": {\n",
        "        \"start\": \"0x9108ba3d21e522400\",\n",
        "        \"end\": \"0x9108ba3d25e5223ff\"\n",
        "    },\n",
        "    \"checkwork_addresses\": [\n",
        "        \"\",\n",
        "        \"\"\n",
        "    ],\n",
        "    \"message\": \"Retrieved existing unchecked block at position 17895\"\n",
        "}\n",
        "\n",
        "SUBBATCH_SIZE = 2**23  # 262144 chaves por sub-lote; para testes, considere diminuir, ex: 2**16\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "PROGRESS_UPDATE_INTERVAL = 100000  # Atualiza o progresso a cada X chaves processadas\n",
        "\n",
        "# ================== FUNÃ‡Ã•ES DE HASH ==================\n",
        "def custom_keccak(data):\n",
        "    \"\"\"Calcula Keccak-256 com tratamento de erros.\"\"\"\n",
        "    try:\n",
        "        if isinstance(data, str):\n",
        "            data = bytes.fromhex(data.replace('0x', ''))\n",
        "        return keccak(data)\n",
        "    except Exception:\n",
        "        return b'\\x00' * 32\n",
        "\n",
        "# ================== FUNÃ‡ÃƒO DE DECODIFICAÃ‡ÃƒO BASE58 ==================\n",
        "def decode_bitcoin_address(address):\n",
        "    \"\"\"\n",
        "    Decodifica um endereÃ§o Bitcoin em Base58Check e extrai os 20 bytes do hash.\n",
        "    Um endereÃ§o P2PKH possui:\n",
        "      - 1 byte de versÃ£o (0x00)\n",
        "      - 20 bytes de hash\n",
        "      - 4 bytes de checksum\n",
        "    Retorna os 20 bytes do hash.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        decoded = base58.b58decode(address)\n",
        "        if len(decoded) != 25:\n",
        "            return None\n",
        "        return decoded[1:-4]\n",
        "    except Exception as e:\n",
        "        print(f\"Erro ao decodificar {address}: {e}\")\n",
        "        return None\n",
        "\n",
        "# ================== CLASSE DE MINERAÃ‡ÃƒO ==================\n",
        "class BitcoinFlixMiner:\n",
        "    def __init__(self):\n",
        "        # Usando os dados dinÃ¢micos obtidos da API\n",
        "        self.current_block = BLOCK_DATA\n",
        "        self.targets = {\n",
        "            decode_bitcoin_address(addr)\n",
        "            for addr in self.current_block.get('checkwork_addresses', [])\n",
        "            if isinstance(addr, str) and addr\n",
        "        }\n",
        "        self.targets = {t for t in self.targets if t is not None}\n",
        "\n",
        "        # Obter informaÃ§Ãµes da GPU\n",
        "        self.gpu_info = get_gpu_info()\n",
        "\n",
        "        # ImpressÃ£o de informaÃ§Ãµes do dispositivo\n",
        "        if self.gpu_info[\"disponÃ­vel\"]:\n",
        "            print(f\"ðŸ–¥ï¸ GPU: {self.gpu_info['modelo']}\")\n",
        "            print(f\"ðŸ“Š MemÃ³ria: {self.gpu_info['memÃ³ria_total_gb']:.2f} GB\")\n",
        "            if \"utilizaÃ§Ã£o\" in self.gpu_info:\n",
        "                print(f\"ðŸŒ¡ï¸ Temperatura: {self.gpu_info['temperatura']}\")\n",
        "        else:\n",
        "            print(\"âš ï¸ GPU nÃ£o disponÃ­vel, usando CPU\")\n",
        "\n",
        "    def process_range(self, start, end):\n",
        "        \"\"\"\n",
        "        Processa um intervalo de chaves com informaÃ§Ãµes detalhadas de progresso.\n",
        "        \"\"\"\n",
        "        total_keys = end - start + 1\n",
        "        valid_keys = []\n",
        "\n",
        "        if total_keys <= 0:\n",
        "            print(\"âŒ Intervalo invÃ¡lido (inÃ­cio >= fim)\")\n",
        "            return []\n",
        "\n",
        "        num_subbatches = (total_keys + SUBBATCH_SIZE - 1) // SUBBATCH_SIZE\n",
        "        print(f\"ðŸš€ Iniciando processamento: {num_subbatches} sub-lotes no intervalo\")\n",
        "        print(f\"ðŸ“Š Tamanho total do range: {total_keys:,} chaves\")\n",
        "\n",
        "        total_processed = 0\n",
        "        global_start_time = time.time()\n",
        "\n",
        "        for i in range(num_subbatches):\n",
        "            sub_start = start + i * SUBBATCH_SIZE\n",
        "            sub_end = min(sub_start + SUBBATCH_SIZE - 1, end)\n",
        "            range_size = sub_end - sub_start + 1\n",
        "\n",
        "            if range_size <= 0:\n",
        "                continue\n",
        "\n",
        "            batch_start_time = time.time()\n",
        "            print(f\"\\nðŸ“Œ [{i+1}/{num_subbatches}] Processando sub-lote {i+1}...\")\n",
        "            print(f\"ðŸ”¢ Range: {sub_start:x} atÃ© {sub_end:x} ({range_size:,} chaves)\")\n",
        "\n",
        "            # Gere offsets pequenos com np.uint32\n",
        "            try:\n",
        "                offsets = np.random.randint(0, range_size, size=SUBBATCH_SIZE, dtype=np.uint32)\n",
        "                keys_cpu = [sub_start + int(off) for off in offsets]\n",
        "\n",
        "                print(\"âš™ï¸ Gerando endereÃ§os e verificando correspondÃªncias...\")\n",
        "\n",
        "                # Inicializa matriz para armazenar endereÃ§os\n",
        "                addresses = np.zeros((SUBBATCH_SIZE, 20), dtype=np.uint8)\n",
        "\n",
        "                # Processamento por lotes com atualizaÃ§Ã£o de progresso\n",
        "                last_update_time = time.time()\n",
        "                last_update_count = 0\n",
        "\n",
        "                for j, key in enumerate(keys_cpu):\n",
        "                    try:\n",
        "                        pk_bytes = bytes.fromhex(f\"{key:064x}\")\n",
        "                        public_key = PublicKey.from_valid_secret(pk_bytes).format(compressed=False)[1:]\n",
        "                        addresses[j] = np.frombuffer(custom_keccak(public_key)[-20:], dtype=np.uint8)\n",
        "                    except Exception:\n",
        "                        addresses[j] = np.zeros(20, dtype=np.uint8)\n",
        "\n",
        "                    # AtualizaÃ§Ã£o de progresso\n",
        "                    if j % PROGRESS_UPDATE_INTERVAL == 0 and j > 0:\n",
        "                        current_time = time.time()\n",
        "                        elapsed = current_time - last_update_time\n",
        "                        keys_since_update = j - last_update_count\n",
        "\n",
        "                        if elapsed > 0:\n",
        "                            speed = keys_since_update / elapsed\n",
        "                            percent = (j / SUBBATCH_SIZE) * 100\n",
        "                            eta = (SUBBATCH_SIZE - j) / speed if speed > 0 else 0\n",
        "\n",
        "                            print(f\"â³ Progresso: {percent:.1f}% | {j:,}/{SUBBATCH_SIZE:,} chaves | \"\n",
        "                                  f\"Velocidade: {speed/1e6:.2f} Mchaves/s | ETA: {eta:.1f}s\")\n",
        "\n",
        "                            last_update_time = current_time\n",
        "                            last_update_count = j\n",
        "\n",
        "                batch_time = time.time() - batch_start_time\n",
        "                batch_speed = SUBBATCH_SIZE / batch_time if batch_time > 0 else 0\n",
        "                print(f\"âœ… GeraÃ§Ã£o concluÃ­da em {batch_time:.2f}s ({batch_speed/1e6:.2f} Mchaves/s)\")\n",
        "\n",
        "                # VerificaÃ§Ã£o de correspondÃªncias\n",
        "                print(f\"ðŸ” Verificando correspondÃªncias com {len(self.targets)} carteiras...\")\n",
        "                match_start_time = time.time()\n",
        "\n",
        "                if self.targets:\n",
        "                    targets = np.array(list(self.targets), dtype=np.uint8)\n",
        "                    matches = np.any(np.all(addresses[:, None] == targets, axis=2), axis=1)\n",
        "                    matched_keys = [keys_cpu[j] for j, m in enumerate(matches) if m]\n",
        "                    valid_keys.extend(matched_keys)\n",
        "\n",
        "                match_time = time.time() - match_start_time\n",
        "                print(f\"âœ… VerificaÃ§Ã£o concluÃ­da em {match_time:.2f}s | Encontradas: {len(matched_keys)} chaves\")\n",
        "\n",
        "                # Atualiza estatÃ­sticas totais\n",
        "                total_processed += SUBBATCH_SIZE\n",
        "                total_elapsed = time.time() - global_start_time\n",
        "                avg_speed = total_processed / total_elapsed if total_elapsed > 0 else 0\n",
        "\n",
        "                print(f\"ðŸ“Š EstatÃ­sticas gerais:\")\n",
        "                print(f\"   Processado: {total_processed:,}/{total_keys:,} chaves ({(total_processed/total_keys)*100:.1f}%)\")\n",
        "                print(f\"   Velocidade mÃ©dia: {avg_speed/1e6:.2f} Mchaves/s\")\n",
        "                print(f\"   Tempo decorrido: {total_elapsed:.2f}s\")\n",
        "\n",
        "                if len(valid_keys) >= 10:\n",
        "                    print(\"ðŸŽ¯ Atingido limite de 10 chaves! Interrompendo processamento.\")\n",
        "                    break\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"âŒ Erro no processamento do sub-lote {i+1}: {e}\")\n",
        "\n",
        "        # EstatÃ­sticas finais\n",
        "        total_elapsed = time.time() - global_start_time\n",
        "        final_speed = total_processed / total_elapsed if total_elapsed > 0 else 0\n",
        "        print(f\"\\nðŸ“ˆ RESUMO FINAL:\")\n",
        "        print(f\"   Processadas {total_processed:,} chaves em {total_elapsed:.2f}s\")\n",
        "        print(f\"   Velocidade mÃ©dia: {final_speed/1e6:.2f} Mchaves/s\")\n",
        "        print(f\"   Chaves vÃ¡lidas encontradas: {len(valid_keys)}\")\n",
        "\n",
        "        return valid_keys[:10]  # Retorna no mÃ¡ximo 10 chaves\n",
        "\n",
        "    def submit_keys(self, keys):\n",
        "        \"\"\"\n",
        "        Envia as chaves encontradas para a API com informaÃ§Ãµes detalhadas.\n",
        "        \"\"\"\n",
        "        if not keys:\n",
        "            print(\"âŒ Nenhuma chave para enviar.\")\n",
        "            return False\n",
        "\n",
        "        print(f\"\\nðŸ“¤ ENVIANDO {len(keys)} CHAVES PARA API\")\n",
        "        print(\"=\" * 50)\n",
        "\n",
        "        # Formata as chaves para o formato esperado pela API\n",
        "        formatted_keys = []\n",
        "        for i, key in enumerate(keys[:10]):\n",
        "            # Converte para string hex e garante que tenha 64 caracteres\n",
        "            hex_key = f\"{key:064x}\"\n",
        "            # Adiciona o prefixo 0x\n",
        "            formatted_key = f\"0x{hex_key}\"\n",
        "            formatted_keys.append(formatted_key)\n",
        "            print(f\"  Chave #{i+1}: {formatted_key}\")\n",
        "\n",
        "        # Completa com zeros se nÃ£o tiver 10 chaves\n",
        "        remaining = 10 - len(formatted_keys)\n",
        "        if remaining > 0:\n",
        "            print(f\"  + {remaining} chaves vazias para completar o lote de 10\")\n",
        "            for _ in range(remaining):\n",
        "                formatted_keys.append(\"0x\" + \"0\" * 64)\n",
        "\n",
        "        # Prepara o payload para a API\n",
        "        payload = {\"privateKeys\": formatted_keys}\n",
        "\n",
        "        # Envia as chaves para a API\n",
        "        headers = {\n",
        "            \"pool-token\": POOL_TOKEN,\n",
        "            \"Content-Type\": \"application/json\"\n",
        "        }\n",
        "\n",
        "        print(\"\\nðŸ”„ Enviando requisiÃ§Ã£o para a API...\")\n",
        "\n",
        "        try:\n",
        "            send_time = time.time()\n",
        "            response = requests.post(API_URL, headers=headers, json=payload)\n",
        "            elapsed = time.time() - send_time\n",
        "\n",
        "            if response.status_code == 200:\n",
        "                print(f\"âœ… SUCESSO! Chaves enviadas em {elapsed:.2f}s\")\n",
        "                try:\n",
        "                    resp_data = response.json()\n",
        "                    if resp_data:\n",
        "                        print(\"ðŸ“‹ Resposta da API:\")\n",
        "                        for k, v in resp_data.items():\n",
        "                            print(f\"  {k}: {v}\")\n",
        "                except:\n",
        "                    print(\"  Resposta sem dados JSON\")\n",
        "                return True\n",
        "            else:\n",
        "                print(f\"âŒ ERRO {response.status_code} ao enviar chaves ({elapsed:.2f}s)\")\n",
        "                print(f\"ðŸ“‹ Resposta: {response.text}\")\n",
        "                return False\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ ERRO na requisiÃ§Ã£o: {e}\")\n",
        "            return False\n",
        "        finally:\n",
        "            print(\"=\" * 50)\n",
        "\n",
        "    def run(self):\n",
        "        \"\"\"Loop principal de mineraÃ§Ã£o com informaÃ§Ãµes detalhadas.\"\"\"\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"ðŸ”¥ BitcoinFlix Miner - VersÃ£o Otimizada com Progresso Detalhado ðŸ”¥\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "        # InformaÃ§Ãµes do dispositivo\n",
        "        print(f\"\\nðŸ“± INFORMAÃ‡Ã•ES DO DISPOSITIVO:\")\n",
        "        print(f\"   Tipo: {'GPU' if torch.cuda.is_available() else 'CPU'}\")\n",
        "        if torch.cuda.is_available():\n",
        "            print(f\"   Modelo: {self.gpu_info['modelo']}\")\n",
        "            print(f\"   MemÃ³ria: {self.gpu_info['memÃ³ria_total_gb']:.2f} GB\")\n",
        "            if \"utilizaÃ§Ã£o\" in self.gpu_info:\n",
        "                print(f\"   UtilizaÃ§Ã£o: {self.gpu_info['utilizaÃ§Ã£o']}\")\n",
        "                print(f\"   Temperatura: {self.gpu_info['temperatura']}\")\n",
        "\n",
        "        # InformaÃ§Ãµes do bloco\n",
        "        print(f\"\\nðŸ“¦ INFORMAÃ‡Ã•ES DO BLOCO:\")\n",
        "        print(f\"   ID: {self.current_block['id']}\")\n",
        "        print(f\"   PosiÃ§Ã£o: {self.current_block.get('position', 'N/A')}\")\n",
        "\n",
        "        # InformaÃ§Ãµes do range\n",
        "        start_hex = self.current_block['range']['start']\n",
        "        end_hex = self.current_block['range']['end']\n",
        "        print(f\"\\nðŸ”¢ RANGE DE PROCESSAMENTO:\")\n",
        "        print(f\"   InÃ­cio: {start_hex}\")\n",
        "        print(f\"   Fim: {end_hex}\")\n",
        "\n",
        "        try:\n",
        "            range_start = int(start_hex, 16)\n",
        "            range_end = int(end_hex, 16)\n",
        "            range_size = range_end - range_start + 1\n",
        "            print(f\"   Tamanho: {range_size:,} chaves\")\n",
        "        except ValueError:\n",
        "            print(\"âŒ Erro ao converter intervalo para inteiro\")\n",
        "            return\n",
        "\n",
        "        # InformaÃ§Ãµes de configuraÃ§Ã£o\n",
        "        print(f\"\\nâš™ï¸ CONFIGURAÃ‡Ã•ES:\")\n",
        "        print(f\"   Tamanho do lote: {SUBBATCH_SIZE:,} chaves\")\n",
        "        print(f\"   Alvos: {len(self.targets)} carteiras\")\n",
        "\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"ðŸš€ INICIANDO PROCESSAMENTO\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "        start_time = time.time()\n",
        "        valid_keys = self.process_range(range_start, range_end)\n",
        "\n",
        "        elapsed = time.time() - start_time\n",
        "        total_speed = SUBBATCH_SIZE * (range_size // SUBBATCH_SIZE) / elapsed if elapsed > 0 else 0\n",
        "\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        if valid_keys:\n",
        "            print(f\"ðŸŽ¯ RESULTADOS: {len(valid_keys)} CHAVES ENCONTRADAS\")\n",
        "            if self.submit_keys(valid_keys):\n",
        "                print(\"âœ… CHAVES ENVIADAS COM SUCESSO!\")\n",
        "            else:\n",
        "                print(\"âš ï¸ ERRO NO ENVIO DAS CHAVES\")\n",
        "        else:\n",
        "            print(\"ðŸ˜ž NENHUMA CHAVE VÃLIDA ENCONTRADA\")\n",
        "\n",
        "        # EstatÃ­sticas finais\n",
        "        print(\"\\nðŸ“Š ESTATÃSTICAS FINAIS:\")\n",
        "        print(f\"   Tempo total: {elapsed:.2f} segundos\")\n",
        "        print(f\"   Velocidade: {total_speed/1e6:.2f} Mchaves/segundo\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    miner = BitcoinFlixMiner()\n",
        "    miner.run()"
      ],
      "metadata": {
        "id": "h_5s__SuLu27"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}