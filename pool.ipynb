{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/WagnerZoega/bet365-test/blob/main/pool.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install cupy-cuda11x coincurve eth-utils base58 pycryptodome\n",
        "!apt install cupy-cuda11x coincurve eth-utils base58 pycryptodome"
      ],
      "metadata": {
        "id": "QbNQvSZv3fGz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Script para instalar depend√™ncias CUDA corretas para o Google Colab\n",
        "Resolve problemas de compatibilidade de biblioteca como o libnvrtc.so n√£o encontrado\n",
        "\"\"\"\n",
        "import os\n",
        "import sys\n",
        "import subprocess\n",
        "import glob\n",
        "import re\n",
        "\n",
        "def check_cuda_version():\n",
        "    \"\"\"Verifica a vers√£o do CUDA instalada no sistema\"\"\"\n",
        "    try:\n",
        "        # Executa o comando nvcc --version\n",
        "        result = subprocess.run(['nvcc', '--version'], stdout=subprocess.PIPE, text=True)\n",
        "        output = result.stdout\n",
        "\n",
        "        # Extrai a vers√£o do CUDA usando regex\n",
        "        match = re.search(r'release (\\d+\\.\\d+)', output)\n",
        "        if match:\n",
        "            version = match.group(1)\n",
        "            print(f\"‚úÖ Vers√£o do CUDA detectada: {version}\")\n",
        "            return version\n",
        "        else:\n",
        "            # Tenta com nvidia-smi\n",
        "            result = subprocess.run(['nvidia-smi'], stdout=subprocess.PIPE, text=True)\n",
        "            output = result.stdout\n",
        "            match = re.search(r'CUDA Version: (\\d+\\.\\d+)', output)\n",
        "            if match:\n",
        "                version = match.group(1)\n",
        "                print(f\"‚úÖ Vers√£o do CUDA detectada (via nvidia-smi): {version}\")\n",
        "                return version\n",
        "\n",
        "            print(\"‚ö†Ô∏è N√£o foi poss√≠vel determinar a vers√£o CUDA, assumindo 12.0\")\n",
        "            return \"12.0\"  # Padr√£o para Colab recentes\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è Erro ao verificar vers√£o CUDA: {e}\")\n",
        "        print(\"‚ö†Ô∏è Assumindo CUDA 12.0\")\n",
        "        return \"12.0\"  # Padr√£o para Colab recentes\n",
        "\n",
        "def install_correct_cupy():\n",
        "    \"\"\"Instala a vers√£o correta do CuPy baseado na vers√£o CUDA\"\"\"\n",
        "    cuda_version = check_cuda_version()\n",
        "    major_version = int(cuda_version.split('.')[0])\n",
        "\n",
        "    print(f\"\\nüîÑ Instalando CuPy compat√≠vel com CUDA {cuda_version}...\")\n",
        "\n",
        "    # Primeiro remover qualquer instala√ß√£o existente para evitar conflitos\n",
        "    subprocess.run([sys.executable, '-m', 'pip', 'uninstall', '-y', 'cupy', 'cupy-cuda11x', 'cupy-cuda12x'])\n",
        "\n",
        "    # Limpar o cache pip para garantir instala√ß√£o limpa\n",
        "    subprocess.run([sys.executable, '-m', 'pip', 'cache', 'purge'])\n",
        "\n",
        "    # Instalar a vers√£o correta do CuPy\n",
        "    if major_version >= 12:\n",
        "        print(\"üîÑ Instalando cupy-cuda12x...\")\n",
        "        subprocess.run([sys.executable, '-m', 'pip', 'install', '--no-cache-dir', 'cupy-cuda12x'])\n",
        "    elif major_version == 11:\n",
        "        print(\"üîÑ Instalando cupy-cuda11x...\")\n",
        "        subprocess.run([sys.executable, '-m', 'pip', 'install', '--no-cache-dir', 'cupy-cuda11x'])\n",
        "    else:\n",
        "        print(f\"‚ö†Ô∏è Vers√£o CUDA {cuda_version} pode n√£o ser compat√≠vel com CuPy atual\")\n",
        "        print(\"üîÑ Tentando instalar cupy-cuda11x como fallback...\")\n",
        "        subprocess.run([sys.executable, '-m', 'pip', 'install', '--no-cache-dir', 'cupy-cuda11x'])\n",
        "\n",
        "    # Verifica se CuPy foi instalado corretamente\n",
        "    print(\"üîç Verificando instala√ß√£o do CuPy...\")\n",
        "    try:\n",
        "        subprocess.run([sys.executable, '-c', 'import cupy; print(\\\"CuPy importado com sucesso\\\")'], check=True)\n",
        "        print(\"‚úÖ CuPy instalado corretamente\")\n",
        "    except subprocess.CalledProcessError:\n",
        "        print(\"‚ö†Ô∏è CuPy n√£o foi instalado corretamente\")\n",
        "        print(\"‚ö†Ô∏è Tentando novamente com CuPy gen√©rico...\")\n",
        "        subprocess.run([sys.executable, '-m', 'pip', 'install', '--no-cache-dir', 'cupy'])\n",
        "\n",
        "def setup_symbolic_links():\n",
        "    \"\"\"Configura links simb√≥licos para bibliotecas CUDA se necess√°rio\"\"\"\n",
        "    print(\"\\nüîÑ Configurando links simb√≥licos para bibliotecas CUDA...\")\n",
        "\n",
        "    try:\n",
        "        # Encontrar arquivos libnvrtc*.so no sistema\n",
        "        nvrtc_libs = []\n",
        "        search_dirs = [\n",
        "            '/usr/local/cuda/lib64/',\n",
        "            '/usr/lib/x86_64-linux-gnu/',\n",
        "            '/usr/lib/',\n",
        "            '/usr/local/lib/'\n",
        "        ]\n",
        "\n",
        "        for directory in search_dirs:\n",
        "            if os.path.exists(directory):\n",
        "                nvrtc_libs.extend(glob.glob(f\"{directory}libnvrtc*.so*\"))\n",
        "\n",
        "        if nvrtc_libs:\n",
        "            print(f\"üìã Bibliotecas NVRTC encontradas: {len(nvrtc_libs)}\")\n",
        "            for lib in nvrtc_libs[:5]:  # Mostra at√© 5 para n√£o sobrecarregar a sa√≠da\n",
        "                print(f\"   - {lib}\")\n",
        "\n",
        "            # Cria link simb√≥lico para libnvrtc.so.11.2 se necess√°rio\n",
        "            if not any('libnvrtc.so.11.2' in lib for lib in nvrtc_libs):\n",
        "                # Encontra a biblioteca mais recente para usar como alvo\n",
        "                target_lib = None\n",
        "                for lib in nvrtc_libs:\n",
        "                    if os.path.islink(lib) and not os.path.exists(lib):\n",
        "                        continue  # Pula links quebrados\n",
        "                    target_lib = lib\n",
        "                    break\n",
        "\n",
        "                if target_lib:\n",
        "                    # Criar diret√≥rio de links\n",
        "                    os.makedirs('/tmp/cuda_links/', exist_ok=True)\n",
        "                    link_path = '/tmp/cuda_links/libnvrtc.so.11.2'\n",
        "\n",
        "                    # Remover link existente se necess√°rio\n",
        "                    if os.path.exists(link_path):\n",
        "                        os.remove(link_path)\n",
        "\n",
        "                    # Criar link simb√≥lico\n",
        "                    os.symlink(target_lib, link_path)\n",
        "                    print(f\"‚úÖ Link simb√≥lico criado: {link_path} -> {target_lib}\")\n",
        "\n",
        "                    # Adicionar ao LD_LIBRARY_PATH\n",
        "                    os.environ['LD_LIBRARY_PATH'] = f\"/tmp/cuda_links:{os.environ.get('LD_LIBRARY_PATH', '')}\"\n",
        "                    print(f\"‚úÖ LD_LIBRARY_PATH atualizado: {os.environ['LD_LIBRARY_PATH']}\")\n",
        "                else:\n",
        "                    print(\"‚ö†Ô∏è N√£o foi poss√≠vel encontrar uma biblioteca NVRTC v√°lida para criar link\")\n",
        "            else:\n",
        "                print(\"‚úÖ libnvrtc.so.11.2 j√° existe, n√£o √© necess√°rio criar link\")\n",
        "        else:\n",
        "            print(\"‚ö†Ô∏è Nenhuma biblioteca NVRTC encontrada no sistema\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è Erro ao configurar links simb√≥licos: {e}\")\n",
        "\n",
        "def install_other_dependencies():\n",
        "    \"\"\"Instala outras depend√™ncias necess√°rias\"\"\"\n",
        "    print(\"\\nüîÑ Instalando outras depend√™ncias...\")\n",
        "\n",
        "    dependencies = [\n",
        "        \"coincurve\",\n",
        "        \"eth-utils\",\n",
        "        \"base58\",\n",
        "        \"torch\"\n",
        "    ]\n",
        "\n",
        "    for dep in dependencies:\n",
        "        print(f\"üîÑ Instalando {dep}...\")\n",
        "        subprocess.run([sys.executable, '-m', 'pip', 'install', dep])\n",
        "\n",
        "def check_installation():\n",
        "    \"\"\"Verifica se a instala√ß√£o foi bem-sucedida\"\"\"\n",
        "    print(\"\\nüîç Verificando instala√ß√£o...\")\n",
        "\n",
        "    try:\n",
        "        print(\"üîÑ Importando CuPy...\")\n",
        "        import cupy as cp\n",
        "\n",
        "        # Obt√©m a vers√£o de uma maneira mais segura\n",
        "        try:\n",
        "            # Tenta diferentes maneiras de obter a vers√£o\n",
        "            version = None\n",
        "            if hasattr(cp, '__version__'):\n",
        "                version = cp.__version__\n",
        "            elif hasattr(cp, 'version'):\n",
        "                version = cp.version\n",
        "            elif hasattr(cp, 'core') and hasattr(cp.core, 'CUPY_VERSION'):\n",
        "                version = cp.core.CUPY_VERSION\n",
        "\n",
        "            if version:\n",
        "                print(f\"‚úÖ CuPy vers√£o {version} importado com sucesso\")\n",
        "            else:\n",
        "                print(\"‚úÖ CuPy importado com sucesso (vers√£o n√£o dispon√≠vel)\")\n",
        "        except:\n",
        "            print(\"‚úÖ CuPy importado com sucesso (n√£o foi poss√≠vel determinar a vers√£o)\")\n",
        "\n",
        "        if cp.cuda.is_available():\n",
        "            print(\"‚úÖ CUDA dispon√≠vel via CuPy!\")\n",
        "            try:\n",
        "                device_props = cp.cuda.runtime.getDeviceProperties(0)\n",
        "                print(f\"   Dispositivo: {device_props['name'].decode()}\")\n",
        "            except:\n",
        "                print(f\"   (N√£o foi poss√≠vel obter o nome do dispositivo)\")\n",
        "\n",
        "            try:\n",
        "                mem = cp.cuda.runtime.memGetInfo()\n",
        "                print(f\"   Mem√≥ria livre: {mem[0]/1024**3:.2f} GB / {mem[1]/1024**3:.2f} GB\")\n",
        "            except:\n",
        "                print(\"   (N√£o foi poss√≠vel obter informa√ß√µes de mem√≥ria)\")\n",
        "\n",
        "            # Teste r√°pido\n",
        "            print(\"\\nüîÑ Executando teste r√°pido de GPU...\")\n",
        "            try:\n",
        "                x = cp.arange(10)\n",
        "                y = cp.arange(10)\n",
        "                z = x + y\n",
        "                print(f\"‚úÖ Teste conclu√≠do: {z.get()}\")\n",
        "                return True\n",
        "            except Exception as e:\n",
        "                print(f\"‚ö†Ô∏è Erro ao executar teste simples: {e}\")\n",
        "                print(\"   Isto pode indicar problemas com o runtime CUDA\")\n",
        "                return False\n",
        "        else:\n",
        "            print(\"‚ùå CUDA n√£o est√° dispon√≠vel via CuPy\")\n",
        "            try:\n",
        "                print(\"\\nVerificando problema:\")\n",
        "                print(f\"   CUDA disponibilidade reportada: {cp.cuda.is_available()}\")\n",
        "                print(f\"   N√∫mero de dispositivos: {cp.cuda.runtime.getDeviceCount()}\")\n",
        "            except Exception as e:\n",
        "                print(f\"   Erro ao verificar dispositivos: {e}\")\n",
        "            return False\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Erro ao verificar instala√ß√£o: {e}\")\n",
        "        print(\"\\nInforma√ß√µes de depura√ß√£o:\")\n",
        "        try:\n",
        "            import sys\n",
        "            print(f\"Python: {sys.version}\")\n",
        "            print(f\"Localiza√ß√£o do pacote CuPy:\")\n",
        "\n",
        "            # Tenta localizar o pacote CuPy mesmo com erro\n",
        "            try:\n",
        "                import importlib.util\n",
        "                cupy_spec = importlib.util.find_spec(\"cupy\")\n",
        "                if cupy_spec:\n",
        "                    print(f\"   Encontrado em: {cupy_spec.origin}\")\n",
        "                else:\n",
        "                    print(\"   Pacote n√£o encontrado no sistema\")\n",
        "            except:\n",
        "                print(\"   N√£o foi poss√≠vel localizar o pacote\")\n",
        "\n",
        "            # Verifica ambiente CUDA\n",
        "            print(\"\\nAmbiente CUDA:\")\n",
        "            import os\n",
        "            for var in ['CUDA_HOME', 'CUDA_PATH', 'LD_LIBRARY_PATH']:\n",
        "                print(f\"   {var}: {os.environ.get(var, 'n√£o definido')}\")\n",
        "\n",
        "            # Tenta mostrar bibliotecas dispon√≠veis\n",
        "            try:\n",
        "                import subprocess\n",
        "                result = subprocess.run('ldconfig -p | grep cuda', shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
        "                if result.returncode == 0 and result.stdout:\n",
        "                    print(\"\\nBibliotecas CUDA no sistema:\")\n",
        "                    for line in result.stdout.splitlines()[:10]:  # Mostra at√© 10 linhas\n",
        "                        print(f\"   {line}\")\n",
        "                    if len(result.stdout.splitlines()) > 10:\n",
        "                        print(f\"   ... mais {len(result.stdout.splitlines()) - 10} bibliotecas\")\n",
        "            except:\n",
        "                pass\n",
        "        except:\n",
        "            print(\"   N√£o foi poss√≠vel coletar informa√ß√µes de depura√ß√£o adicionais\")\n",
        "\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        return False\n",
        "\n",
        "def main():\n",
        "    print(\"=\" * 60)\n",
        "    print(\"üîß CONFIGURA√á√ÉO CUDA PARA BITCOINFLIX MINER üîß\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # Verificar se estamos no Google Colab\n",
        "    in_colab = 'google.colab' in sys.modules\n",
        "    if in_colab:\n",
        "        print(\"‚úÖ Ambiente Google Colab detectado\")\n",
        "\n",
        "        # Verificar se runtime Colab est√° com GPU\n",
        "        try:\n",
        "            import torch\n",
        "            if not torch.cuda.is_available():\n",
        "                print(\"\\n‚ùå IMPORTANTE: GPU N√ÉO DETECTADA NO COLAB!\")\n",
        "                print(\"   Certifique-se de que selecionou GPU em: Runtime > Change runtime type\")\n",
        "                proceed = input(\"Continuar mesmo sem GPU? (s/n): \")\n",
        "                if proceed.lower() != 's':\n",
        "                    print(\"Abortando instala√ß√£o.\")\n",
        "                    return\n",
        "            else:\n",
        "                print(f\"‚úÖ GPU detectada: {torch.cuda.get_device_name(0)}\")\n",
        "        except:\n",
        "            print(\"\\n‚ö†Ô∏è N√£o foi poss√≠vel verificar GPU via PyTorch\")\n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è Este script √© otimizado para Google Colab\")\n",
        "\n",
        "    # Instalar vers√£o correta do CuPy\n",
        "    install_correct_cupy()\n",
        "\n",
        "    # Configurar links simb√≥licos\n",
        "    setup_symbolic_links()\n",
        "\n",
        "    # Instalar outras depend√™ncias\n",
        "    install_other_dependencies()\n",
        "\n",
        "    # Verificar instala√ß√£o\n",
        "    success = check_installation()\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    if success:\n",
        "        print(\"‚úÖ CONFIGURA√á√ÉO CONCLU√çDA COM SUCESSO!\")\n",
        "        print(\"üöÄ Agora voc√™ pode executar colab_cuda_alt.py\")\n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è CONFIGURA√á√ÉO COM PROBLEMAS\")\n",
        "        print(\"‚ùì Tente uma das seguintes op√ß√µes:\")\n",
        "        print(\"   1. Reinicie o runtime (Runtime > Restart runtime) e execute este script novamente\")\n",
        "        print(\"   2. Verifique se voc√™ selecionou GPU em Runtime > Change runtime type\")\n",
        "        print(\"   3. Tente executar colab_cuda_alt.py mesmo assim - a verifica√ß√£o pode falhar mas o script pode funcionar\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "roQJKr_auJvf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Script para resolver problemas de compatibilidade do CuPy com CUDA\n",
        "Resolve os seguintes problemas:\n",
        "1. M√∫ltiplos pacotes CuPy instalados (cupy-cuda11x e cupy-cuda12x)\n",
        "2. Link simb√≥lico faltando para libnvrtc.so.11.2\n",
        "\"\"\"\n",
        "import os\n",
        "import sys\n",
        "import subprocess\n",
        "import glob\n",
        "import re\n",
        "import time\n",
        "\n",
        "def check_environment():\n",
        "    \"\"\"Verifica o ambiente e mostra informa√ß√µes relevantes\"\"\"\n",
        "    print(\"=\" * 60)\n",
        "    print(\"üîç VERIFICANDO AMBIENTE CUDA/CuPy\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # Verificar se estamos no Google Colab\n",
        "    is_colab = 'google.colab' in sys.modules\n",
        "    if is_colab:\n",
        "        print(\"‚úÖ Ambiente Google Colab detectado\")\n",
        "    else:\n",
        "        print(\"‚ÑπÔ∏è Executando fora do Google Colab\")\n",
        "\n",
        "    # Verificar vers√£o do CUDA via nvidia-smi\n",
        "    try:\n",
        "        print(\"\\nüìã Verificando vers√£o CUDA...\")\n",
        "        result = subprocess.run([\"nvidia-smi\"], capture_output=True, text=True)\n",
        "        cuda_match = re.search(r'CUDA Version: (\\d+\\.\\d+)', result.stdout)\n",
        "        if cuda_match:\n",
        "            cuda_version = cuda_match.group(1)\n",
        "            print(f\"‚úÖ CUDA vers√£o {cuda_version} detectada\")\n",
        "            major_version = cuda_version.split('.')[0]\n",
        "            print(f\"   Vers√£o principal: {major_version}\")\n",
        "        else:\n",
        "            print(\"‚ö†Ô∏è N√£o foi poss√≠vel determinar a vers√£o do CUDA via nvidia-smi\")\n",
        "            cuda_version = None\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è Erro ao executar nvidia-smi: {e}\")\n",
        "        cuda_version = None\n",
        "\n",
        "    # Verificar pacotes CuPy instalados\n",
        "    try:\n",
        "        print(\"\\nüìã Verificando instala√ß√µes do CuPy...\")\n",
        "        result = subprocess.run([sys.executable, \"-m\", \"pip\", \"list\"], capture_output=True, text=True)\n",
        "        cupy_packages = re.findall(r'(cupy[^\\s]+)\\s+([^\\s]+)', result.stdout)\n",
        "\n",
        "        if cupy_packages:\n",
        "            print(f\"üì¶ Pacotes CuPy instalados:\")\n",
        "            for pkg, version in cupy_packages:\n",
        "                print(f\"   - {pkg} {version}\")\n",
        "        else:\n",
        "            print(\"‚ö†Ô∏è CuPy n√£o est√° instalado\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è Erro ao verificar pacotes instalados: {e}\")\n",
        "\n",
        "    # Verificar bibliotecas CUDA dispon√≠veis\n",
        "    try:\n",
        "        print(\"\\nüìã Verificando bibliotecas CUDA...\")\n",
        "        library_dirs = [\n",
        "            \"/usr/local/cuda/lib64\",\n",
        "            \"/usr/lib/x86_64-linux-gnu\",\n",
        "            \"/usr/lib\",\n",
        "            \"/lib\"\n",
        "        ]\n",
        "\n",
        "        nvrtc_libs = []\n",
        "        cuda_libs = []\n",
        "\n",
        "        for directory in library_dirs:\n",
        "            if os.path.exists(directory):\n",
        "                nvrtc_candidates = glob.glob(f\"{directory}/libnvrtc*\")\n",
        "                nvrtc_libs.extend(nvrtc_candidates)\n",
        "\n",
        "                # Busca por outras libs CUDA importantes\n",
        "                cuda_candidates = glob.glob(f\"{directory}/libcuda*\") + glob.glob(f\"{directory}/libcudart*\")\n",
        "                cuda_libs.extend(cuda_candidates)\n",
        "\n",
        "        if nvrtc_libs:\n",
        "            print(f\"üìö Bibliotecas NVRTC encontradas ({len(nvrtc_libs)}):\")\n",
        "            for lib in nvrtc_libs[:5]:  # Mostrar apenas as primeiras 5\n",
        "                print(f\"   - {os.path.basename(lib)}\")\n",
        "            if len(nvrtc_libs) > 5:\n",
        "                print(f\"   - ... e mais {len(nvrtc_libs) - 5} bibliotecas\")\n",
        "        else:\n",
        "            print(\"‚ö†Ô∏è Nenhuma biblioteca libnvrtc*.so encontrada\")\n",
        "\n",
        "        if cuda_libs:\n",
        "            print(f\"üìö Outras bibliotecas CUDA importantes ({len(cuda_libs)}):\")\n",
        "            for lib in cuda_libs[:5]:  # Mostrar apenas as primeiras 5\n",
        "                print(f\"   - {os.path.basename(lib)}\")\n",
        "            if len(cuda_libs) > 5:\n",
        "                print(f\"   - ... e mais {len(cuda_libs) - 5} bibliotecas\")\n",
        "\n",
        "        # Verificar a biblioteca espec√≠fica que est√° causando o problema\n",
        "        target_lib = \"libnvrtc.so.11.2\"\n",
        "        target_found = False\n",
        "        for path in nvrtc_libs:\n",
        "            if target_lib in path:\n",
        "                print(f\"‚úÖ {target_lib} encontrada: {path}\")\n",
        "                target_found = True\n",
        "                break\n",
        "\n",
        "        if not target_found:\n",
        "            print(f\"‚ùå {target_lib} n√£o encontrada! Precisamos configurar um link simb√≥lico.\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è Erro ao verificar bibliotecas: {e}\")\n",
        "\n",
        "    return cuda_version\n",
        "\n",
        "def clean_cupy_installation():\n",
        "    \"\"\"Remove todas as instala√ß√µes existentes do CuPy\"\"\"\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"üßπ LIMPANDO INSTALA√á√ïES CuPy EXISTENTES\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # Lista de pacotes CuPy para remover\n",
        "    cupy_packages = [\"cupy\", \"cupy-cuda11x\", \"cupy-cuda12x\", \"cupy-cuda110\", \"cupy-cuda111\", \"cupy-cuda112\", \"cupy-cuda120\"]\n",
        "\n",
        "    for pkg in cupy_packages:\n",
        "        print(f\"üóëÔ∏è Removendo {pkg}...\")\n",
        "        subprocess.run([sys.executable, \"-m\", \"pip\", \"uninstall\", \"-y\", pkg], stdout=subprocess.DEVNULL)\n",
        "\n",
        "    # Limpar o cache pip para evitar problemas\n",
        "    print(\"üóëÔ∏è Limpando cache pip...\")\n",
        "    subprocess.run([sys.executable, \"-m\", \"pip\", \"cache\", \"purge\"], stdout=subprocess.DEVNULL)\n",
        "\n",
        "    print(\"‚úÖ Todas as instala√ß√µes do CuPy foram removidas\")\n",
        "\n",
        "def install_correct_cupy(cuda_version):\n",
        "    \"\"\"Instala a vers√£o correta do CuPy com base na vers√£o do CUDA\"\"\"\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"üì¶ INSTALANDO CuPy COMPAT√çVEL\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    if cuda_version:\n",
        "        major_version = int(float(cuda_version))\n",
        "    else:\n",
        "        # Tenta uma detec√ß√£o alternativa\n",
        "        print(\"‚ö†Ô∏è N√£o foi poss√≠vel determinar a vers√£o CUDA, tentando detectar novamente...\")\n",
        "        try:\n",
        "            # Verificar via nvcc ou buscar outros indicadores\n",
        "            try:\n",
        "                result = subprocess.run([\"nvcc\", \"--version\"], capture_output=True, text=True)\n",
        "                m = re.search(r'release (\\d+\\.\\d+)', result.stdout)\n",
        "                if m:\n",
        "                    major_version = int(float(m.group(1)))\n",
        "                    print(f\"‚úÖ CUDA {major_version} detectado via nvcc\")\n",
        "                else:\n",
        "                    # Verificar presen√ßa de bibliotecas espec√≠ficas\n",
        "                    if os.path.exists(\"/usr/local/cuda-12\"):\n",
        "                        major_version = 12\n",
        "                        print(\"‚úÖ CUDA 12 detectado via diret√≥rios\")\n",
        "                    elif os.path.exists(\"/usr/local/cuda-11\"):\n",
        "                        major_version = 11\n",
        "                        print(\"‚úÖ CUDA 11 detectado via diret√≥rios\")\n",
        "                    else:\n",
        "                        # Assumir vers√£o mais recente\n",
        "                        major_version = 12\n",
        "                        print(\"‚ö†Ô∏è Vers√£o CUDA n√£o detectada, assumindo CUDA 12\")\n",
        "            except:\n",
        "                # Assumir vers√£o mais recente como fallback\n",
        "                major_version = 12\n",
        "                print(\"‚ö†Ô∏è Vers√£o CUDA n√£o detectada, assumindo CUDA 12\")\n",
        "        except:\n",
        "            major_version = 12\n",
        "            print(\"‚ö†Ô∏è Vers√£o CUDA n√£o detectada, assumindo CUDA 12\")\n",
        "\n",
        "    # Instalar a vers√£o correta do CuPy\n",
        "    if major_version >= 12:\n",
        "        cupy_package = \"cupy-cuda12x\"\n",
        "    elif major_version == 11:\n",
        "        cupy_package = \"cupy-cuda11x\"\n",
        "    else:\n",
        "        print(f\"‚ö†Ô∏è CUDA {major_version} pode n√£o ser compat√≠vel com o CuPy atual!\")\n",
        "        print(\"   Tentando instalar a vers√£o para CUDA 11.x como fallback\")\n",
        "        cupy_package = \"cupy-cuda11x\"\n",
        "\n",
        "    print(f\"üì¶ Instalando {cupy_package}...\")\n",
        "    start_time = time.time()\n",
        "    try:\n",
        "        result = subprocess.run(\n",
        "            [sys.executable, \"-m\", \"pip\", \"install\", \"--no-cache-dir\", \"-v\", cupy_package],\n",
        "            capture_output=True,\n",
        "            text=True\n",
        "        )\n",
        "\n",
        "        # Verificar erros espec√≠ficos conhecidos\n",
        "        if \"ERROR: No matching distribution found for cupy\" in result.stderr:\n",
        "            print(f\"‚ùå Erro: Pacote {cupy_package} n√£o encontrado!\")\n",
        "            print(\"   Tentando com instala√ß√£o gen√©rica do cupy...\")\n",
        "            subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"--no-cache-dir\", \"cupy\"])\n",
        "        elif result.returncode != 0:\n",
        "            print(f\"‚ö†Ô∏è Aviso: Poss√≠veis problemas na instala√ß√£o: {result.stderr}\")\n",
        "        else:\n",
        "            print(f\"‚úÖ {cupy_package} instalado com sucesso!\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Erro na instala√ß√£o: {e}\")\n",
        "        print(\"   Tentando alternativa...\")\n",
        "        try:\n",
        "            subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"--no-cache-dir\", \"cupy\"])\n",
        "        except:\n",
        "            print(\"‚ùå Todas as tentativas de instala√ß√£o falharam\")\n",
        "\n",
        "    elapsed = time.time() - start_time\n",
        "    print(f\"‚è±Ô∏è Instala√ß√£o conclu√≠da em {elapsed:.1f} segundos\")\n",
        "\n",
        "def setup_symbolic_links():\n",
        "    \"\"\"Configura links simb√≥licos necess√°rios para as bibliotecas CUDA\"\"\"\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"üîó CONFIGURANDO LINKS SIMB√ìLICOS\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # Criar diret√≥rio para links simb√≥licos\n",
        "    link_dir = \"/tmp/cuda_links\"\n",
        "    os.makedirs(link_dir, exist_ok=True)\n",
        "    print(f\"üìÅ Diret√≥rio para links simb√≥licos: {link_dir}\")\n",
        "\n",
        "    # Adicionar ao LD_LIBRARY_PATH\n",
        "    os.environ[\"LD_LIBRARY_PATH\"] = f\"{link_dir}:{os.environ.get('LD_LIBRARY_PATH', '')}\"\n",
        "    print(f\"‚úÖ LD_LIBRARY_PATH atualizado: {os.environ['LD_LIBRARY_PATH']}\")\n",
        "\n",
        "    # Encontrar bibliotecas NVRTC dispon√≠veis\n",
        "    library_dirs = [\n",
        "        \"/usr/local/cuda/lib64\",\n",
        "        \"/usr/lib/x86_64-linux-gnu\",\n",
        "        \"/usr/lib\",\n",
        "        \"/lib\"\n",
        "    ]\n",
        "\n",
        "    nvrtc_libs = []\n",
        "    for directory in library_dirs:\n",
        "        if os.path.exists(directory):\n",
        "            nvrtc_candidates = glob.glob(f\"{directory}/libnvrtc*\")\n",
        "            nvrtc_libs.extend(nvrtc_candidates)\n",
        "\n",
        "    # Definir os links necess√°rios e suas origens\n",
        "    needed_links = {\n",
        "        \"libnvrtc.so.11.2\": None  # Vai ser preenchido com a biblioteca encontrada\n",
        "    }\n",
        "\n",
        "    # Encontrar o melhor candidato para cada link\n",
        "    for lib in nvrtc_libs:\n",
        "        lib_name = os.path.basename(lib)\n",
        "\n",
        "        # Para libnvrtc.so.11.2, queremos a vers√£o mais pr√≥xima\n",
        "        if \"libnvrtc.so\" in lib_name:\n",
        "            # J√° encontrou o arquivo exato?\n",
        "            if lib_name == \"libnvrtc.so.11.2\":\n",
        "                needed_links[\"libnvrtc.so.11.2\"] = lib\n",
        "                break\n",
        "\n",
        "            # Se n√£o temos um candidato ou este √© um candidato melhor\n",
        "            if needed_links[\"libnvrtc.so.11.2\"] is None:\n",
        "                needed_links[\"libnvrtc.so.11.2\"] = lib\n",
        "\n",
        "    # Criar links simb√≥licos\n",
        "    for link_name, source_lib in needed_links.items():\n",
        "        if source_lib:\n",
        "            link_path = f\"{link_dir}/{link_name}\"\n",
        "\n",
        "            # Remover link antigo se existir\n",
        "            if os.path.exists(link_path):\n",
        "                os.remove(link_path)\n",
        "\n",
        "            os.symlink(source_lib, link_path)\n",
        "            print(f\"üîó Link criado: {link_path} -> {source_lib}\")\n",
        "        else:\n",
        "            print(f\"‚ùå N√£o foi poss√≠vel encontrar biblioteca para {link_name}!\")\n",
        "            print(\"   Isso pode causar falha ao usar CuPy!\")\n",
        "\n",
        "def verify_installation():\n",
        "    \"\"\"Verifica se a instala√ß√£o do CuPy est√° funcionando corretamente\"\"\"\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"üîç VERIFICANDO INSTALA√á√ÉO\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    try:\n",
        "        print(\"üîÑ Tentando importar CuPy...\")\n",
        "        import cupy as cp\n",
        "\n",
        "        print(\"‚úÖ CuPy importado com sucesso!\")\n",
        "\n",
        "        # Mostrar vers√£o\n",
        "        if hasattr(cp, \"__version__\"):\n",
        "            print(f\"üìã Vers√£o: {cp.__version__}\")\n",
        "        else:\n",
        "            print(\"‚ö†Ô∏è N√£o foi poss√≠vel determinar a vers√£o do CuPy\")\n",
        "\n",
        "        # Verificar CUDA dispon√≠vel\n",
        "        if cp.cuda.is_available():\n",
        "            print(\"‚úÖ CUDA dispon√≠vel!\")\n",
        "\n",
        "            # Mostrar informa√ß√µes do dispositivo\n",
        "            try:\n",
        "                device = cp.cuda.Device(0)\n",
        "                props = cp.cuda.runtime.getDeviceProperties(0)\n",
        "                print(f\"üìä Dispositivo: {props['name'].decode()}\")\n",
        "                print(f\"   Mem√≥ria total: {props['totalGlobalMem'] / (1024**3):.2f} GB\")\n",
        "                print(f\"   Compute capability: {props['major']}.{props['minor']}\")\n",
        "            except Exception as e:\n",
        "                print(f\"‚ö†Ô∏è Erro ao obter informa√ß√µes do dispositivo: {e}\")\n",
        "\n",
        "            # Testar opera√ß√µes b√°sicas\n",
        "            print(\"\\nüß™ Executando teste simples...\")\n",
        "            try:\n",
        "                x = cp.array([1, 2, 3])\n",
        "                y = cp.array([4, 5, 6])\n",
        "                z = x + y\n",
        "                print(f\"   Resultado: {z}\")\n",
        "                print(\"‚úÖ Teste bem-sucedido!\")\n",
        "                return True\n",
        "            except Exception as e:\n",
        "                print(f\"‚ùå Teste falhou: {e}\")\n",
        "                return False\n",
        "        else:\n",
        "            print(\"‚ùå CUDA n√£o est√° dispon√≠vel!\")\n",
        "            return False\n",
        "    except ImportError:\n",
        "        print(\"‚ùå N√£o foi poss√≠vel importar CuPy!\")\n",
        "        return False\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Erro ao verificar instala√ß√£o: {e}\")\n",
        "        return False\n",
        "\n",
        "def main():\n",
        "    print(\"=\" * 60)\n",
        "    print(\"üõ†Ô∏è CORRE√á√ÉO DE PROBLEMAS CUDA/CuPy\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # 1. Verificar ambiente\n",
        "    cuda_version = check_environment()\n",
        "\n",
        "    # 2. Limpar instala√ß√µes do CuPy\n",
        "    clean_cupy_installation()\n",
        "\n",
        "    # 3. Instalar vers√£o correta do CuPy\n",
        "    install_correct_cupy(cuda_version)\n",
        "\n",
        "    # 4. Configurar links simb√≥licos\n",
        "    setup_symbolic_links()\n",
        "\n",
        "    # 5. Verificar instala√ß√£o\n",
        "    success = verify_installation()\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    if success:\n",
        "        print(\"‚úÖ CONFIGURA√á√ÉO CONCLU√çDA COM SUCESSO!\")\n",
        "        print(\"\\nüöÄ Agora voc√™ pode executar batch_size_tester.py novamente.\")\n",
        "        print(\"   Recomendamos reiniciar o runtime antes de executar.\")\n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è CONFIGURA√á√ÉO CONCLU√çDA COM POSS√çVEIS PROBLEMAS\")\n",
        "        print(\"\\nüîÑ Por favor, siga estes passos:\")\n",
        "        print(\"   1. Reinicie o runtime (Runtime > Restart runtime)\")\n",
        "        print(\"   2. Execute novamente este script para verificar\")\n",
        "        print(\"   3. Tente executar batch_size_tester.py\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "EBjkoAsrC_5s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Este script testa v√°rios tamanhos de batch para encontrar a configura√ß√£o ideal\n",
        "para o seu hardware espec√≠fico de GPU.\n",
        "\"\"\"\n",
        "import time\n",
        "import numpy as np\n",
        "import sys\n",
        "import subprocess\n",
        "import os\n",
        "\n",
        "# Verificar se estamos no ambiente do Colab ou Jupyter\n",
        "IS_COLAB = 'google.colab' in sys.modules\n",
        "IS_NOTEBOOK = 'ipykernel' in sys.modules\n",
        "\n",
        "# Fun√ß√£o para verificar e consertar o ambiente CUDA/CuPy\n",
        "def check_and_fix_cupy():\n",
        "    \"\"\"Verifica se o ambiente CuPy est√° configurado corretamente e tenta corrigir se necess√°rio.\"\"\"\n",
        "    # Verificar se temos m√∫ltiplos pacotes CuPy instalados\n",
        "    try:\n",
        "        result = subprocess.run([sys.executable, \"-m\", \"pip\", \"list\"], capture_output=True, text=True)\n",
        "        cupy_packages = [line for line in result.stdout.split('\\n') if 'cupy' in line.lower()]\n",
        "\n",
        "        if len(cupy_packages) > 1:\n",
        "            print(\"‚ö†Ô∏è Detectados m√∫ltiplos pacotes CuPy instalados. Isso pode causar conflitos.\")\n",
        "            print(\"   Deseja executar o script de corre√ß√£o CUDA/CuPy? (Recomendado)\")\n",
        "            choice = input(\"   Executar cuda_setup_fix.py? (s/n): \").strip().lower()\n",
        "\n",
        "            if choice == 's':\n",
        "                # Verifica se o script de corre√ß√£o existe\n",
        "                if os.path.exists(\"cuda_setup_fix.py\"):\n",
        "                    print(\"üîÑ Executando script de corre√ß√£o...\")\n",
        "                    subprocess.run([sys.executable, \"cuda_setup_fix.py\"])\n",
        "                    print(\"\\n‚ö†Ô∏è Por favor, reinicie o runtime e execute batch_size_tester.py novamente.\")\n",
        "                    sys.exit(0)\n",
        "                else:\n",
        "                    print(\"‚ùå Script cuda_setup_fix.py n√£o encontrado.\")\n",
        "                    print(\"   Tente reinstalar o CuPy manualmente:\")\n",
        "                    print(\"   !pip uninstall -y cupy cupy-cuda11x cupy-cuda12x\")\n",
        "                    print(\"   !pip install cupy-cuda12x  # Ou a vers√£o apropriada\")\n",
        "                    return False\n",
        "\n",
        "        # Verificar se libnvrtc.so.11.2 est√° dispon√≠vel\n",
        "        # Podemos tentar configurar os links simb√≥licos tamb√©m\n",
        "        try:\n",
        "            # Testar se o CuPy consegue fazer opera√ß√µes b√°sicas\n",
        "            import cupy as cp\n",
        "            test_array = cp.array([1, 2, 3])\n",
        "            test_result = test_array + test_array\n",
        "            return True\n",
        "        except ImportError:\n",
        "            print(\"‚ùå CuPy n√£o est√° instalado.\")\n",
        "            print(\"   Tente instalar com: !pip install cupy-cuda12x\")\n",
        "            return False\n",
        "        except Exception as e:\n",
        "            if \"libnvrtc.so.11.2\" in str(e):\n",
        "                print(\"‚ö†Ô∏è Erro de biblioteca libnvrtc.so.11.2 detectado.\")\n",
        "                print(\"   Executando configura√ß√£o de links simb√≥licos...\")\n",
        "\n",
        "                try:\n",
        "                    # Criar diret√≥rio para links e configurar\n",
        "                    os.makedirs('/tmp/cuda_links', exist_ok=True)\n",
        "\n",
        "                    # Procurar por libnvrtc em locais comuns\n",
        "                    nvrtc_paths = []\n",
        "                    for path in [\"/usr/local/cuda/lib64\", \"/usr/lib/x86_64-linux-gnu\"]:\n",
        "                        if os.path.exists(path):\n",
        "                            nvrtc_paths.extend(subprocess.run(f\"find {path} -name 'libnvrtc.so*'\",\n",
        "                                                           shell=True,\n",
        "                                                           capture_output=True,\n",
        "                                                           text=True).stdout.splitlines())\n",
        "\n",
        "                    if nvrtc_paths:\n",
        "                        # Criar link usando a primeira biblioteca encontrada\n",
        "                        target_path = nvrtc_paths[0]\n",
        "                        link_path = \"/tmp/cuda_links/libnvrtc.so.11.2\"\n",
        "\n",
        "                        # Remover link antigo, se existir\n",
        "                        if os.path.exists(link_path):\n",
        "                            os.remove(link_path)\n",
        "\n",
        "                        # Criar novo link\n",
        "                        os.symlink(target_path, link_path)\n",
        "\n",
        "                        # Atualizar LD_LIBRARY_PATH\n",
        "                        os.environ[\"LD_LIBRARY_PATH\"] = f\"/tmp/cuda_links:{os.environ.get('LD_LIBRARY_PATH', '')}\"\n",
        "                        print(f\"‚úÖ Link simb√≥lico criado: {link_path} -> {target_path}\")\n",
        "                        print(f\"‚úÖ LD_LIBRARY_PATH atualizado\")\n",
        "\n",
        "                        print(\"\\n‚ö†Ô∏è Por favor, reinicie o runtime e execute batch_size_tester.py novamente.\")\n",
        "                        sys.exit(0)\n",
        "                    else:\n",
        "                        print(\"‚ùå N√£o foi poss√≠vel encontrar bibliotecas libnvrtc.so\")\n",
        "                        print(\"   Execute o script cuda_setup_fix.py ou reinstale o CuPy manualmente.\")\n",
        "                        return False\n",
        "                except Exception as link_error:\n",
        "                    print(f\"‚ùå Erro ao configurar links simb√≥licos: {link_error}\")\n",
        "                    return False\n",
        "            else:\n",
        "                print(f\"‚ùå Erro ao inicializar CuPy: {e}\")\n",
        "                return False\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Erro ao verificar ambiente CuPy: {e}\")\n",
        "        return False\n",
        "\n",
        "# Verificar ambiente CuPy e corrigir se necess√°rio\n",
        "check_and_fix_cupy()\n",
        "\n",
        "# Tentar importar bibliotecas necess√°rias\n",
        "try:\n",
        "    import cupy as cp\n",
        "    HAS_CUPY = True\n",
        "    print(\"‚úÖ CuPy dispon√≠vel\")\n",
        "except ImportError:\n",
        "    HAS_CUPY = False\n",
        "    print(\"‚ùå CuPy n√£o dispon√≠vel\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Erro ao inicializar CuPy: {e}\")\n",
        "    print(\"   Execute o script cuda_setup_fix.py para resolver problemas de configura√ß√£o.\")\n",
        "    print(\"   Depois reinicie o runtime e execute este script novamente.\")\n",
        "    sys.exit(1)\n",
        "\n",
        "try:\n",
        "    from coincurve import PublicKey\n",
        "    from eth_utils import keccak\n",
        "    import base58\n",
        "except ImportError:\n",
        "    print(\"‚ö†Ô∏è Bibliotecas necess√°rias n√£o encontradas.\")\n",
        "    print(\"   Instalando bibliotecas essenciais...\")\n",
        "    try:\n",
        "        import subprocess\n",
        "        subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"coincurve\", \"eth-utils\", \"base58\"],\n",
        "                       check=True)\n",
        "        from coincurve import PublicKey\n",
        "        from eth_utils import keccak\n",
        "        import base58\n",
        "        print(\"‚úÖ Bibliotecas instaladas com sucesso\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Erro ao instalar bibliotecas: {e}\")\n",
        "        sys.exit(1)\n",
        "\n",
        "# Fun√ß√µes para benchmark\n",
        "def custom_keccak(data):\n",
        "    \"\"\"Calcula Keccak-256.\"\"\"\n",
        "    try:\n",
        "        if isinstance(data, str):\n",
        "            data = bytes.fromhex(data.replace('0x', ''))\n",
        "        return keccak(data)\n",
        "    except Exception:\n",
        "        return b'\\x00' * 32\n",
        "\n",
        "def generate_random_keys(n):\n",
        "    \"\"\"Gera n chaves aleat√≥rias.\"\"\"\n",
        "    return [int.from_bytes(np.random.bytes(32), 'big') % (2**256 - 2**32 - 977) + 1\n",
        "            for _ in range(n)]\n",
        "\n",
        "def generate_addresses_cpu(keys):\n",
        "    \"\"\"Gera endere√ßos Bitcoin na CPU usando gera√ß√£o em lote.\"\"\"\n",
        "    batch_size = len(keys)\n",
        "    addresses = np.zeros((batch_size, 20), dtype=np.uint8)\n",
        "\n",
        "    for i, key in enumerate(keys):\n",
        "        try:\n",
        "            key_hex = f\"{key:064x}\"\n",
        "            pk_bytes = bytes.fromhex(key_hex)\n",
        "            public_key = PublicKey.from_valid_secret(pk_bytes).format(compressed=False)[1:]\n",
        "            hash_bytes = custom_keccak(public_key)[-20:]\n",
        "            addresses[i] = np.frombuffer(hash_bytes, dtype=np.uint8)\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "    return addresses\n",
        "\n",
        "def test_cpu_to_gpu_transfer(sizes):\n",
        "    \"\"\"Testa a transfer√™ncia de dados CPU para GPU para v√°rios tamanhos.\"\"\"\n",
        "    if not HAS_CUPY:\n",
        "        print(\"‚ùå CuPy n√£o dispon√≠vel para teste de transfer√™ncia\")\n",
        "        return\n",
        "\n",
        "    results = []\n",
        "\n",
        "    print(\"üîÑ Testando transfer√™ncia CPU‚ÜíGPU para diferentes tamanhos de lote\")\n",
        "    print(\"=\" * 60)\n",
        "    print(f\"{'Tamanho':>10} | {'Tempo (ms)':>12} | {'Taxa (GB/s)':>12}\")\n",
        "    print(\"-\" * 60)\n",
        "\n",
        "    for size in sizes:\n",
        "        # Gerar dados na CPU\n",
        "        cpu_data = np.random.randint(0, 256, size=(size, 20), dtype=np.uint8)\n",
        "\n",
        "        # Medir tempo de transfer√™ncia para GPU\n",
        "        start_time = time.time()\n",
        "        gpu_data = cp.asarray(cpu_data)\n",
        "        cp.cuda.stream.get_current_stream().synchronize()\n",
        "        elapsed = (time.time() - start_time) * 1000  # em ms\n",
        "\n",
        "        # Calcular taxa de transfer√™ncia\n",
        "        bytes_transferred = cpu_data.nbytes\n",
        "        transfer_rate = bytes_transferred / (elapsed / 1000) / (1024**3)  # em GB/s\n",
        "\n",
        "        results.append((size, elapsed, transfer_rate))\n",
        "        print(f\"{size:>10} | {elapsed:12.2f} | {transfer_rate:12.2f}\")\n",
        "\n",
        "        # Liberar mem√≥ria\n",
        "        del gpu_data\n",
        "        cp.get_default_memory_pool().free_all_blocks()\n",
        "\n",
        "    return results\n",
        "\n",
        "def test_batch_processing(sizes):\n",
        "    \"\"\"Testa o processamento em lote para diferentes tamanhos.\"\"\"\n",
        "    if not HAS_CUPY:\n",
        "        print(\"‚ùå CuPy n√£o dispon√≠vel para teste de processamento\")\n",
        "        return\n",
        "\n",
        "    results = []\n",
        "\n",
        "    print(\"\\nüîÑ Testando processamento em lote para diferentes tamanhos\")\n",
        "    print(\"=\" * 80)\n",
        "    print(f\"{'Tamanho':>10} | {'Gera√ß√£o CPU (ms)':>16} | {'Verifica√ß√£o GPU (ms)':>18} | {'Total (ms)':>12} | {'Taxa (Mend/s)':>12}\")\n",
        "    print(\"-\" * 80)\n",
        "\n",
        "    # Gerar alguns targets fict√≠cios\n",
        "    n_targets = 10\n",
        "    targets = np.random.randint(0, 256, size=(n_targets, 20), dtype=np.uint8)\n",
        "    targets_gpu = cp.asarray(targets)\n",
        "\n",
        "    for size in sizes:\n",
        "        # PARTE 1: Gerar chaves e endere√ßos na CPU\n",
        "        keys = generate_random_keys(size)\n",
        "\n",
        "        start_time = time.time()\n",
        "        addresses = generate_addresses_cpu(keys)\n",
        "        cpu_time = (time.time() - start_time) * 1000  # em ms\n",
        "\n",
        "        # PARTE 2: Verificar correspond√™ncias na GPU\n",
        "        start_time = time.time()\n",
        "\n",
        "        # Transferir para GPU\n",
        "        addresses_gpu = cp.asarray(addresses)\n",
        "\n",
        "        # Verificar correspond√™ncias\n",
        "        match_any = cp.zeros(size, dtype=cp.bool_)\n",
        "\n",
        "        for t in range(n_targets):\n",
        "            target = targets_gpu[t]\n",
        "            matches = cp.all(addresses_gpu == target, axis=1)\n",
        "            match_any = cp.logical_or(match_any, matches)\n",
        "\n",
        "        # Transferir resultados de volta\n",
        "        matches_cpu = match_any.get()\n",
        "\n",
        "        gpu_time = (time.time() - start_time) * 1000  # em ms\n",
        "\n",
        "        # Estat√≠sticas\n",
        "        total_time = cpu_time + gpu_time\n",
        "        throughput = size / (total_time / 1000) / 1e6  # milh√µes de endere√ßos/segundo\n",
        "\n",
        "        results.append((size, cpu_time, gpu_time, total_time, throughput))\n",
        "        print(f\"{size:>10} | {cpu_time:16.2f} | {gpu_time:18.2f} | {total_time:12.2f} | {throughput:12.2f}\")\n",
        "\n",
        "        # Limpar mem√≥ria\n",
        "        del addresses_gpu, match_any\n",
        "        cp.get_default_memory_pool().free_all_blocks()\n",
        "\n",
        "    return results\n",
        "\n",
        "def show_recommendations(transfer_results, processing_results):\n",
        "    \"\"\"Mostra recomenda√ß√µes baseadas nos resultados dos testes.\"\"\"\n",
        "    if not transfer_results or not processing_results:\n",
        "        return\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"üîç AN√ÅLISE E RECOMENDA√á√ïES\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # Encontrar melhor tamanho de lote para transfer√™ncia\n",
        "    best_transfer = max(transfer_results, key=lambda x: x[2])\n",
        "    print(f\"‚úÖ Melhor tamanho para transfer√™ncia: {best_transfer[0]}\")\n",
        "    print(f\"   Taxa: {best_transfer[2]:.2f} GB/s\")\n",
        "\n",
        "    # Encontrar melhor tamanho de lote para processamento\n",
        "    best_processing = max(processing_results, key=lambda x: x[4])\n",
        "    print(f\"\\n‚úÖ Melhor tamanho para processamento: {best_processing[0]}\")\n",
        "    print(f\"   Throughput: {best_processing[4]:.2f} Mend/s\")\n",
        "\n",
        "    # An√°lise de gargalos\n",
        "    print(\"\\nüìä An√°lise de gargalos:\")\n",
        "\n",
        "    # Verificar se CPU √© gargalo\n",
        "    cpu_times = [r[1] for r in processing_results]\n",
        "    gpu_times = [r[2] for r in processing_results]\n",
        "\n",
        "    cpu_avg_ratio = sum(cpu_times) / sum(gpu_times) if sum(gpu_times) > 0 else float('inf')\n",
        "\n",
        "    if cpu_avg_ratio > 2.0:\n",
        "        print(\"‚ö†Ô∏è A gera√ß√£o de endere√ßos na CPU √© um gargalo significativo\")\n",
        "        print(f\"   CPU leva {cpu_avg_ratio:.1f}x mais tempo que GPU\")\n",
        "        print(\"   Recomenda√ß√£o: Implementar paralelismo na gera√ß√£o de endere√ßos\")\n",
        "\n",
        "    # Verificar efici√™ncia de transfer√™ncia\n",
        "    sizes = [r[0] for r in transfer_results]\n",
        "    transfer_rates = [r[2] for r in transfer_results]\n",
        "\n",
        "    if max(transfer_rates) / min(transfer_rates) > 3.0:\n",
        "        print(\"\\n‚ö†Ô∏è Grande varia√ß√£o na efici√™ncia de transfer√™ncia\")\n",
        "        print(\"   Recomenda√ß√£o: Preferir tamanhos de lote maiores para transfers\")\n",
        "\n",
        "    # Recomenda√ß√£o final baseada nos resultados\n",
        "    print(\"\\nüöÄ RECOMENDA√á√ïES FINAIS:\")\n",
        "\n",
        "    # Escolher tamanho de lote balanceado\n",
        "    recommended_batch = best_processing[0]\n",
        "\n",
        "    # Tamanho para sub-batch baseado no tamanho de mem√≥ria\n",
        "    try:\n",
        "        import cupy as cp\n",
        "        free_mem, total_mem = cp.cuda.runtime.memGetInfo()\n",
        "        available_bytes = free_mem * 0.8  # 80% da mem√≥ria livre\n",
        "\n",
        "        # Tamanho aproximado por registro (endere√ßo + estruturas auxiliares)\n",
        "        bytes_per_record = 100\n",
        "\n",
        "        max_elements = int(available_bytes / bytes_per_record)\n",
        "\n",
        "        # Arredondar para pot√™ncia de 2 mais pr√≥xima\n",
        "        max_power_of_2 = 2**int(np.log2(max_elements))\n",
        "\n",
        "        # Limitar o sub-batch a um m√°ximo razo√°vel\n",
        "        max_subbatch = min(max_power_of_2, 2**26)  # M√°ximo de 64M\n",
        "\n",
        "        recommended_subbatch = max_subbatch\n",
        "    except:\n",
        "        # Valor conservador se falhar\n",
        "        recommended_subbatch = 2**24\n",
        "\n",
        "    print(f\"1. BATCH_SIZE = {recommended_batch}\")\n",
        "    print(f\"2. SUBBATCH_SIZE = {recommended_subbatch} ({recommended_subbatch:,})\")\n",
        "    print(\"3. Implementar paraleliza√ß√£o na gera√ß√£o de endere√ßos\")\n",
        "\n",
        "    # C√≥digo para f√°cil c√≥pia e cola\n",
        "    print(\"\\nC√≥digo para atualizar no seu script:\")\n",
        "    print(\"-\" * 40)\n",
        "    print(f\"BATCH_SIZE = {recommended_batch} if HAS_CUDA else 8192\")\n",
        "    print(f\"SUBBATCH_SIZE = {recommended_subbatch} if HAS_CUDA else 2**20\")\n",
        "\n",
        "def main():\n",
        "    # Vers√£o modificada para funcionar tanto no Colab quanto na linha de comando\n",
        "\n",
        "    # Detectar ambiente de execu√ß√£o e definir par√¢metros apropriados\n",
        "    test_mode = \"standard\"  # default\n",
        "\n",
        "    if IS_NOTEBOOK or IS_COLAB:\n",
        "        # Se estamos em um notebook/Colab, ignoramos os argumentos da linha de comando\n",
        "        # e oferecemos uma interface baseada em vari√°veis\n",
        "        print(\"üí° Executando no ambiente Notebook/Colab - ignorando argumentos de linha de comando\")\n",
        "\n",
        "        # Opcionalmente, podemos permitir ao usu√°rio escolher o modo atrav√©s de uma vari√°vel\n",
        "        try:\n",
        "            # Verifica se estamos no Colab e oferecemos widgets interativos\n",
        "            if IS_COLAB:\n",
        "                from google.colab import output\n",
        "                from IPython.display import display, HTML\n",
        "\n",
        "                print(\"\\nüéÆ Selecione o modo de teste:\")\n",
        "                print(\"1. M√≠nimo (r√°pido, poucos tamanhos)\")\n",
        "                print(\"2. Padr√£o (equil√≠brio entre tempo e precis√£o)\")\n",
        "                print(\"3. Completo (mais preciso, leva mais tempo)\")\n",
        "\n",
        "                choice = input(\"Escolha [1-3] (padr√£o: 2): \").strip()\n",
        "\n",
        "                if choice == \"1\":\n",
        "                    test_mode = \"minimal\"\n",
        "                elif choice == \"3\":\n",
        "                    test_mode = \"full\"\n",
        "                else:\n",
        "                    test_mode = \"standard\"\n",
        "\n",
        "        except (ImportError, Exception) as e:\n",
        "            print(f\"‚ö†Ô∏è N√£o foi poss√≠vel exibir widgets interativos: {e}\")\n",
        "            print(\"‚ö†Ô∏è Usando modo de teste padr√£o\")\n",
        "            test_mode = \"standard\"\n",
        "    else:\n",
        "        # Ambiente de linha de comando normal - podemos usar argparse\n",
        "        import argparse\n",
        "        parser = argparse.ArgumentParser(description='Teste de tamanhos de batch para GPU')\n",
        "        parser.add_argument('--minimal', action='store_true', help='Executar teste m√≠nimo (mais r√°pido)')\n",
        "        parser.add_argument('--full', action='store_true', help='Executar teste completo (mais demorado)')\n",
        "        args = parser.parse_args()\n",
        "\n",
        "        if args.minimal:\n",
        "            test_mode = \"minimal\"\n",
        "        elif args.full:\n",
        "            test_mode = \"full\"\n",
        "\n",
        "    print(\"=\" * 60)\n",
        "    print(\"üöÄ OTIMIZADOR DE BATCH SIZE PARA MINERADOR BITCOIN üöÄ\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # Verifica√ß√£o de hardware\n",
        "    print(\"\\nüîç Verificando hardware dispon√≠vel...\")\n",
        "    if IS_COLAB:\n",
        "        print(\"‚úÖ Ambiente Google Colab detectado\")\n",
        "\n",
        "        # Verificar GPU no Colab\n",
        "        try:\n",
        "            gpu_info = subprocess.run(\"nvidia-smi\", shell=True, stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
        "            print(\"\\nüìä Informa√ß√µes da GPU:\")\n",
        "            for line in gpu_info.split(\"\\n\")[:8]:\n",
        "                print(f\"   {line}\")\n",
        "        except:\n",
        "            print(\"‚ùå nvidia-smi falhou. GPU n√£o dispon√≠vel?\")\n",
        "\n",
        "    if not HAS_CUPY:\n",
        "        print(\"\\n‚ùå CuPy n√£o dispon√≠vel. N√£o √© poss√≠vel executar testes na GPU.\")\n",
        "        print(\"   Instale com: pip install cupy-cuda11x ou cupy-cuda12x dependendo da sua vers√£o CUDA\")\n",
        "        return\n",
        "\n",
        "    # Definir tamanhos de teste com base no modo selecionado\n",
        "    if test_mode == \"minimal\":\n",
        "        print(\"\\nüîç Modo: Teste M√≠nimo (R√°pido)\")\n",
        "        batch_sizes = [1024, 8192, 32768]\n",
        "    elif test_mode == \"full\":\n",
        "        print(\"\\nüîç Modo: Teste Completo (Detalhado)\")\n",
        "        batch_sizes = [512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]\n",
        "        # Verificar se h√° mem√≥ria suficiente para testar tamanhos maiores\n",
        "        if HAS_CUPY:\n",
        "            try:\n",
        "                free_mem, _ = cp.cuda.runtime.memGetInfo()\n",
        "                if free_mem > 6 * (1024**3):  # Mais de 6GB livre\n",
        "                    batch_sizes.append(131072)  # Adicionar teste de 128K\n",
        "                    print(\"‚ö†Ô∏è Executando teste de tamanho grande (128K)\")\n",
        "            except:\n",
        "                pass\n",
        "    else:\n",
        "        print(\"\\nüîç Modo: Teste Padr√£o\")\n",
        "        batch_sizes = [1024, 4096, 8192, 16384, 32768, 65536]\n",
        "\n",
        "    print(f\"\\nüî¢ Testando tamanhos de batch: {batch_sizes}\")\n",
        "\n",
        "    # Testar transfer√™ncia CPU‚ÜíGPU\n",
        "    transfer_results = test_cpu_to_gpu_transfer(batch_sizes)\n",
        "\n",
        "    # Testar processamento de lotes\n",
        "    processing_results = test_batch_processing(batch_sizes)\n",
        "\n",
        "    # Mostrar recomenda√ß√µes\n",
        "    show_recommendations(transfer_results, processing_results)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "VZax15_NAEjh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Ferramenta para otimizar o desempenho GPU para o minerador Bitcoin\n",
        "Resolve o problema de baixo desempenho GPU comparado √† CPU\n",
        "\"\"\"\n",
        "\n",
        "import time\n",
        "import numpy as np\n",
        "import sys\n",
        "import subprocess\n",
        "\n",
        "# Tentar importar CuPy, PyTorch e TensorFlow para testes\n",
        "GPU_LIBS = {}\n",
        "\n",
        "try:\n",
        "    import cupy as cp\n",
        "    GPU_LIBS[\"cupy\"] = True\n",
        "    print(\"‚úÖ CuPy dispon√≠vel\")\n",
        "except ImportError:\n",
        "    GPU_LIBS[\"cupy\"] = False\n",
        "    print(\"‚ùå CuPy n√£o dispon√≠vel\")\n",
        "\n",
        "try:\n",
        "    import torch\n",
        "    GPU_LIBS[\"torch\"] = torch.cuda.is_available()\n",
        "    print(f\"‚úÖ PyTorch dispon√≠vel, GPU: {torch.cuda.is_available()}\")\n",
        "    if torch.cuda.is_available():\n",
        "        print(f\"   Device: {torch.cuda.get_device_name(0)}\")\n",
        "except ImportError:\n",
        "    GPU_LIBS[\"torch\"] = False\n",
        "    print(\"‚ùå PyTorch n√£o dispon√≠vel\")\n",
        "\n",
        "try:\n",
        "    import tensorflow as tf\n",
        "    GPU_LIBS[\"tensorflow\"] = len(tf.config.list_physical_devices('GPU')) > 0\n",
        "    print(f\"‚úÖ TensorFlow dispon√≠vel, GPU: {len(tf.config.list_physical_devices('GPU')) > 0}\")\n",
        "except ImportError:\n",
        "    GPU_LIBS[\"tensorflow\"] = False\n",
        "    print(\"‚ùå TensorFlow n√£o dispon√≠vel\")\n",
        "\n",
        "def test_gpu_memory_transfer():\n",
        "    \"\"\"Testa a velocidade de transfer√™ncia de dados entre CPU e GPU\"\"\"\n",
        "    if not GPU_LIBS[\"cupy\"]:\n",
        "        print(\"‚ùå CuPy n√£o dispon√≠vel para teste de transfer√™ncia\")\n",
        "        return\n",
        "\n",
        "    print(\"\\nüîç Testando velocidade de transfer√™ncia CPU <-> GPU...\")\n",
        "\n",
        "    sizes = [\n",
        "        (1024*1024, \"1MB\"),\n",
        "        (10*1024*1024, \"10MB\"),\n",
        "        (100*1024*1024, \"100MB\"),\n",
        "        (500*1024*1024, \"500MB\"),\n",
        "    ]\n",
        "\n",
        "    for size_bytes, size_name in sizes:\n",
        "        # Criar array na CPU\n",
        "        cpu_array = np.ones(size_bytes // 4, dtype=np.float32)\n",
        "\n",
        "        # Teste de upload (CPU -> GPU)\n",
        "        start = time.time()\n",
        "        gpu_array = cp.asarray(cpu_array)\n",
        "        cp.cuda.stream.get_current_stream().synchronize()\n",
        "        upload_time = time.time() - start\n",
        "        upload_speed = size_bytes / upload_time / (1024**3)  # GB/s\n",
        "\n",
        "        # Teste de download (GPU -> CPU)\n",
        "        start = time.time()\n",
        "        cpu_result = gpu_array.get()\n",
        "        download_time = time.time() - start\n",
        "        download_speed = size_bytes / download_time / (1024**3)  # GB/s\n",
        "\n",
        "        print(f\"üì¶ Tamanho: {size_name}\")\n",
        "        print(f\"   Upload (CPU‚ÜíGPU): {upload_time*1000:.1f}ms ({upload_speed:.2f} GB/s)\")\n",
        "        print(f\"   Download (GPU‚ÜíCPU): {download_time*1000:.1f}ms ({download_speed:.2f} GB/s)\")\n",
        "\n",
        "        # Limpar mem√≥ria\n",
        "        del gpu_array\n",
        "        cp.get_default_memory_pool().free_all_blocks()\n",
        "\n",
        "def optimize_batch_size():\n",
        "    \"\"\"Encontra o tamanho de lote ideal para processamento na GPU\"\"\"\n",
        "    if not GPU_LIBS[\"cupy\"]:\n",
        "        print(\"‚ùå CuPy n√£o dispon√≠vel para teste de tamanho de lote\")\n",
        "        return\n",
        "\n",
        "    print(\"\\nüîç Encontrando tamanho de lote ideal para GPU...\")\n",
        "\n",
        "    # Definir diferentes tamanhos de lote para teste\n",
        "    batch_sizes = [512, 1024, 2048, 4096, 8192, 16384, 32768, 65536]\n",
        "    vector_size = 20  # Tamanho do vetor para cada elemento (20 bytes para hash160)\n",
        "    target_count = 10  # N√∫mero de targets para comparar\n",
        "\n",
        "    best_batch_size = None\n",
        "    best_throughput = 0\n",
        "\n",
        "    for batch_size in batch_sizes:\n",
        "        print(f\"\\nüìä Testando batch_size={batch_size}...\")\n",
        "\n",
        "        # Criar dados de teste\n",
        "        addresses_cpu = np.random.randint(0, 256, size=(batch_size, vector_size), dtype=np.uint8)\n",
        "        targets_cpu = np.random.randint(0, 256, size=(target_count, vector_size), dtype=np.uint8)\n",
        "\n",
        "        # Transferir para GPU\n",
        "        start_time = time.time()\n",
        "        addresses_gpu = cp.asarray(addresses_cpu)\n",
        "        targets_gpu = cp.asarray(targets_cpu)\n",
        "\n",
        "        # Simular opera√ß√µes de verifica√ß√£o (compara√ß√£o com cada target)\n",
        "        results = cp.zeros(batch_size, dtype=cp.bool_)\n",
        "\n",
        "        for t in range(target_count):\n",
        "            target = targets_gpu[t]\n",
        "\n",
        "            # Comparar todos os vetores com este target\n",
        "            match_all = cp.ones(batch_size, dtype=cp.bool_)\n",
        "            for b in range(vector_size):\n",
        "                match_this_byte = addresses_gpu[:, b] == target[b]\n",
        "                match_all = match_all & match_this_byte\n",
        "\n",
        "            # Adicionar aos resultados\n",
        "            results = results | match_all\n",
        "\n",
        "        # Obter resultados de volta\n",
        "        matches = results.get()\n",
        "\n",
        "        total_time = time.time() - start_time\n",
        "        throughput = batch_size / total_time\n",
        "\n",
        "        print(f\"   Tempo: {total_time:.4f}s\")\n",
        "        print(f\"   Throughput: {throughput:.0f} elementos/s\")\n",
        "        print(f\"   Throughput: {throughput/1e6:.2f} Melementos/s\")\n",
        "\n",
        "        if throughput > best_throughput:\n",
        "            best_throughput = throughput\n",
        "            best_batch_size = batch_size\n",
        "\n",
        "        # Limpar mem√≥ria GPU\n",
        "        del addresses_gpu, targets_gpu, results\n",
        "        cp.get_default_memory_pool().free_all_blocks()\n",
        "\n",
        "    # Resumo final\n",
        "    print(f\"\\n‚úÖ RESULTADO FINAL:\")\n",
        "    print(f\"   Melhor tamanho de lote: {best_batch_size}\")\n",
        "    print(f\"   Throughput m√°ximo: {best_throughput/1e6:.2f} Melementos/s\")\n",
        "    print(f\"   ‚û°Ô∏è Recomenda√ß√£o: Definir BATCH_SIZE = {best_batch_size} no seu script\")\n",
        "\n",
        "    return best_batch_size\n",
        "\n",
        "def optimize_memory_usage():\n",
        "    \"\"\"Otimiza o uso de mem√≥ria GPU para melhor desempenho\"\"\"\n",
        "    if not GPU_LIBS[\"cupy\"]:\n",
        "        return\n",
        "\n",
        "    print(\"\\nüîç Otimizando uso de mem√≥ria GPU...\")\n",
        "\n",
        "    try:\n",
        "        # Obter informa√ß√µes de mem√≥ria total e dispon√≠vel\n",
        "        mem_info = cp.cuda.runtime.memGetInfo()\n",
        "        mem_free = mem_info[0]\n",
        "        mem_total = mem_info[1]\n",
        "\n",
        "        print(f\"   Mem√≥ria total: {mem_total / (1024**2):.0f} MB\")\n",
        "        print(f\"   Mem√≥ria dispon√≠vel: {mem_free / (1024**2):.0f} MB\")\n",
        "\n",
        "        # Calcular fra√ß√£o segura para uso\n",
        "        safe_fraction = 0.8  # Usa 80% da mem√≥ria dispon√≠vel\n",
        "        safe_mem = int(mem_free * safe_fraction)\n",
        "\n",
        "        # Estimar quantos elementos podem ser processados com essa mem√≥ria\n",
        "        # Assumindo que cada elemento usa ~100 bytes na GPU (endere√ßo + dados complementares)\n",
        "        bytes_per_element = 100\n",
        "        max_elements = safe_mem // bytes_per_element\n",
        "\n",
        "        print(f\"   Mem√≥ria segura para uso: {safe_mem / (1024**2):.0f} MB\")\n",
        "        print(f\"   Elementos estimados: {max_elements:,}\")\n",
        "\n",
        "        # Calcular batch size recomendado (arredondar para pot√™ncia de 2 inferior)\n",
        "        batch_size = 2**int(np.log2(max_elements))\n",
        "        batch_size = min(batch_size, 65536)  # Limitar ao m√°ximo razo√°vel\n",
        "\n",
        "        print(f\"   ‚û°Ô∏è Batch size recomendado: {batch_size}\")\n",
        "\n",
        "        # Sugest√£o para sub-batch size (maior para GPU)\n",
        "        subbatch_size = 2**24  # 16M chaves por sub-lote\n",
        "        if mem_total < 8 * (1024**3):  # Menos de 8GB de VRAM\n",
        "            subbatch_size = 2**22  # Reduz para 4M em GPUs com menos mem√≥ria\n",
        "\n",
        "        print(f\"   ‚û°Ô∏è Sub-batch size recomendado: {subbatch_size:,}\")\n",
        "\n",
        "        return batch_size, subbatch_size\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Erro ao calcular uso de mem√≥ria: {e}\")\n",
        "        return None, None\n",
        "\n",
        "def test_cpu_vs_gpu():\n",
        "    \"\"\"Compara desempenho da CPU vs GPU para opera√ß√µes espec√≠ficas do minerador\"\"\"\n",
        "    print(\"\\nüèÜ COMPARANDO DESEMPENHO CPU vs GPU\")\n",
        "\n",
        "    # Definir tamanho do teste\n",
        "    sample_size = 50000  # 50K elementos\n",
        "\n",
        "    # Gerar dados aleat√≥rios para teste\n",
        "    data_np = np.random.randint(0, 256, size=(sample_size, 20), dtype=np.uint8)\n",
        "    targets_np = np.random.randint(0, 256, size=(10, 20), dtype=np.uint8)\n",
        "\n",
        "    # Teste 1: Compara√ß√£o na CPU usando NumPy\n",
        "    print(\"\\nüìä Teste de compara√ß√£o (CPU/NumPy):\")\n",
        "    start_time = time.time()\n",
        "    matches_cpu = np.zeros(sample_size, dtype=bool)\n",
        "\n",
        "    for i in range(sample_size):\n",
        "        for t in range(10):\n",
        "            if np.array_equal(data_np[i], targets_np[t]):\n",
        "                matches_cpu[i] = True\n",
        "                break\n",
        "\n",
        "    cpu_time = time.time() - start_time\n",
        "\n",
        "    print(f\"   Tempo CPU: {cpu_time:.4f}s\")\n",
        "    print(f\"   Throughput: {sample_size / cpu_time:.0f} elem/s\")\n",
        "\n",
        "    # Teste 2: Compara√ß√£o na GPU usando CuPy\n",
        "    if GPU_LIBS[\"cupy\"]:\n",
        "        print(\"\\nüìä Teste de compara√ß√£o (GPU/CuPy):\")\n",
        "        start_time = time.time()\n",
        "\n",
        "        # Transferir dados para GPU\n",
        "        data_cp = cp.asarray(data_np)\n",
        "        targets_cp = cp.asarray(targets_np)\n",
        "\n",
        "        # Realizar compara√ß√£o\n",
        "        matches_gpu = cp.zeros(sample_size, dtype=cp.bool_)\n",
        "\n",
        "        for t in range(10):\n",
        "            target = targets_cp[t]\n",
        "            match_all = cp.all(data_cp == target, axis=1)\n",
        "            matches_gpu = matches_gpu | match_all\n",
        "\n",
        "        # For√ßar sincroniza√ß√£o e copiar resultados\n",
        "        cp.cuda.stream.get_current_stream().synchronize()\n",
        "        matches_gpu_np = matches_gpu.get()\n",
        "\n",
        "        gpu_time = time.time() - start_time\n",
        "\n",
        "        print(f\"   Tempo GPU: {gpu_time:.4f}s\")\n",
        "        print(f\"   Throughput: {sample_size / gpu_time:.0f} elem/s\")\n",
        "        print(f\"   Speedup GPU/CPU: {cpu_time / gpu_time:.2f}x\")\n",
        "\n",
        "        # Verificar resultados\n",
        "        matches = np.sum(matches_cpu == matches_gpu_np)\n",
        "        accuracy = matches / sample_size * 100\n",
        "        print(f\"   Resultados equivalentes: {accuracy:.2f}%\")\n",
        "\n",
        "        # Limpar mem√≥ria GPU\n",
        "        del data_cp, targets_cp, matches_gpu\n",
        "        cp.get_default_memory_pool().free_all_blocks()\n",
        "\n",
        "def main():\n",
        "    print(\"=\" * 60)\n",
        "    print(\"üöÄ OTIMIZADOR DE DESEMPENHO GPU PARA MINERADOR BITCOIN üöÄ\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # Verificar se GPU est√° dispon√≠vel\n",
        "    if not any(GPU_LIBS.values()):\n",
        "        print(\"‚ùå Nenhuma biblioteca GPU (CuPy, PyTorch, TensorFlow) dispon√≠vel.\")\n",
        "        print(\"   Instale pelo menos uma dessas bibliotecas antes de usar este otimizador.\")\n",
        "        return\n",
        "\n",
        "    # Testar velocidade de transfer√™ncia entre CPU e GPU\n",
        "    test_gpu_memory_transfer()\n",
        "\n",
        "    # Otimizar tamanho de lote para GPU\n",
        "    best_batch_size = optimize_batch_size()\n",
        "\n",
        "    # Otimizar uso de mem√≥ria\n",
        "    mem_batch_size, subbatch_size = optimize_memory_usage()\n",
        "\n",
        "    # Comparar CPU vs GPU\n",
        "    test_cpu_vs_gpu()\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"‚úÖ RECOMENDA√á√ïES FINAIS\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # Determinar tamanho final recomendado\n",
        "    batch_size = best_batch_size if best_batch_size else mem_batch_size\n",
        "    if not batch_size:\n",
        "        batch_size = 8192  # valor padr√£o conservador\n",
        "\n",
        "    print(f\"1. Defina BATCH_SIZE = {batch_size}\")\n",
        "    print(f\"2. Defina SUBBATCH_SIZE = {subbatch_size or 2**23}\")\n",
        "    print(f\"3. Para melhor desempenho com CuPy, minimize transfer√™ncias entre CPU e GPU\")\n",
        "    print(f\"4. Pr√©-aloque buffers na GPU para reduzir fragmenta√ß√£o de mem√≥ria\")\n",
        "    print(f\"5. Processe os lotes em blocos para opera√ß√µes na GPU\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "GjJiHcuU-W5u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Script para testar a velocidade de processamento de diferentes m√©todos\n",
        "e identificar gargalos de desempenho\n",
        "\"\"\"\n",
        "import time\n",
        "import numpy as np\n",
        "from coincurve import PublicKey\n",
        "from eth_utils import keccak\n",
        "import base58\n",
        "import hashlib\n",
        "\n",
        "# Tente importar bibliotecas GPU\n",
        "try:\n",
        "    import cupy as cp\n",
        "    HAS_CUPY = True\n",
        "    print(\"‚úÖ CuPy dispon√≠vel\")\n",
        "except ImportError:\n",
        "    HAS_CUPY = False\n",
        "    print(\"‚ùå CuPy n√£o dispon√≠vel\")\n",
        "\n",
        "try:\n",
        "    import torch\n",
        "    HAS_TORCH = torch.cuda.is_available()\n",
        "    print(f\"‚úÖ PyTorch dispon√≠vel, GPU: {torch.cuda.is_available()}\")\n",
        "    if torch.cuda.is_available():\n",
        "        print(f\"   Device: {torch.cuda.get_device_name(0)}\")\n",
        "except ImportError:\n",
        "    HAS_TORCH = False\n",
        "    print(\"‚ùå PyTorch n√£o dispon√≠vel\")\n",
        "\n",
        "try:\n",
        "    import tensorflow as tf\n",
        "    HAS_TF = len(tf.config.list_physical_devices('GPU')) > 0\n",
        "    print(f\"‚úÖ TensorFlow dispon√≠vel, GPU: {len(tf.config.list_physical_devices('GPU')) > 0}\")\n",
        "except ImportError:\n",
        "    HAS_TF = False\n",
        "    print(\"‚ùå TensorFlow n√£o dispon√≠vel\")\n",
        "\n",
        "# Fun√ß√µes de hash e endere√ßamento\n",
        "def custom_keccak(data):\n",
        "    \"\"\"Calcula Keccak-256 com tratamento de erros.\"\"\"\n",
        "    try:\n",
        "        if isinstance(data, str):\n",
        "            data = bytes.fromhex(data.replace('0x', ''))\n",
        "        return keccak(data)\n",
        "    except Exception:\n",
        "        return b'\\x00' * 32\n",
        "\n",
        "def bitcoin_hash160(data):\n",
        "    \"\"\"Calcula hash160 (SHA-256 seguido de RIPEMD-160)\"\"\"\n",
        "    sha = hashlib.sha256(data).digest()\n",
        "    ripemd160 = hashlib.new('ripemd160')\n",
        "    ripemd160.update(sha)\n",
        "    return ripemd160.digest()\n",
        "\n",
        "def test_address_generation(n_keys=1000):\n",
        "    \"\"\"Testa a velocidade da gera√ß√£o de endere√ßos Bitcoin.\"\"\"\n",
        "    print(f\"\\nüîÑ Testando gera√ß√£o de {n_keys} endere√ßos Bitcoin...\")\n",
        "\n",
        "    # Gerar chaves privadas aleat√≥rias\n",
        "    print(\"Gerando chaves privadas...\")\n",
        "    keys = [int.from_bytes(np.random.bytes(32), 'big') % (2**256 - 2**32 - 977) + 1 for _ in range(n_keys)]\n",
        "\n",
        "    # M√©todo 1: Keccak-256 (ethereum)\n",
        "    print(\"\\nM√©todo 1: Keccak-256 (Ethereum)\")\n",
        "    start_time = time.time()\n",
        "    addresses_keccak = []\n",
        "    for key in keys:\n",
        "        try:\n",
        "            private_key_hex = f\"{key:064x}\"\n",
        "            pk_bytes = bytes.fromhex(private_key_hex)\n",
        "            public_key = PublicKey.from_valid_secret(pk_bytes).format(compressed=False)[1:]\n",
        "            hash_bytes = custom_keccak(public_key)[-20:]\n",
        "            addresses_keccak.append(hash_bytes)\n",
        "        except Exception:\n",
        "            addresses_keccak.append(b'\\x00' * 20)\n",
        "    elapsed = time.time() - start_time\n",
        "    print(f\"‚úÖ Tempo: {elapsed:.3f}s ({n_keys/elapsed:.1f} chaves/s)\")\n",
        "\n",
        "    # M√©todo 2: SHA-256 + RIPEMD-160 (bitcoin)\n",
        "    print(\"\\nM√©todo 2: SHA-256 + RIPEMD-160 (Bitcoin)\")\n",
        "    start_time = time.time()\n",
        "    addresses_bitcoin = []\n",
        "    for key in keys:\n",
        "        try:\n",
        "            private_key_hex = f\"{key:064x}\"\n",
        "            pk_bytes = bytes.fromhex(private_key_hex)\n",
        "            public_key = PublicKey.from_valid_secret(pk_bytes).format(compressed=False)[1:]\n",
        "            hash_bytes = bitcoin_hash160(public_key)\n",
        "            addresses_bitcoin.append(hash_bytes)\n",
        "        except Exception:\n",
        "            addresses_bitcoin.append(b'\\x00' * 20)\n",
        "    elapsed = time.time() - start_time\n",
        "    print(f\"‚úÖ Tempo: {elapsed:.3f}s ({n_keys/elapsed:.1f} chaves/s)\")\n",
        "\n",
        "    # Comparar resultados\n",
        "    matches = 0\n",
        "    for i in range(len(addresses_keccak)):\n",
        "        if addresses_keccak[i] == addresses_bitcoin[i]:\n",
        "            matches += 1\n",
        "    match_percent = (matches / len(addresses_keccak)) * 100\n",
        "    print(f\"üìä Correspond√™ncia entre m√©todos: {match_percent:.2f}%\")\n",
        "\n",
        "    if match_percent < 100:\n",
        "        print(\"‚ö†Ô∏è AVISO: Os m√©todos produzem resultados diferentes!\")\n",
        "        print(\"   Isso pode causar incompatibilidade com endere√ßos Bitcoin reais.\")\n",
        "\n",
        "def test_batch_processing():\n",
        "    \"\"\"Testa a velocidade de processamento em lotes.\"\"\"\n",
        "    print(\"\\nüîÑ Testando velocidade de processamento em lote...\")\n",
        "\n",
        "    # Preparar dados de teste\n",
        "    n_addresses = 10000\n",
        "    n_targets = 10\n",
        "\n",
        "    # Gerar endere√ßos aleat√≥rios\n",
        "    addresses = np.random.randint(0, 256, size=(n_addresses, 20), dtype=np.uint8)\n",
        "    # Garantir que pelo menos 5 endere√ßos correspondem a targets\n",
        "    targets = np.random.randint(0, 256, size=(n_targets, 20), dtype=np.uint8)\n",
        "    for i in range(5):\n",
        "        addresses[i] = targets[i % n_targets]\n",
        "\n",
        "    # M√©todo 1: Compara√ß√£o com NumPy\n",
        "    print(\"\\nM√©todo 1: NumPy (CPU)\")\n",
        "    start_time = time.time()\n",
        "    matches_numpy = np.zeros(n_addresses, dtype=bool)\n",
        "    for i in range(n_addresses):\n",
        "        for t in range(n_targets):\n",
        "            if np.array_equal(addresses[i], targets[t]):\n",
        "                matches_numpy[i] = True\n",
        "                break\n",
        "    numpy_time = time.time() - start_time\n",
        "    print(f\"‚úÖ Tempo: {numpy_time:.3f}s ({n_addresses/numpy_time:.1f} endere√ßos/s)\")\n",
        "    print(f\"   Matches: {np.sum(matches_numpy)}\")\n",
        "\n",
        "    # M√©todo 2: CuPy (se dispon√≠vel)\n",
        "    if HAS_CUPY:\n",
        "        print(\"\\nM√©todo 2: CuPy (GPU)\")\n",
        "        start_time = time.time()\n",
        "\n",
        "        # Transferir para GPU\n",
        "        addresses_gpu = cp.asarray(addresses)\n",
        "        targets_gpu = cp.asarray(targets)\n",
        "        matches_cupy = cp.zeros(n_addresses, dtype=bool)\n",
        "\n",
        "        # Verificar correspond√™ncias\n",
        "        for t_idx in range(n_targets):\n",
        "            target = targets_gpu[t_idx]\n",
        "            # Comparar cada endere√ßo com este target\n",
        "            equal_bytes = cp.all(addresses_gpu == target, axis=1)\n",
        "            # Atualizar resultados\n",
        "            matches_cupy = cp.logical_or(matches_cupy, equal_bytes)\n",
        "\n",
        "        # Transferir resultados de volta para CPU\n",
        "        matches_cupy_cpu = matches_cupy.get()\n",
        "\n",
        "        cupy_time = time.time() - start_time\n",
        "        print(f\"‚úÖ Tempo: {cupy_time:.3f}s ({n_addresses/cupy_time:.1f} endere√ßos/s)\")\n",
        "        print(f\"   Matches: {np.sum(matches_cupy_cpu)}\")\n",
        "        print(f\"   Speedup vs CPU: {numpy_time/cupy_time:.1f}x\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"=\" * 60)\n",
        "    print(\"üöÄ TESTE DE DESEMPENHO BITCOIN MINER üöÄ\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # Teste de gera√ß√£o de endere√ßos\n",
        "    test_address_generation(5000)\n",
        "\n",
        "    # Teste de processamento em lote\n",
        "    test_batch_processing()\n"
      ],
      "metadata": {
        "id": "30tVM1H08dKR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Script para validar a correta convers√£o de chaves privadas para endere√ßos Bitcoin\n",
        "\"\"\"\n",
        "import base58\n",
        "import numpy as np\n",
        "from coincurve import PublicKey\n",
        "from eth_utils import keccak\n",
        "import hashlib\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "# Instalar bibliotecas necess√°rias se n√£o estiverem dispon√≠veis\n",
        "try:\n",
        "    from Crypto.Hash import RIPEMD160\n",
        "    HAS_PYCRYPTO = True\n",
        "    print(\"‚úÖ Usando Crypto.Hash.RIPEMD160\")\n",
        "except ImportError:\n",
        "    HAS_PYCRYPTO = False\n",
        "    print(\"‚ö†Ô∏è Crypto.Hash.RIPEMD160 n√£o dispon√≠vel, instalando pycryptodome...\")\n",
        "    try:\n",
        "        subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"pycryptodome\"], check=True)\n",
        "        from Crypto.Hash import RIPEMD160\n",
        "        HAS_PYCRYPTO = True\n",
        "        print(\"‚úÖ pycryptodome instalado com sucesso\")\n",
        "    except:\n",
        "        print(\"‚ùå N√£o foi poss√≠vel instalar pycryptodome\")\n",
        "        HAS_PYCRYPTO = False\n",
        "\n",
        "def custom_keccak(data):\n",
        "    \"\"\"Calcula Keccak-256 com tratamento de erros.\"\"\"\n",
        "    try:\n",
        "        if isinstance(data, str):\n",
        "            data = bytes.fromhex(data.replace('0x', ''))\n",
        "        return keccak(data)\n",
        "    except Exception:\n",
        "        return b'\\x00' * 32\n",
        "\n",
        "def sha256(data):\n",
        "    \"\"\"Calcula SHA-256\"\"\"\n",
        "    return hashlib.sha256(data).digest()\n",
        "\n",
        "def ripemd160(data):\n",
        "    \"\"\"\n",
        "    Calcula RIPEMD-160 usando a biblioteca Crypto.Hash quando dispon√≠vel\n",
        "    ou um m√©todo alternativo quando n√£o est√° dispon√≠vel\n",
        "    \"\"\"\n",
        "    if HAS_PYCRYPTO:\n",
        "        # Usando pycryptodome\n",
        "        h = RIPEMD160.new()\n",
        "        h.update(data)\n",
        "        return h.digest()\n",
        "    else:\n",
        "        # Implementa√ß√£o alternativa usando outro algoritmo\n",
        "        # (isso √© apenas um fallback, n√£o use em produ√ß√£o)\n",
        "        print(\"‚ö†Ô∏è RIPEMD160 n√£o dispon√≠vel, usando SHA1 como fallback (N√ÉO SEGURO)\")\n",
        "        return hashlib.sha1(data).digest()\n",
        "\n",
        "def bitcoin_hash160(public_key):\n",
        "    \"\"\"Implementa√ß√£o correta do hash160 usado no Bitcoin (SHA256 seguido de RIPEMD160)\"\"\"\n",
        "    sha = sha256(public_key)\n",
        "    ripe = ripemd160(sha)\n",
        "    return ripe\n",
        "\n",
        "def bitcoin_address_from_private_key(private_key_int):\n",
        "    \"\"\"\n",
        "    Converte uma chave privada (inteiro) para um endere√ßo Bitcoin.\n",
        "    Retorna o endere√ßo Base58Check e o hash160 como array.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Converter para bytes\n",
        "        private_key_hex = f\"{private_key_int:064x}\"\n",
        "        private_key_bytes = bytes.fromhex(private_key_hex)\n",
        "\n",
        "        # Gerar chave p√∫blica\n",
        "        public_key = PublicKey.from_valid_secret(private_key_bytes).format(compressed=False)[1:]\n",
        "\n",
        "        # Op√ß√£o 1: Hash usando Keccak (eth_utils)\n",
        "        hash_keccak = custom_keccak(public_key)[-20:]\n",
        "\n",
        "        # Op√ß√£o 2: Hash usando SHA-256 + RIPEMD-160 (m√©todo Bitcoin tradicional)\n",
        "        hash_bitcoin = bitcoin_hash160(public_key)\n",
        "\n",
        "        # Comparar os dois m√©todos de hash\n",
        "        if hash_keccak != hash_bitcoin:\n",
        "            print(f\"‚ö†Ô∏è Discrep√¢ncia nos m√©todos de hash para chave {private_key_hex[:8]}...\")\n",
        "            print(f\"   Keccak: {hash_keccak.hex()}\")\n",
        "            print(f\"   Bitcoin: {hash_bitcoin.hex()}\")\n",
        "\n",
        "        # Usar o m√©todo Bitcoin (SHA-256 + RIPEMD-160)\n",
        "        hash160 = hash_bitcoin\n",
        "\n",
        "        # Adicionar byte de vers√£o (0x00 para Bitcoin mainnet)\n",
        "        extended = b'\\x00' + hash160\n",
        "\n",
        "        # Calcular checksum (4 primeiros bytes do SHA-256 duplo)\n",
        "        checksum = sha256(sha256(extended))[:4]\n",
        "\n",
        "        # Juntar tudo\n",
        "        address_bytes = extended + checksum\n",
        "\n",
        "        # Codificar em Base58\n",
        "        address = base58.b58encode(address_bytes).decode('ascii')\n",
        "\n",
        "        return address, np.frombuffer(hash160, dtype=np.uint8)\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Erro ao converter chave privada: {e}\")\n",
        "        return None, None\n",
        "\n",
        "def test_conversion():\n",
        "    \"\"\"Testa a convers√£o com chaves privadas e endere√ßos conhecidos.\"\"\"\n",
        "    # Alguns exemplos conhecidos de pares chave privada -> endere√ßo Bitcoin\n",
        "    test_cases = [\n",
        "        # Formato: (chave privada em hex, endere√ßo esperado)\n",
        "        (\"1\", \"1EHNa6Q4Jz2uvNExL497mE43ikXhwF6kZm\"),\n",
        "        (\"FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFEBAAEDCE6AF48A03BBFD25E8CD0364140\", \"1LdHYK73XVvknPTLoTVW7hm3H6LWNdZQKL\"),\n",
        "        (\"0000000000000000000000000000000000000000000000000000000000000001\", \"1BgGZ9tcN4rm9KBzDn7KprQz87SZ26SAMH\")\n",
        "    ]\n",
        "\n",
        "    print(\"üîç Validando convers√£o de chaves privadas para endere√ßos Bitcoin...\")\n",
        "\n",
        "    for i, (priv_key_hex, expected_address) in enumerate(test_cases):\n",
        "        priv_key_int = int(priv_key_hex, 16)\n",
        "        generated_address, hash160 = bitcoin_address_from_private_key(priv_key_int)\n",
        "\n",
        "        if generated_address == expected_address:\n",
        "            print(f\"‚úÖ Teste {i+1}: Endere√ßo correto: {generated_address}\")\n",
        "        else:\n",
        "            print(f\"‚ùå Teste {i+1}: Erro! Esperado: {expected_address}, obtido: {generated_address}\")\n",
        "\n",
        "    # Teste especial para o endere√ßo adicional\n",
        "    golden_address = \"1MVDYgVaSN6iKKEsbzRUAYFrYJadLYZvvZ\"\n",
        "\n",
        "    # Decodificar o endere√ßo para obter o hash160\n",
        "    decoded = base58.b58decode(golden_address)\n",
        "    golden_hash = decoded[1:-4]  # Remove byte de vers√£o e checksum\n",
        "\n",
        "    print(f\"\\nüåü Golden Address: {golden_address}\")\n",
        "    print(f\"   Hash160: {golden_hash.hex()}\")\n",
        "\n",
        "    # Para valida√ß√£o, podemos verificar se o endere√ßo reconstru√≠do corresponde ao original\n",
        "    extended = b'\\x00' + golden_hash\n",
        "    checksum = sha256(sha256(extended))[:4]\n",
        "    address_bytes = extended + checksum\n",
        "    reconstructed = base58.b58encode(address_bytes).decode('ascii')\n",
        "\n",
        "    if reconstructed == golden_address:\n",
        "        print(f\"‚úÖ Valida√ß√£o do Golden Address bem-sucedida\")\n",
        "    else:\n",
        "        print(f\"‚ùå Valida√ß√£o do Golden Address falhou\")\n",
        "\n",
        "    print(\"\\nüîÑ O minerador est√° usando o algoritmo de hash correto para Bitcoin? Verificando...\")\n",
        "    # Verificar se estamos usando o algoritmo correto para Bitcoin\n",
        "    if \"eth_utils\" in globals():\n",
        "        print(\"‚ö†Ô∏è O c√≥digo est√° usando 'eth_utils.keccak' em vez de SHA-256+RIPEMD-160.\")\n",
        "        print(\"   Isso pode causar incompatibilidade com endere√ßos Bitcoin.\")\n",
        "    else:\n",
        "        print(\"‚úÖ O c√≥digo est√° usando SHA-256+RIPEMD-160, que √© o algoritmo correto para Bitcoin.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"=\" * 60)\n",
        "    print(\"üß™ TESTE DE VALIDA√á√ÉO DE CHAVES BITCOIN üß™\")\n",
        "    print(\"=\" * 60)\n",
        "    test_conversion()\n",
        "    print(\"=\" * 60)\n"
      ],
      "metadata": {
        "id": "FL5qEq9R8Fo0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Script para otimizar o ambiente de minera√ß√£o com base nos resultados do teste de batch size\n",
        "Configura o sistema para m√°ximo desempenho de acesso √† GPU\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import subprocess\n",
        "import time\n",
        "import json\n",
        "import multiprocessing\n",
        "\n",
        "def check_environment():\n",
        "    \"\"\"Verifica o ambiente de execu√ß√£o e mostra informa√ß√µes relevantes.\"\"\"\n",
        "    print(\"=\" * 60)\n",
        "    print(\"üîç VERIFICANDO AMBIENTE DE MINERA√á√ÉO\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # Verificar se estamos no Google Colab\n",
        "    is_colab = 'google.colab' in sys.modules\n",
        "    if is_colab:\n",
        "        print(\"‚úÖ Ambiente Google Colab detectado\")\n",
        "\n",
        "        # Verificar informa√ß√µes da GPU\n",
        "        try:\n",
        "            gpu_info = subprocess.run(\"nvidia-smi\", shell=True, stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
        "            print(\"\\nüìä Informa√ß√µes da GPU:\")\n",
        "            for line in gpu_info.split('\\n')[:10]:\n",
        "                print(f\"   {line}\")\n",
        "        except:\n",
        "            print(\"‚ùå GPU n√£o detectada ou nvidia-smi falhou\")\n",
        "    else:\n",
        "        print(\"‚ÑπÔ∏è Executando fora do Google Colab\")\n",
        "\n",
        "    # Verificar CPUs dispon√≠veis\n",
        "    cpu_count = multiprocessing.cpu_count()\n",
        "    print(f\"\\nüìä CPUs dispon√≠veis: {cpu_count}\")\n",
        "\n",
        "    # Verificar mem√≥ria do sistema\n",
        "    try:\n",
        "        if is_colab:\n",
        "            # Usar comando para obter mem√≥ria no Linux\n",
        "            mem_info = subprocess.run(\"free -m\", shell=True, stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
        "            print(\"\\nüìä Informa√ß√µes de mem√≥ria:\")\n",
        "            for line in mem_info.split('\\n')[:3]:\n",
        "                print(f\"   {line}\")\n",
        "        else:\n",
        "            # M√©todo mais gen√©rico\n",
        "            import psutil\n",
        "            vm = psutil.virtual_memory()\n",
        "            print(f\"\\nüìä Mem√≥ria sistema: {vm.total / (1024**3):.1f} GB total, {vm.available / (1024**3):.1f} GB dispon√≠vel\")\n",
        "    except:\n",
        "        print(\"‚ö†Ô∏è N√£o foi poss√≠vel obter informa√ß√µes de mem√≥ria\")\n",
        "\n",
        "    return is_colab\n",
        "\n",
        "def load_batch_test_results():\n",
        "    \"\"\"Carrega resultados do teste de batch size se dispon√≠vel, ou usa valores padr√£o.\"\"\"\n",
        "    try:\n",
        "        with open(\"batch_test_results.json\", \"r\") as f:\n",
        "            results = json.load(f)\n",
        "            print(\"‚úÖ Carregados resultados do teste de batch size anterior\")\n",
        "            return results\n",
        "    except:\n",
        "        # Valores padr√£o caso n√£o tenhamos um arquivo de resultados\n",
        "        print(\"‚ö†Ô∏è Arquivo de resultados n√£o encontrado, usando valores padr√£o\")\n",
        "        return {\n",
        "            \"batch_size\": 32768,\n",
        "            \"subbatch_size\": 67108864,\n",
        "            \"cpu_is_bottleneck\": True,\n",
        "            \"recommended_workers\": multiprocessing.cpu_count() - 1\n",
        "        }\n",
        "\n",
        "def update_runtime_config():\n",
        "    \"\"\"Atualiza configura√ß√µes do ambiente de execu√ß√£o para melhor desempenho.\"\"\"\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"üîß OTIMIZANDO CONFIGURA√á√ïES DE RUNTIME\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # Carregar configura√ß√µes do n√∫cleo do sistema (Linux)\n",
        "    try:\n",
        "        # Configurar para melhor desempenho multithreading\n",
        "        if sys.platform.startswith('linux'):\n",
        "            # Desativar preemption para melhor desempenho de CPU\n",
        "            subprocess.run(\"echo 0 | sudo tee /proc/sys/kernel/sched_rt_runtime_us\",\n",
        "                          shell=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
        "            print(\"‚úÖ Kernel configurado para priorizar tasks de tempo real\")\n",
        "\n",
        "            # Configurar para melhor desempenho de I/O\n",
        "            subprocess.run(\"echo 3 | sudo tee /proc/sys/vm/drop_caches\",\n",
        "                          shell=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
        "            print(\"‚úÖ Caches de sistema liberados para melhor desempenho\")\n",
        "    except:\n",
        "        print(\"‚ö†Ô∏è N√£o foi poss√≠vel otimizar configura√ß√µes do kernel\")\n",
        "\n",
        "    # Configurar Python para melhor desempenho\n",
        "    try:\n",
        "        # Ajustar GC para menos interrup√ß√µes\n",
        "        import gc\n",
        "        gc.disable()\n",
        "        print(\"‚úÖ Garbage collector desabilitado para melhor desempenho\")\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    # Configurar NumPy para usar m√∫ltiplas threads\n",
        "    try:\n",
        "        import numpy as np\n",
        "        np.show_config()\n",
        "        print(\"‚ö†Ô∏è Verifique se NumPy est√° usando MKL para otimiza√ß√£o de performance\")\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    return True\n",
        "\n",
        "def optimize_nvidia_settings():\n",
        "    \"\"\"Otimiza configura√ß√µes espec√≠ficas da GPU NVIDIA.\"\"\"\n",
        "    try:\n",
        "        # Definir modo de performance para m√°ximo desempenho\n",
        "        subprocess.run(\"nvidia-smi -pm 1\", shell=True,\n",
        "                      stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
        "\n",
        "        # Desativar limita√ß√£o de pot√™ncia\n",
        "        subprocess.run(\"nvidia-smi -pl 250\", shell=True,  # 250W ou ajustar conforme sua GPU\n",
        "                      stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
        "\n",
        "        # Configurar para modo de computa√ß√£o\n",
        "        subprocess.run(\"nvidia-smi -c 3\", shell=True,  # Modo EXCLUSIVE_PROCESS\n",
        "                      stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
        "\n",
        "        print(\"‚úÖ GPU NVIDIA otimizada para m√°ximo desempenho\")\n",
        "        return True\n",
        "    except:\n",
        "        print(\"‚ö†Ô∏è N√£o foi poss√≠vel otimizar configura√ß√µes NVIDIA\")\n",
        "        return False\n",
        "\n",
        "def generate_optimized_config():\n",
        "    \"\"\"Gera um arquivo de configura√ß√£o otimizado para o minerador.\"\"\"\n",
        "    # Carregar resultados do teste de batch size\n",
        "    results = load_batch_test_results()\n",
        "\n",
        "    # Determinar valores √≥timos\n",
        "    batch_size = results.get(\"batch_size\", 32768)\n",
        "    subbatch_size = results.get(\"subbatch_size\", 67108864)\n",
        "    cpu_is_bottleneck = results.get(\"cpu_is_bottleneck\", True)\n",
        "\n",
        "    # Determinar n√∫mero de workers com base no n√∫mero de CPUs\n",
        "    cpu_count = multiprocessing.cpu_count()\n",
        "    recommended_workers = max(1, cpu_count - 1)  # Deixar 1 CPU livre para OS\n",
        "\n",
        "    # Criar configura√ß√£o\n",
        "    config = {\n",
        "        \"batch_size\": batch_size,\n",
        "        \"subbatch_size\": subbatch_size,\n",
        "        \"parallel_workers\": recommended_workers,\n",
        "        \"cpu_is_bottleneck\": cpu_is_bottleneck,\n",
        "        \"gpu_memory_fraction\": 0.9,  # Usar 90% da mem√≥ria GPU\n",
        "        \"timestamp\": time.time()\n",
        "    }\n",
        "\n",
        "    # Salvar em arquivo\n",
        "    try:\n",
        "        with open(\"mining_config.json\", \"w\") as f:\n",
        "            json.dump(config, f, indent=2)\n",
        "\n",
        "        print(\"\\n‚úÖ Configura√ß√£o otimizada salva em mining_config.json\")\n",
        "        print(f\"   BATCH_SIZE = {batch_size}\")\n",
        "        print(f\"   SUBBATCH_SIZE = {subbatch_size}\")\n",
        "        print(f\"   PARALLEL_WORKERS = {recommended_workers}\")\n",
        "\n",
        "        # Gerar c√≥digo para incluir no script\n",
        "        print(\"\\nüìã Adicione este c√≥digo ao seu script:\")\n",
        "        print(\"-\" * 60)\n",
        "        print(f\"BATCH_SIZE = {batch_size} if HAS_CUDA else 8192\")\n",
        "        print(f\"SUBBATCH_SIZE = {subbatch_size} if HAS_CUDA else 2**20\")\n",
        "        print(f\"MAX_PARALLEL_WORKERS = {recommended_workers}\")\n",
        "        print(\"-\" * 60)\n",
        "\n",
        "        return config\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Erro ao salvar configura√ß√£o: {e}\")\n",
        "        return None\n",
        "\n",
        "def main():\n",
        "    print(\"=\" * 60)\n",
        "    print(\"üöÄ OTIMIZADOR DE AMBIENTE DE MINERA√á√ÉO\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # Verificar ambiente\n",
        "    is_colab = check_environment()\n",
        "\n",
        "    # Atualizar configura√ß√µes\n",
        "    update_runtime_config()\n",
        "\n",
        "    # Otimizar configura√ß√µes NVIDIA se poss√≠vel\n",
        "    if is_colab:\n",
        "        optimize_nvidia_settings()\n",
        "\n",
        "    # Gerar configura√ß√£o otimizada\n",
        "    config = generate_optimized_config()\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"‚úÖ OTIMIZA√á√ÉO CONCLU√çDA\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # Mostrar pr√≥ximos passos\n",
        "    print(\"\\n‚è≠Ô∏è Pr√≥ximos passos:\")\n",
        "    print(\"1. Execute o minerador com as configura√ß√µes otimizadas\")\n",
        "    print(\"2. Monitore o desempenho para verificar se as otimiza√ß√µes foram eficazes\")\n",
        "    print(\"3. Se necess√°rio, ajuste os par√¢metros manualmente\")\n",
        "\n",
        "    if is_colab:\n",
        "        print(\"\\n‚ö†Ô∏è Lembre-se: No Colab, voc√™ pode precisar reiniciar o runtime\")\n",
        "        print(\"   para que algumas configura√ß√µes tenham efeito.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "gV5U5KgJFZ1v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Gerador paralelo otimizado de endere√ßos Bitcoin para melhorar o desempenho do minerador\n",
        "Resolve o gargalo identificado no teste de batch size (gera√ß√£o de endere√ßos na CPU)\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "import time\n",
        "import multiprocessing\n",
        "from concurrent.futures import ProcessPoolExecutor\n",
        "from coincurve import PublicKey\n",
        "import hashlib\n",
        "import sys\n",
        "\n",
        "# Verificar se temos suporte a RIPEMD160\n",
        "try:\n",
        "    from Crypto.Hash import RIPEMD160\n",
        "    HAS_PYCRYPTO = True\n",
        "except ImportError:\n",
        "    HAS_PYCRYPTO = False\n",
        "    try:\n",
        "        # Tentar instalar\n",
        "        import subprocess\n",
        "        print(\"üîÑ Instalando pycryptodome para suporte RIPEMD160...\")\n",
        "        subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"pycryptodome\"], check=True)\n",
        "        from Crypto.Hash import RIPEMD160\n",
        "        HAS_PYCRYPTO = True\n",
        "    except:\n",
        "        HAS_PYCRYPTO = False\n",
        "\n",
        "def sha256(data):\n",
        "    \"\"\"Calcula SHA-256\"\"\"\n",
        "    return hashlib.sha256(data).digest()\n",
        "\n",
        "def ripemd160(data):\n",
        "    \"\"\"Calcula RIPEMD-160 com suporte a diferentes implementa√ß√µes\"\"\"\n",
        "    if HAS_PYCRYPTO:\n",
        "        h = RIPEMD160.new()\n",
        "        h.update(data)\n",
        "        return h.digest()\n",
        "    else:\n",
        "        # Usar hashlib ou implementa√ß√£o alternativa\n",
        "        # Aviso: O hashlib padr√£o pode n√£o suportar RIPEMD160\n",
        "        import hashlib\n",
        "        try:\n",
        "            h = hashlib.new('ripemd160')\n",
        "            h.update(data)\n",
        "            return h.digest()\n",
        "        except:\n",
        "            # √öltimo recurso, usar SHA-1 (N√ÉO RECOMENDADO para produ√ß√£o!)\n",
        "            print(\"‚ö†Ô∏è AVISO: Usando SHA-1 como substituto para RIPEMD160 (n√£o seguro)\")\n",
        "            return hashlib.sha1(data).digest()\n",
        "\n",
        "def hash160(public_key):\n",
        "    \"\"\"Implementa√ß√£o padr√£o Bitcoin: SHA-256 seguido de RIPEMD-160\"\"\"\n",
        "    h = sha256(public_key)\n",
        "    return ripemd160(h)\n",
        "\n",
        "def generate_bitcoin_address(private_key):\n",
        "    \"\"\"\n",
        "    Gera um endere√ßo Bitcoin a partir de uma chave privada.\n",
        "\n",
        "    Args:\n",
        "        private_key: Chave privada em formato n√∫mero inteiro\n",
        "\n",
        "    Returns:\n",
        "        ndarray: Array NumPy (20 bytes) contendo o hash160 do endere√ßo\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Converter para bytes\n",
        "        key_hex = f\"{private_key:064x}\"\n",
        "        key_bytes = bytes.fromhex(key_hex)\n",
        "\n",
        "        # Gerar chave p√∫blica\n",
        "        public_key = PublicKey.from_valid_secret(key_bytes).format(compressed=False)[1:]\n",
        "\n",
        "        # Calcular hash160 (SHA-256 + RIPEMD-160)\n",
        "        hash_bytes = hash160(public_key)\n",
        "\n",
        "        # Retornar array NumPy\n",
        "        return np.frombuffer(hash_bytes, dtype=np.uint8)\n",
        "    except Exception:\n",
        "        # Retornar zeros em caso de erro\n",
        "        return np.zeros(20, dtype=np.uint8)\n",
        "\n",
        "def process_key_chunk(key_chunk, chunk_idx=0):\n",
        "    \"\"\"\n",
        "    Processa um conjunto de chaves em paralelo.\n",
        "\n",
        "    Args:\n",
        "        key_chunk: Lista de chaves privadas\n",
        "        chunk_idx: √çndice do chunk (para logging)\n",
        "\n",
        "    Returns:\n",
        "        ndarray: Array NumPy (n_keys, 20) contendo os hash160 dos endere√ßos\n",
        "    \"\"\"\n",
        "    n_keys = len(key_chunk)\n",
        "    addresses = np.zeros((n_keys, 20), dtype=np.uint8)\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    for i, key in enumerate(key_chunk):\n",
        "        try:\n",
        "            addresses[i] = generate_bitcoin_address(key)\n",
        "        except Exception as e:\n",
        "            # Manter zeros em caso de erro\n",
        "            if i % 1000 == 0:\n",
        "                print(f\"‚ö†Ô∏è Erro no chunk {chunk_idx}, key {i}: {e}\")\n",
        "\n",
        "    elapsed = time.time() - start_time\n",
        "    rate = n_keys / elapsed if elapsed > 0 else 0\n",
        "\n",
        "    if chunk_idx % 10 == 0:  # Reduzir o volume de logs\n",
        "        print(f\"‚úÖ Chunk {chunk_idx}: {n_keys} endere√ßos em {elapsed:.2f}s ({rate:.0f}/s)\")\n",
        "\n",
        "    return addresses\n",
        "\n",
        "def generate_addresses_parallel(keys, max_workers=None, chunk_size=1000):\n",
        "    \"\"\"\n",
        "    Gera endere√ßos Bitcoin em paralelo para um conjunto de chaves.\n",
        "\n",
        "    Args:\n",
        "        keys: Lista de chaves privadas\n",
        "        max_workers: N√∫mero m√°ximo de workers (None = auto, baseado em CPU cores)\n",
        "        chunk_size: Tamanho do chunk para cada worker processar\n",
        "\n",
        "    Returns:\n",
        "        ndarray: Array NumPy (n_keys, 20) contendo os hash160 dos endere√ßos\n",
        "    \"\"\"\n",
        "    if max_workers is None:\n",
        "        # Usar n√∫mero de CPUs dispon√≠veis, menos 1 para n√£o travar o sistema\n",
        "        max_workers = max(1, multiprocessing.cpu_count() - 1)\n",
        "\n",
        "    n_keys = len(keys)\n",
        "    print(f\"üîÑ Gerando {n_keys} endere√ßos com {max_workers} workers em paralelo...\")\n",
        "\n",
        "    # Criar array para resultado final\n",
        "    all_addresses = np.zeros((n_keys, 20), dtype=np.uint8)\n",
        "\n",
        "    # Dividir as chaves em chunks\n",
        "    if chunk_size <= 0:\n",
        "        chunk_size = max(1, n_keys // (max_workers * 2))\n",
        "\n",
        "    chunks = []\n",
        "    for i in range(0, n_keys, chunk_size):\n",
        "        end = min(i + chunk_size, n_keys)\n",
        "        chunks.append(keys[i:end])\n",
        "\n",
        "    n_chunks = len(chunks)\n",
        "    print(f\"üìä Processando {n_chunks} chunks de {chunk_size} chaves cada\")\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    try:\n",
        "        # Usar ProcessPoolExecutor para paralelismo real (multiprocessamento)\n",
        "        with ProcessPoolExecutor(max_workers=max_workers) as executor:\n",
        "            futures = []\n",
        "\n",
        "            # Submeter todos os chunks para processamento\n",
        "            for i, chunk in enumerate(chunks):\n",
        "                futures.append(executor.submit(process_key_chunk, chunk, i))\n",
        "\n",
        "            # Coletar resultados na ordem\n",
        "            for i, future in enumerate(futures):\n",
        "                try:\n",
        "                    # Obter resultado do chunk\n",
        "                    addresses = future.result()\n",
        "\n",
        "                    # Copiar para o array final\n",
        "                    start_idx = i * chunk_size\n",
        "                    end_idx = min(start_idx + len(addresses), n_keys)\n",
        "                    all_addresses[start_idx:end_idx] = addresses\n",
        "                except Exception as e:\n",
        "                    print(f\"‚ùå Erro ao processar chunk {i}: {e}\")\n",
        "\n",
        "    except KeyboardInterrupt:\n",
        "        print(\"‚ö†Ô∏è Interrompido pelo usu√°rio\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Erro no processamento paralelo: {e}\")\n",
        "\n",
        "        # Tentar abordagem sequencial como fallback\n",
        "        print(\"‚ö†Ô∏è Tentando processamento sequencial como fallback...\")\n",
        "        for i, key in enumerate(keys):\n",
        "            try:\n",
        "                all_addresses[i] = generate_bitcoin_address(key)\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "    elapsed = time.time() - start_time\n",
        "    rate = n_keys / elapsed if elapsed > 0 else 0\n",
        "\n",
        "    print(f\"‚úÖ Gera√ß√£o paralela conclu√≠da: {n_keys} endere√ßos em {elapsed:.2f}s\")\n",
        "    print(f\"üìä Taxa: {rate:.0f} endere√ßos/s ({rate/1e6:.2f} Mend/s)\")\n",
        "\n",
        "    return all_addresses\n",
        "\n",
        "def test_performance(n_keys=10000):\n",
        "    \"\"\"Executa um teste de desempenho da gera√ß√£o paralela de endere√ßos.\"\"\"\n",
        "    print(\"=\" * 60)\n",
        "    print(\"üöÄ TESTE DE DESEMPENHO - GERA√á√ÉO PARALELA DE ENDERE√áOS\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # Gerar chaves aleat√≥rias para teste\n",
        "    print(f\"üîÑ Gerando {n_keys} chaves aleat√≥rias...\")\n",
        "    keys = [int.from_bytes(np.random.bytes(32), 'big') % (2**256 - 2**32 - 977) + 1\n",
        "            for _ in range(n_keys)]\n",
        "\n",
        "    # Teste sequencial\n",
        "    print(\"\\nüîÑ Teste sequencial:\")\n",
        "    start_time = time.time()\n",
        "    addresses_seq = np.zeros((n_keys, 20), dtype=np.uint8)\n",
        "    for i, key in enumerate(keys):\n",
        "        addresses_seq[i] = generate_bitcoin_address(key)\n",
        "    seq_elapsed = time.time() - start_time\n",
        "    seq_rate = n_keys / seq_elapsed\n",
        "\n",
        "    print(f\"‚úÖ Sequencial: {seq_elapsed:.2f}s ({seq_rate:.0f} end/s)\")\n",
        "\n",
        "    # Teste com diferentes n√∫meros de workers\n",
        "    for workers in [2, 4, 8, 16]:\n",
        "        if workers > multiprocessing.cpu_count():\n",
        "            continue  # Pular se n√£o tivermos CPUs suficientes\n",
        "\n",
        "        print(f\"\\nüîÑ Teste paralelo com {workers} workers:\")\n",
        "        start_time = time.time()\n",
        "        addresses_par = generate_addresses_parallel(keys, max_workers=workers)\n",
        "        par_elapsed = time.time() - start_time\n",
        "        par_rate = n_keys / par_elapsed\n",
        "\n",
        "        # Verificar se os resultados s√£o iguais\n",
        "        matches = np.sum(np.all(addresses_seq == addresses_par, axis=1))\n",
        "        accuracy = (matches / n_keys) * 100\n",
        "\n",
        "        speedup = seq_elapsed / par_elapsed if par_elapsed > 0 else 0\n",
        "        print(f\"‚úÖ Paralelo: {par_elapsed:.2f}s ({par_rate:.0f} end/s)\")\n",
        "        print(f\"üìä Speedup: {speedup:.1f}x | Precis√£o: {accuracy:.2f}%\")\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Executar teste de desempenho se for chamado diretamente\n",
        "    test_performance(n_keys=20000)\n"
      ],
      "metadata": {
        "id": "oIjwB0TqFqGO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "M√≥dulo auxiliar para processamento paralelo de endere√ßos Bitcoin\n",
        "Resolve o erro de pickling em fun√ß√µes aninhadas\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "from coincurve import PublicKey\n",
        "import hashlib\n",
        "\n",
        "# Fun√ß√µes de hashing t√™m que estar no escopo global para serem pickable\n",
        "def sha256(data):\n",
        "    \"\"\"Calcula SHA-256\"\"\"\n",
        "    return hashlib.sha256(data).digest()\n",
        "\n",
        "def ripemd160(data):\n",
        "    \"\"\"Calcula RIPEMD-160 com suporte a diferentes implementa√ß√µes\"\"\"\n",
        "    try:\n",
        "        from Crypto.Hash import RIPEMD160\n",
        "        h = RIPEMD160.new()\n",
        "        h.update(data)\n",
        "        return h.digest()\n",
        "    except ImportError:\n",
        "        # Fallback para hashlib se dispon√≠vel\n",
        "        try:\n",
        "            h = hashlib.new('ripemd160')\n",
        "            h.update(data)\n",
        "            return h.digest()\n",
        "        except:\n",
        "            # √öltimo recurso (n√£o recomendado para produ√ß√£o)\n",
        "            return hashlib.sha1(data).digest()\n",
        "\n",
        "def bitcoin_hash160(public_key):\n",
        "    \"\"\"Implementa√ß√£o padr√£o Bitcoin: SHA-256 seguido de RIPEMD-160\"\"\"\n",
        "    h = sha256(public_key)\n",
        "    return ripemd160(h)\n",
        "\n",
        "def process_keys_chunk(chunk_data):\n",
        "    \"\"\"\n",
        "    Processa um conjunto de chaves em paralelo.\n",
        "\n",
        "    Args:\n",
        "        chunk_data: Tupla (keys, start_idx, end_idx)\n",
        "\n",
        "    Returns:\n",
        "        ndarray: Array NumPy contendo os hash160 dos endere√ßos\n",
        "    \"\"\"\n",
        "    keys, start_idx, end_idx = chunk_data\n",
        "    chunk_size = end_idx - start_idx\n",
        "    addresses = np.zeros((chunk_size, 20), dtype=np.uint8)\n",
        "\n",
        "    # Pr√©-inicializar objetos para evitar recria√ß√£o constante\n",
        "    try:\n",
        "        from Crypto.Hash import RIPEMD160\n",
        "        ripemd = RIPEMD160.new\n",
        "        has_pycrypto = True\n",
        "\n",
        "        # Pr√©-inicializar fun√ß√£o PublicKey para melhor performance\n",
        "        from coincurve import PublicKey\n",
        "        get_public_key = lambda priv_bytes: PublicKey.from_valid_secret(priv_bytes).format(compressed=False)[1:]\n",
        "\n",
        "        # Pr√©-inicializar SHA256\n",
        "        import hashlib\n",
        "        sha256_func = hashlib.sha256\n",
        "    except ImportError:\n",
        "        has_pycrypto = False\n",
        "\n",
        "    # Otimiza√ß√£o: Processar em blocos para melhorar cache locality\n",
        "    block_size = 128  # Tamanho do bloco\n",
        "\n",
        "    for block_start in range(0, chunk_size, block_size):\n",
        "        block_end = min(block_start + block_size, chunk_size)\n",
        "\n",
        "        # Processar bloco\n",
        "        for i in range(block_start, block_end):\n",
        "            idx = i + start_idx\n",
        "            if idx >= len(keys):\n",
        "                break\n",
        "\n",
        "            try:\n",
        "                key = keys[idx]\n",
        "                # Converter para bytes e calcular endere√ßo\n",
        "                key_hex = f\"{key:064x}\"\n",
        "                pk_bytes = bytes.fromhex(key_hex)\n",
        "\n",
        "                # Criar chave p√∫blica (sem copiar dados desnecess√°rios)\n",
        "                public_key = get_public_key(pk_bytes)\n",
        "\n",
        "                # Hash SHA-256 otimizado\n",
        "                h = sha256_func(public_key).digest()\n",
        "\n",
        "                # RIPEMD-160 otimizado\n",
        "                if has_pycrypto:\n",
        "                    # Vers√£o mais r√°pida com pycryptodome\n",
        "                    r = ripemd()\n",
        "                    r.update(h)\n",
        "                    hash_bytes = r.digest()\n",
        "                else:\n",
        "                    hash_bytes = ripemd160(h)\n",
        "\n",
        "                # Armazenar resultado sem c√≥pias desnecess√°rias\n",
        "                addresses[i] = np.frombuffer(hash_bytes, dtype=np.uint8)\n",
        "            except Exception:\n",
        "                # Manter zeros em caso de erro\n",
        "                pass\n",
        "\n",
        "    return addresses\n",
        "\n",
        "def batch_generate_addresses(keys, max_workers=8, chunk_size=None):\n",
        "    \"\"\"\n",
        "    Fun√ß√£o wrapper para facilitar o uso do processamento paralelo\n",
        "\n",
        "    Args:\n",
        "        keys: Lista de chaves privadas\n",
        "        max_workers: N√∫mero m√°ximo de workers\n",
        "        chunk_size: Tamanho de cada chunk (se None, calcula automaticamente)\n",
        "\n",
        "    Returns:\n",
        "        ndarray: Array NumPy (n_keys, 20) contendo os hash160 dos endere√ßos\n",
        "    \"\"\"\n",
        "    from concurrent.futures import ProcessPoolExecutor\n",
        "    import multiprocessing\n",
        "    import os\n",
        "\n",
        "    # Definir vari√°veis de ambiente para melhorar performance das libs\n",
        "    os.environ[\"OMP_NUM_THREADS\"] = \"1\"  # Evitar que numpy crie threads em cada processo\n",
        "\n",
        "    if max_workers is None or max_workers <= 0:\n",
        "        max_workers = max(1, multiprocessing.cpu_count())\n",
        "\n",
        "    batch_size = len(keys)\n",
        "    addresses = np.zeros((batch_size, 20), dtype=np.uint8)\n",
        "\n",
        "    # Calcular tamanho dos chunks - otimizado para reduzir overhead\n",
        "    if chunk_size is None:\n",
        "        # Para A100, mais workers com chunks menores funcionam melhor\n",
        "        chunk_size = 2000  # Valor otimizado para A100\n",
        "\n",
        "    # Preparar chunks para processamento\n",
        "    chunks_data = []\n",
        "    for start in range(0, batch_size, chunk_size):\n",
        "        end = min(start + chunk_size, batch_size)\n",
        "        chunks_data.append((keys, start, end))\n",
        "\n",
        "    # Otimiza√ß√£o: usar start_method='spawn' para evitar problemas de fork\n",
        "    context = multiprocessing.get_context('spawn')\n",
        "\n",
        "    # Processar em paralelo com um timeout maior e controle de falhas\n",
        "    with ProcessPoolExecutor(max_workers=max_workers, mp_context=context) as executor:\n",
        "        try:\n",
        "            # Usar chunksize=1 para melhor balanceamento\n",
        "            results = list(executor.map(process_keys_chunk, chunks_data, chunksize=1, timeout=180))\n",
        "        except Exception as e:\n",
        "            # Em caso de falha, processar sequencialmente\n",
        "            print(f\"‚ö†Ô∏è Falha no processamento paralelo: {e}\")\n",
        "            print(f\"‚ö†Ô∏è Tentando m√©todo sequencial...\")\n",
        "            addresses = np.zeros((len(keys), 20), dtype=np.uint8)\n",
        "            for i, key in enumerate(keys):\n",
        "                try:\n",
        "                    key_hex = f\"{key:064x}\"\n",
        "                    pk_bytes = bytes.fromhex(key_hex)\n",
        "                    public_key = PublicKey.from_valid_secret(pk_bytes).format(compressed=False)[1:]\n",
        "                    hash_bytes = bitcoin_hash160(public_key)\n",
        "                    addresses[i] = np.frombuffer(hash_bytes, dtype=np.uint8)\n",
        "                except Exception:\n",
        "                    pass  # Manter zeros em caso de erro\n",
        "            return addresses\n",
        "\n",
        "    # Unificar resultados\n",
        "    for i, chunk_result in enumerate(results):\n",
        "        start_idx = i * chunk_size\n",
        "        end_idx = min(start_idx + chunk_size, batch_size)\n",
        "        if start_idx < batch_size:  # Verificar limites\n",
        "            actual_chunk_size = min(chunk_size, batch_size - start_idx)\n",
        "            addresses[start_idx:end_idx] = chunk_result[:actual_chunk_size]\n",
        "\n",
        "    return addresses\n"
      ],
      "metadata": {
        "id": "f6MZG65dnMED"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!apt install batch_generate_addresses"
      ],
      "metadata": {
        "id": "L4eAvrcWpre_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "M√≥dulo para pr√©-computa√ß√£o de endere√ßos Bitcoin em background\n",
        "Implementa um modelo produtor-consumidor para reduzir o gargalo de CPU\n",
        "\"\"\"\n",
        "import threading\n",
        "import queue\n",
        "import time\n",
        "import numpy as np\n",
        "# from fixed_multiprocess import batch_generate_addresses\n",
        "import multiprocessing\n",
        "\n",
        "class AddressPrecomputer:\n",
        "    \"\"\"\n",
        "    Classe para pr√©-computar endere√ßos Bitcoin em threads de background.\n",
        "    Usa um modelo produtor-consumidor para alimentar o processamento GPU.\n",
        "    \"\"\"\n",
        "    def __init__(self, batch_size=32768, buffer_size=3, max_workers=None):\n",
        "        \"\"\"\n",
        "        Inicializa o sistema de pr√©-computa√ß√£o de endere√ßos.\n",
        "\n",
        "        Args:\n",
        "            batch_size: Tamanho de cada lote de endere√ßos\n",
        "            buffer_size: N√∫mero de lotes pr√©-computados a manter em buffer\n",
        "            max_workers: N√∫mero m√°ximo de workers para o processamento paralelo\n",
        "        \"\"\"\n",
        "        self.batch_size = batch_size\n",
        "        self.address_queue = queue.Queue(maxsize=buffer_size)\n",
        "        self.stop_event = threading.Event()\n",
        "        self.max_workers = max_workers or max(1, multiprocessing.cpu_count() - 1)\n",
        "        self.producer_thread = None\n",
        "        self.active = False\n",
        "\n",
        "        # Estat√≠sticas\n",
        "        self.total_generated = 0\n",
        "        self.total_consumed = 0\n",
        "        self.start_time = 0\n",
        "\n",
        "    def start(self, range_start, range_end):\n",
        "        \"\"\"\n",
        "        Inicia o thread produtor para gerar endere√ßos em background.\n",
        "\n",
        "        Args:\n",
        "            range_start: In√≠cio do intervalo de chaves\n",
        "            range_end: Fim do intervalo de chaves\n",
        "        \"\"\"\n",
        "        if self.active:\n",
        "            return\n",
        "\n",
        "        self.range_start = range_start\n",
        "        self.range_end = range_end\n",
        "        self.stop_event.clear()\n",
        "        self.active = True\n",
        "        self.start_time = time.time()\n",
        "\n",
        "        # Iniciar thread produtor\n",
        "        self.producer_thread = threading.Thread(\n",
        "            target=self._producer_task,\n",
        "            args=(range_start, range_end),\n",
        "            daemon=True\n",
        "        )\n",
        "        self.producer_thread.start()\n",
        "\n",
        "        print(f\"‚úÖ Iniciado pr√©-computador de endere√ßos com buffer de {self.address_queue.maxsize} lotes\")\n",
        "\n",
        "    def stop(self):\n",
        "        \"\"\"Para o thread produtor e limpa o buffer.\"\"\"\n",
        "        self.stop_event.set()\n",
        "        self.active = False\n",
        "\n",
        "        # Esvaziar a fila\n",
        "        while not self.address_queue.empty():\n",
        "            try:\n",
        "                self.address_queue.get_nowait()\n",
        "                self.address_queue.task_done()\n",
        "            except queue.Empty:\n",
        "                break\n",
        "\n",
        "    def _producer_task(self, range_start, range_end):\n",
        "        \"\"\"Tarefa de thread produtor que gera endere√ßos continuamente.\"\"\"\n",
        "        # Calcular o tamanho do intervalo como bigint para evitar overflow\n",
        "        sub_size = range_end - range_start + 1\n",
        "        batch_idx = 0\n",
        "\n",
        "        # Otimiza√ß√£o: usar multiprocessing.set_start_method('spawn') para evitar problemas\n",
        "        import multiprocessing\n",
        "        try:\n",
        "            multiprocessing.set_start_method('spawn', force=True)\n",
        "        except RuntimeError:\n",
        "            # J√° foi configurado\n",
        "            pass\n",
        "\n",
        "        # Verificar e informar sobre o tamanho do intervalo\n",
        "        range_too_large_for_uint32 = sub_size > 0xFFFFFFFF  # Maior que 2^32 - 1\n",
        "        range_too_large_for_uint64 = sub_size > 0xFFFFFFFFFFFFFFFF  # Maior que 2^64 - 1\n",
        "\n",
        "        if range_too_large_for_uint32:\n",
        "            if range_too_large_for_uint64:\n",
        "                print(f\"‚ö†Ô∏è Range extremamente grande: {sub_size} (> uint64, usando m√©todo bytes)\")\n",
        "            else:\n",
        "                print(f\"‚ö†Ô∏è Range grande: {sub_size} (> uint32, usando uint64)\")\n",
        "\n",
        "        while not self.stop_event.is_set():\n",
        "            try:\n",
        "                # Verificar se a fila j√° est√° cheia\n",
        "                if self.address_queue.qsize() >= self.address_queue.maxsize:\n",
        "                    # Pausar brevemente se o buffer estiver cheio\n",
        "                    time.sleep(0.5)\n",
        "                    continue\n",
        "\n",
        "                # Gerar chaves aleat√≥rias - usando a estrat√©gia apropriada para o tamanho do intervalo\n",
        "                keys = []\n",
        "\n",
        "                # Estrat√©gia baseada no tamanho do intervalo\n",
        "                if not range_too_large_for_uint32:\n",
        "                    # CASO 1: Intervalo cabe em uint32 - usar m√©todo padr√£o randint\n",
        "                    offsets = np.random.randint(0, sub_size, size=self.batch_size, dtype=np.uint32)\n",
        "                    keys = [range_start + int(offset) for offset in offsets]\n",
        "\n",
        "                elif not range_too_large_for_uint64:\n",
        "                    # CASO 2: Intervalo maior que uint32 mas cabe em uint64\n",
        "                    try:\n",
        "                        # Primeiro, tentar usar uint64 diretamente\n",
        "                        offsets = np.random.randint(0, sub_size, size=self.batch_size, dtype=np.uint64)\n",
        "                        keys = [range_start + int(offset) for offset in offsets]\n",
        "                    except OverflowError:\n",
        "                        # Fallback para o m√©todo de bytes individuais\n",
        "                        for _ in range(self.batch_size):\n",
        "                            # Usar m√©todo bit a bit (at√© 64 bits)\n",
        "                            max_bits = 64\n",
        "                            random_bits = np.random.randint(0, 2, size=max_bits, dtype=np.uint8)\n",
        "                            random_value = 0\n",
        "                            for i, bit in enumerate(random_bits):\n",
        "                                if bit:\n",
        "                                    random_value |= (1 << i)\n",
        "\n",
        "                            # Aplicar m√≥dulo para ficar no intervalo correto\n",
        "                            random_value = random_value % sub_size\n",
        "                            keys.append(range_start + random_value)\n",
        "\n",
        "                else:\n",
        "                    # CASO 3: Intervalo extremamente grande (> uint64)\n",
        "                    for _ in range(self.batch_size):\n",
        "                        # Usar m√©todo de bytes aleat√≥rios (funciona para qualquer tamanho)\n",
        "                        num_bytes = (sub_size.bit_length() + 7) // 8\n",
        "                        num_bytes = max(num_bytes, 16)  # Pelo menos 16 bytes (128 bits)\n",
        "\n",
        "                        # Gerar bytes aleat√≥rios e converter para inteiro\n",
        "                        random_bytes = np.random.bytes(num_bytes)\n",
        "                        random_value = int.from_bytes(random_bytes, byteorder='big')\n",
        "\n",
        "                        # Garantir que est√° dentro do intervalo\n",
        "                        random_value = random_value % sub_size\n",
        "                        keys.append(range_start + random_value)\n",
        "\n",
        "                # Gerar endere√ßos em paralelo\n",
        "                start_time = time.time()\n",
        "                addresses = batch_generate_addresses(\n",
        "                    keys,\n",
        "                    max_workers=self.max_workers,\n",
        "                    chunk_size=2000  # Otimizado para A100\n",
        "                )\n",
        "                gen_time = time.time() - start_time\n",
        "\n",
        "                # Adicionar ao buffer\n",
        "                self.address_queue.put((keys, addresses, gen_time), block=True)\n",
        "\n",
        "                self.total_generated += self.batch_size\n",
        "                batch_idx += 1\n",
        "\n",
        "                rate = self.batch_size / gen_time if gen_time > 0 else 0\n",
        "                if batch_idx % 5 == 0:  # Log a cada 5 batches\n",
        "                    print(f\"üîÑ Pr√©-computado lote {batch_idx}: {rate/1e6:.2f} Mend/s (buffer: {self.address_queue.qsize()}/{self.address_queue.maxsize})\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"‚ö†Ô∏è Erro no produtor de endere√ßos: {e}\")\n",
        "                import traceback\n",
        "                traceback.print_exc()\n",
        "                # Pausa para n√£o sobrecarregar em caso de erros\n",
        "                time.sleep(1.0)\n",
        "\n",
        "    def get_next_batch(self, timeout=None):\n",
        "        \"\"\"\n",
        "        Retorna o pr√≥ximo lote de endere√ßos pr√©-computados.\n",
        "\n",
        "        Args:\n",
        "            timeout: Tempo m√°ximo de espera em segundos (None = esperar indefinidamente)\n",
        "\n",
        "        Returns:\n",
        "            tuple: (keys, addresses, generation_time) ou None se timeout\n",
        "        \"\"\"\n",
        "        if not self.active:\n",
        "            return None\n",
        "\n",
        "        try:\n",
        "            # Obter pr√≥ximo lote (bloqueia at√© que um esteja dispon√≠vel)\n",
        "            next_batch = self.address_queue.get(block=True, timeout=timeout)\n",
        "            self.address_queue.task_done()\n",
        "\n",
        "            # Atualizar estat√≠sticas\n",
        "            self.total_consumed += self.batch_size\n",
        "\n",
        "            # Mostrar estat√≠sticas gerais\n",
        "            elapsed = time.time() - self.start_time\n",
        "            if elapsed > 0:\n",
        "                avg_speed = self.total_consumed / elapsed / 1e6  # Mend/s\n",
        "                print(f\"üìä Taxa m√©dia: {avg_speed:.2f} Mend/s | Gerados: {self.total_generated:,} | Consumidos: {self.total_consumed:,}\")\n",
        "\n",
        "            return next_batch\n",
        "        except queue.Empty:\n",
        "            print(\"‚ö†Ô∏è Timeout ao aguardar por endere√ßos pr√©-computados\")\n",
        "            return None\n",
        "\n",
        "    def get_stats(self):\n",
        "        \"\"\"Retorna estat√≠sticas do pr√©-computador.\"\"\"\n",
        "        elapsed = time.time() - self.start_time if self.start_time > 0 else 0\n",
        "        return {\n",
        "            \"total_generated\": self.total_generated,\n",
        "            \"total_consumed\": self.total_consumed,\n",
        "            \"elapsed_time\": elapsed,\n",
        "            \"average_speed\": self.total_consumed / elapsed if elapsed > 0 else 0,\n",
        "            \"buffer_status\": f\"{self.address_queue.qsize()}/{self.address_queue.maxsize}\"\n",
        "        }\n"
      ],
      "metadata": {
        "id": "j9y_abxLnfSE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!apt install multiprocessing"
      ],
      "metadata": {
        "id": "U9SJe-YyoD_t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Script para criar manualmente os arquivos de m√≥dulo no Google Colab\n",
        "\"\"\"\n",
        "import os\n",
        "\n",
        "def create_fixed_multiprocess():\n",
        "    \"\"\"Cria o arquivo fixed_multiprocess.py no diret√≥rio atual\"\"\"\n",
        "    code = '''\"\"\"\n",
        "M√≥dulo auxiliar para processamento paralelo de endere√ßos Bitcoin\n",
        "Resolve o erro de pickling em fun√ß√µes aninhadas\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "from coincurve import PublicKey\n",
        "import hashlib\n",
        "\n",
        "# Fun√ß√µes de hashing t√™m que estar no escopo global para serem pickable\n",
        "def sha256(data):\n",
        "    \"\"\"Calcula SHA-256\"\"\"\n",
        "    return hashlib.sha256(data).digest()\n",
        "\n",
        "def ripemd160(data):\n",
        "    \"\"\"Calcula RIPEMD-160 com suporte a diferentes implementa√ß√µes\"\"\"\n",
        "    try:\n",
        "        from Crypto.Hash import RIPEMD160\n",
        "        h = RIPEMD160.new()\n",
        "        h.update(data)\n",
        "        return h.digest()\n",
        "    except ImportError:\n",
        "        # Fallback para hashlib se dispon√≠vel\n",
        "        try:\n",
        "            h = hashlib.new('ripemd160')\n",
        "            h.update(data)\n",
        "            return h.digest()\n",
        "        except:\n",
        "            # √öltimo recurso (n√£o recomendado para produ√ß√£o)\n",
        "            return hashlib.sha1(data).digest()\n",
        "\n",
        "def bitcoin_hash160(public_key):\n",
        "    \"\"\"Implementa√ß√£o padr√£o Bitcoin: SHA-256 seguido de RIPEMD-160\"\"\"\n",
        "    h = sha256(public_key)\n",
        "    return ripemd160(h)\n",
        "\n",
        "def process_keys_chunk(chunk_data):\n",
        "    \"\"\"\n",
        "    Processa um conjunto de chaves em paralelo.\n",
        "\n",
        "    Args:\n",
        "        chunk_data: Tupla (keys, start_idx, end_idx)\n",
        "\n",
        "    Returns:\n",
        "        ndarray: Array NumPy contendo os hash160 dos endere√ßos\n",
        "    \"\"\"\n",
        "    keys, start_idx, end_idx = chunk_data\n",
        "    chunk_size = end_idx - start_idx\n",
        "    addresses = np.zeros((chunk_size, 20), dtype=np.uint8)\n",
        "\n",
        "    # Pr√©-inicializar objetos para evitar recria√ß√£o constante\n",
        "    try:\n",
        "        from Crypto.Hash import RIPEMD160\n",
        "        ripemd = RIPEMD160.new\n",
        "        has_pycrypto = True\n",
        "\n",
        "        # Pr√©-inicializar fun√ß√£o PublicKey para melhor performance\n",
        "        from coincurve import PublicKey\n",
        "        get_public_key = lambda priv_bytes: PublicKey.from_valid_secret(priv_bytes).format(compressed=False)[1:]\n",
        "\n",
        "        # Pr√©-inicializar SHA256\n",
        "        import hashlib\n",
        "        sha256_func = hashlib.sha256\n",
        "    except ImportError:\n",
        "        has_pycrypto = False\n",
        "\n",
        "    # Otimiza√ß√£o: Processar em blocos para melhorar cache locality\n",
        "    block_size = 128  # Tamanho do bloco\n",
        "\n",
        "    for block_start in range(0, chunk_size, block_size):\n",
        "        block_end = min(block_start + block_size, chunk_size)\n",
        "\n",
        "        # Processar bloco\n",
        "        for i in range(block_start, block_end):\n",
        "            idx = i + start_idx\n",
        "            if idx >= len(keys):\n",
        "                break\n",
        "\n",
        "            try:\n",
        "                key = keys[idx]\n",
        "                # Converter para bytes e calcular endere√ßo\n",
        "                key_hex = f\"{key:064x}\"\n",
        "                pk_bytes = bytes.fromhex(key_hex)\n",
        "\n",
        "                # Criar chave p√∫blica (sem copiar dados desnecess√°rios)\n",
        "                public_key = get_public_key(pk_bytes)\n",
        "\n",
        "                # Hash SHA-256 otimizado\n",
        "                h = sha256_func(public_key).digest()\n",
        "\n",
        "                # RIPEMD-160 otimizado\n",
        "                if has_pycrypto:\n",
        "                    # Vers√£o mais r√°pida com pycryptodome\n",
        "                    r = ripemd()\n",
        "                    r.update(h)\n",
        "                    hash_bytes = r.digest()\n",
        "                else:\n",
        "                    hash_bytes = ripemd160(h)\n",
        "\n",
        "                # Armazenar resultado sem c√≥pias desnecess√°rias\n",
        "                addresses[i] = np.frombuffer(hash_bytes, dtype=np.uint8)\n",
        "            except Exception:\n",
        "                # Manter zeros em caso de erro\n",
        "                pass\n",
        "\n",
        "    return addresses\n",
        "\n",
        "def batch_generate_addresses(keys, max_workers=8, chunk_size=None):\n",
        "    \"\"\"\n",
        "    Fun√ß√£o wrapper para facilitar o uso do processamento paralelo\n",
        "\n",
        "    Args:\n",
        "        keys: Lista de chaves privadas\n",
        "        max_workers: N√∫mero m√°ximo de workers\n",
        "        chunk_size: Tamanho de cada chunk (se None, calcula automaticamente)\n",
        "\n",
        "    Returns:\n",
        "        ndarray: Array NumPy (n_keys, 20) contendo os hash160 dos endere√ßos\n",
        "    \"\"\"\n",
        "    from concurrent.futures import ProcessPoolExecutor\n",
        "    import multiprocessing\n",
        "    import os\n",
        "\n",
        "    # Definir vari√°veis de ambiente para melhorar performance das libs\n",
        "    os.environ[\"OMP_NUM_THREADS\"] = \"1\"  # Evitar que numpy crie threads em cada processo\n",
        "\n",
        "    if max_workers is None or max_workers <= 0:\n",
        "        max_workers = max(1, multiprocessing.cpu_count())\n",
        "\n",
        "    batch_size = len(keys)\n",
        "    addresses = np.zeros((batch_size, 20), dtype=np.uint8)\n",
        "\n",
        "    # Calcular tamanho dos chunks - otimizado para reduzir overhead\n",
        "    if chunk_size is None:\n",
        "        # Para A100, mais workers com chunks menores funcionam melhor\n",
        "        chunk_size = 2000  # Valor otimizado para A100\n",
        "\n",
        "    # Preparar chunks para processamento\n",
        "    chunks_data = []\n",
        "    for start in range(0, batch_size, chunk_size):\n",
        "        end = min(start + chunk_size, batch_size)\n",
        "        chunks_data.append((keys, start, end))\n",
        "\n",
        "    # Otimiza√ß√£o: usar start_method='spawn' para evitar problemas de fork\n",
        "    context = multiprocessing.get_context('spawn')\n",
        "\n",
        "    # Processar em paralelo com um timeout maior e controle de falhas\n",
        "    with ProcessPoolExecutor(max_workers=max_workers, mp_context=context) as executor:\n",
        "        try:\n",
        "            # Usar chunksize=1 para melhor balanceamento\n",
        "            results = list(executor.map(process_keys_chunk, chunks_data, chunksize=1, timeout=180))\n",
        "        except Exception as e:\n",
        "            # Em caso de falha, processar sequencialmente\n",
        "            print(f\"‚ö†Ô∏è Falha no processamento paralelo: {e}\")\n",
        "            print(f\"‚ö†Ô∏è Tentando m√©todo sequencial...\")\n",
        "            addresses = np.zeros((len(keys), 20), dtype=np.uint8)\n",
        "            for i, key in enumerate(keys):\n",
        "                try:\n",
        "                    key_hex = f\"{key:064x}\"\n",
        "                    pk_bytes = bytes.fromhex(key_hex)\n",
        "                    public_key = PublicKey.from_valid_secret(pk_bytes).format(compressed=False)[1:]\n",
        "                    hash_bytes = bitcoin_hash160(public_key)\n",
        "                    addresses[i] = np.frombuffer(hash_bytes, dtype=np.uint8)\n",
        "                except Exception:\n",
        "                    pass  # Manter zeros em caso de erro\n",
        "            return addresses\n",
        "\n",
        "    # Unificar resultados\n",
        "    for i, chunk_result in enumerate(results):\n",
        "        start_idx = i * chunk_size\n",
        "        end_idx = min(start_idx + chunk_size, batch_size)\n",
        "        if start_idx < batch_size:  # Verificar limites\n",
        "            actual_chunk_size = min(chunk_size, batch_size - start_idx)\n",
        "            addresses[start_idx:end_idx] = chunk_result[:actual_chunk_size]\n",
        "\n",
        "    return addresses\n",
        "'''\n",
        "\n",
        "    with open(\"fixed_multiprocess.py\", \"w\") as f:\n",
        "        f.write(code)\n",
        "\n",
        "    print(\"‚úÖ Arquivo fixed_multiprocess.py criado com sucesso no diret√≥rio atual.\")\n",
        "\n",
        "def create_address_precomputing():\n",
        "    \"\"\"Cria o arquivo address_precomputing.py no diret√≥rio atual\"\"\"\n",
        "    code = '''\"\"\"\n",
        "M√≥dulo para pr√©-computa√ß√£o de endere√ßos Bitcoin em background\n",
        "Implementa um modelo produtor-consumidor para reduzir o gargalo de CPU\n",
        "\"\"\"\n",
        "import threading\n",
        "import queue\n",
        "import time\n",
        "import numpy as np\n",
        "from fixed_multiprocess import batch_generate_addresses\n",
        "import multiprocessing\n",
        "\n",
        "class AddressPrecomputer:\n",
        "    \"\"\"\n",
        "    Classe para pr√©-computar endere√ßos Bitcoin em threads de background.\n",
        "    Usa um modelo produtor-consumidor para alimentar o processamento GPU.\n",
        "    \"\"\"\n",
        "    def __init__(self, batch_size=32768, buffer_size=3, max_workers=None):\n",
        "        \"\"\"\n",
        "        Inicializa o sistema de pr√©-computa√ß√£o de endere√ßos.\n",
        "\n",
        "        Args:\n",
        "            batch_size: Tamanho de cada lote de endere√ßos\n",
        "            buffer_size: N√∫mero de lotes pr√©-computados a manter em buffer\n",
        "            max_workers: N√∫mero m√°ximo de workers para o processamento paralelo\n",
        "        \"\"\"\n",
        "        self.batch_size = batch_size\n",
        "        self.address_queue = queue.Queue(maxsize=buffer_size)\n",
        "        self.stop_event = threading.Event()\n",
        "        self.max_workers = max_workers or max(1, multiprocessing.cpu_count() - 1)\n",
        "        self.producer_thread = None\n",
        "        self.active = False\n",
        "\n",
        "        # Estat√≠sticas\n",
        "        self.total_generated = 0\n",
        "        self.total_consumed = 0\n",
        "        self.start_time = 0\n",
        "\n",
        "    def start(self, range_start, range_end):\n",
        "        \"\"\"\n",
        "        Inicia o thread produtor para gerar endere√ßos em background.\n",
        "\n",
        "        Args:\n",
        "            range_start: In√≠cio do intervalo de chaves\n",
        "            range_end: Fim do intervalo de chaves\n",
        "        \"\"\"\n",
        "        if self.active:\n",
        "            return\n",
        "\n",
        "        self.range_start = range_start\n",
        "        self.range_end = range_end\n",
        "        self.stop_event.clear()\n",
        "        self.active = True\n",
        "        self.start_time = time.time()\n",
        "\n",
        "        # Iniciar thread produtor\n",
        "        self.producer_thread = threading.Thread(\n",
        "            target=self._producer_task,\n",
        "            args=(range_start, range_end),\n",
        "            daemon=True\n",
        "        )\n",
        "        self.producer_thread.start()\n",
        "\n",
        "        print(f\"‚úÖ Iniciado pr√©-computador de endere√ßos com buffer de {self.address_queue.maxsize} lotes\")\n",
        "\n",
        "    def stop(self):\n",
        "        \"\"\"Para o thread produtor e limpa o buffer.\"\"\"\n",
        "        self.stop_event.set()\n",
        "        self.active = False\n",
        "\n",
        "        # Esvaziar a fila\n",
        "        while not self.address_queue.empty():\n",
        "            try:\n",
        "                self.address_queue.get_nowait()\n",
        "                self.address_queue.task_done()\n",
        "            except queue.Empty:\n",
        "                break\n",
        "\n",
        "    def _producer_task(self, range_start, range_end):\n",
        "        \"\"\"Tarefa de thread produtor que gera endere√ßos continuamente.\"\"\"\n",
        "        # Calcular o tamanho do intervalo como bigint para evitar overflow\n",
        "        sub_size = range_end - range_start + 1\n",
        "        batch_idx = 0\n",
        "\n",
        "        # Otimiza√ß√£o: usar multiprocessing.set_start_method('spawn') para evitar problemas\n",
        "        import multiprocessing\n",
        "        try:\n",
        "            multiprocessing.set_start_method('spawn', force=True)\n",
        "        except RuntimeError:\n",
        "            # J√° foi configurado\n",
        "            pass\n",
        "\n",
        "        # Verificar tamanho do range para determinar a estrat√©gia\n",
        "        range_too_large = sub_size > 0xFFFFFFFF  # Maior que max uint32\n",
        "        if range_too_large:\n",
        "            print(f\"‚ö†Ô∏è Range muito grande para uint32: {sub_size} (Usando m√©todo alternativo)\")\n",
        "\n",
        "        while not self.stop_event.is_set():\n",
        "            try:\n",
        "                # Verificar se a fila j√° est√° cheia\n",
        "                if self.address_queue.qsize() >= self.address_queue.maxsize:\n",
        "                    # Pausar brevemente se o buffer estiver cheio\n",
        "                    time.sleep(0.5)\n",
        "                    continue\n",
        "\n",
        "                # Gerar chaves aleat√≥rias - abordagem segura independente do tamanho\n",
        "                keys = []\n",
        "                np.random.seed()  # Renovar seed para melhor aleatoriedade\n",
        "\n",
        "                # M√©todo 100% seguro usando gera√ß√£o de n√∫meros diretamente\n",
        "                for _ in range(self.batch_size):\n",
        "                    # Gerar um n√∫mero aleat√≥rio no range [0, sub_size)\n",
        "                    if range_too_large:\n",
        "                        # Para intervalos muito grandes, gerar bytes aleat√≥rios e convert√™-los para um inteiro\n",
        "                        # Calcular quantos bytes precisamos para representar sub_size\n",
        "                        num_bytes = (sub_size.bit_length() + 7) // 8\n",
        "\n",
        "                        # Gerar um valor aleat√≥rio usando bytes aleat√≥rios\n",
        "                        while True:\n",
        "                            # Gerar bytes suficientes para cobrir o range\n",
        "                            random_bytes = np.random.bytes(num_bytes)\n",
        "                            random_value = int.from_bytes(random_bytes, byteorder='little')\n",
        "\n",
        "                            # Aplicar m√≥dulo para ficar no range correto\n",
        "                            random_value = random_value % sub_size\n",
        "\n",
        "                            if random_value < sub_size:\n",
        "                                break\n",
        "                    else:\n",
        "                        # Para intervalos menores, usar randint diretamente\n",
        "                        random_value = np.random.randint(0, sub_size, dtype=np.uint64)\n",
        "\n",
        "                    # Calcular chave final\n",
        "                    key = range_start + random_value\n",
        "                    keys.append(key)\n",
        "\n",
        "                # Gerar endere√ßos em paralelo\n",
        "                start_time = time.time()\n",
        "                addresses = batch_generate_addresses(\n",
        "                    keys,\n",
        "                    max_workers=self.max_workers,\n",
        "                    chunk_size=2000  # Otimizado para A100\n",
        "                )\n",
        "                gen_time = time.time() - start_time\n",
        "\n",
        "                # Adicionar ao buffer\n",
        "                self.address_queue.put((keys, addresses, gen_time), block=True)\n",
        "\n",
        "                self.total_generated += self.batch_size\n",
        "                batch_idx += 1\n",
        "\n",
        "                rate = self.batch_size / gen_time if gen_time > 0 else 0\n",
        "                if batch_idx % 5 == 0:  # Log a cada 5 batches\n",
        "                    print(f\"üîÑ Pr√©-computado lote {batch_idx}: {rate/1e6:.2f} Mend/s (buffer: {self.address_queue.qsize()}/{self.address_queue.maxsize})\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"‚ö†Ô∏è Erro no produtor de endere√ßos: {e}\")\n",
        "                import traceback\n",
        "                traceback.print_exc()\n",
        "                # Pausa para n√£o sobrecarregar em caso de erros\n",
        "                time.sleep(1.0)\n",
        "\n",
        "    def get_next_batch(self, timeout=None):\n",
        "        \"\"\"\n",
        "        Retorna o pr√≥ximo lote de endere√ßos pr√©-computados.\n",
        "\n",
        "        Args:\n",
        "            timeout: Tempo m√°ximo de espera em segundos (None = esperar indefinidamente)\n",
        "\n",
        "        Returns:\n",
        "            tuple: (keys, addresses, generation_time) ou None se timeout\n",
        "        \"\"\"\n",
        "        if not self.active:\n",
        "            return None\n",
        "\n",
        "        try:\n",
        "            # Obter pr√≥ximo lote (bloqueia at√© que um esteja dispon√≠vel)\n",
        "            next_batch = self.address_queue.get(block=True, timeout=timeout)\n",
        "            self.address_queue.task_done()\n",
        "\n",
        "            # Atualizar estat√≠sticas\n",
        "            self.total_consumed += self.batch_size\n",
        "\n",
        "            # Mostrar estat√≠sticas gerais\n",
        "            elapsed = time.time() - self.start_time\n",
        "            if elapsed > 0:\n",
        "                avg_speed = self.total_consumed / elapsed / 1e6  # Mend/s\n",
        "                print(f\"üìä Taxa m√©dia: {avg_speed:.2f} Mend/s | Gerados: {self.total_generated:,} | Consumidos: {self.total_consumed:,}\")\n",
        "\n",
        "            return next_batch\n",
        "        except queue.Empty:\n",
        "            print(\"‚ö†Ô∏è Timeout ao aguardar por endere√ßos pr√©-computados\")\n",
        "            return None\n",
        "\n",
        "    def get_stats(self):\n",
        "        \"\"\"Retorna estat√≠sticas do pr√©-computador.\"\"\"\n",
        "        elapsed = time.time() - self.start_time if self.start_time > 0 else 0\n",
        "        return {\n",
        "            \"total_generated\": self.total_generated,\n",
        "            \"total_consumed\": self.total_consumed,\n",
        "            \"elapsed_time\": elapsed,\n",
        "            \"average_speed\": self.total_consumed / elapsed if elapsed > 0 else 0,\n",
        "            \"buffer_status\": f\"{self.address_queue.qsize()}/{self.address_queue.maxsize}\"\n",
        "        }\n",
        "'''\n",
        "\n",
        "    with open(\"address_precomputing.py\", \"w\") as f:\n",
        "        f.write(code)\n",
        "\n",
        "    print(\"‚úÖ Arquivo address_precomputing.py criado com sucesso no diret√≥rio atual.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Verificar se os arquivos j√° existem\n",
        "    if os.path.exists(\"fixed_multiprocess.py\"):\n",
        "        print(\"‚ö†Ô∏è O arquivo fixed_multiprocess.py j√° existe.\")\n",
        "        overwrite = input(\"Sobrescrever? (s/n): \").strip().lower() == 's'\n",
        "        if overwrite:\n",
        "            create_fixed_multiprocess()\n",
        "    else:\n",
        "        create_fixed_multiprocess()\n",
        "\n",
        "    if os.path.exists(\"address_precomputing.py\"):\n",
        "        print(\"‚ö†Ô∏è O arquivo address_precomputing.py j√° existe.\")\n",
        "        overwrite = input(\"Sobrescrever? (s/n): \").strip().lower() == 's'\n",
        "        if overwrite:\n",
        "            create_address_precomputing()\n",
        "    else:\n",
        "        create_address_precomputing()\n",
        "\n",
        "    print(\"\\n‚úÖ M√≥dulos criados com sucesso!\")\n",
        "    print(\"   Agora voc√™ pode import√°-los em seus scripts:\")\n",
        "    print(\"   from fixed_multiprocess import batch_generate_addresses\")\n",
        "    print(\"   from address_precomputing import AddressPrecomputer\")\n"
      ],
      "metadata": {
        "id": "Rq3fcA0CweJ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from fixed_multiprocess import batch_generate_addresses\n",
        "from address_precomputing import AddressPrecomputer\n"
      ],
      "metadata": {
        "id": "Ay3OX0LgwrjT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "BitcoinFlix Miner - Vers√£o CUDA para m√°ximo desempenho GPU (Alternativa)\n",
        "Usa CuPy para GPU sem depender das fun√ß√µes Numba que est√£o causando problemas de compatibilidade\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import time\n",
        "import sys\n",
        "import requests\n",
        "import numpy as np\n",
        "import base58\n",
        "from coincurve import PublicKey\n",
        "from eth_utils import keccak\n",
        "import hashlib\n",
        "import multiprocessing\n",
        "from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor\n",
        "import threading\n",
        "\n",
        "# Detecta ambiente Colab\n",
        "IS_COLAB = 'google.colab' in sys.modules\n",
        "\n",
        "# Importar CuPy com tratamento de erro\n",
        "print(\"üîÑ Inicializando bibliotecas CUDA...\")\n",
        "try:\n",
        "    import cupy as cp\n",
        "    # Configurar LD_LIBRARY_PATH se necess√°rio\n",
        "    if 'google.colab' in sys.modules:\n",
        "        import os\n",
        "        cuda_link_dir = '/tmp/cuda_links'\n",
        "        if os.path.exists(cuda_link_dir):\n",
        "            current_ld_path = os.environ.get('LD_LIBRARY_PATH', '')\n",
        "            if cuda_link_dir not in current_ld_path:\n",
        "                os.environ['LD_LIBRARY_PATH'] = f\"{cuda_link_dir}:{current_ld_path}\"\n",
        "                print(f\"‚úÖ LD_LIBRARY_PATH atualizado: {os.environ['LD_LIBRARY_PATH']}\")\n",
        "\n",
        "    HAS_CUDA = cp.cuda.is_available()\n",
        "    if HAS_CUDA:\n",
        "        # Obter informa√ß√µes da GPU usando CuPy\n",
        "        dev_id = cp.cuda.Device()\n",
        "        try:\n",
        "            dev_props = cp.cuda.runtime.getDeviceProperties(dev_id.id)\n",
        "            print(f\"‚úÖ CUDA dispon√≠vel via CuPy: {dev_props['name'].decode()}\")\n",
        "            print(f\"   - Mem√≥ria total: {dev_props['totalGlobalMem'] / (1024**3):.2f} GB\")\n",
        "            print(f\"   - Compute capability: {dev_props['major']}.{dev_props['minor']}\")\n",
        "            print(f\"   - Multiprocessadores: {dev_props['multiProcessorCount']}\")\n",
        "        except Exception as e:\n",
        "            # Fallback para informa√ß√µes b√°sicas se houver erro\n",
        "            print(f\"‚úÖ CUDA dispon√≠vel via CuPy (informa√ß√µes limitadas)\")\n",
        "            print(f\"   - Erro ao obter propriedades detalhadas: {e}\")\n",
        "            mem = cp.cuda.runtime.memGetInfo()\n",
        "            print(f\"   - Mem√≥ria livre/total: {mem[0]/1024**3:.2f}GB/{mem[1]/1024**3:.2f}GB\")\n",
        "    else:\n",
        "        print(\"‚ùå CUDA n√£o est√° dispon√≠vel\")\n",
        "except ImportError as e:\n",
        "    HAS_CUDA = False\n",
        "    print(f\"‚ö†Ô∏è CuPy n√£o encontrado: {e}\")\n",
        "    print(\"‚ö†Ô∏è Execute install_cuda_deps.py para instalar as depend√™ncias necess√°rias\")\n",
        "\n",
        "    # Auto-instala√ß√£o das depend√™ncias\n",
        "    if IS_COLAB:\n",
        "        print(\"\\n‚ö†Ô∏è Para corrigir os problemas CUDA, execute primeiro:\")\n",
        "        print(\"!python install_cuda_deps.py\")\n",
        "        print(\"E ent√£o reinicie o runtime (Runtime > Restart runtime) antes de executar este script novamente.\")\n",
        "        sys.exit(1)\n",
        "\n",
        "# Importa√ß√µes para suporte RIPEMD160\n",
        "try:\n",
        "    from Crypto.Hash import RIPEMD160\n",
        "    HAS_PYCRYPTO = True\n",
        "except ImportError:\n",
        "    HAS_PYCRYPTO = False\n",
        "    print(\"‚ö†Ô∏è Crypto.Hash.RIPEMD160 n√£o dispon√≠vel, instalando pycryptodome...\")\n",
        "    try:\n",
        "        import subprocess\n",
        "        subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"pycryptodome\"], check=True)\n",
        "        from Crypto.Hash import RIPEMD160\n",
        "        HAS_PYCRYPTO = True\n",
        "        print(\"‚úÖ pycryptodome instalado com sucesso\")\n",
        "    except:\n",
        "        print(\"‚ùå N√£o foi poss√≠vel instalar pycryptodome\")\n",
        "        HAS_PYCRYPTO = False\n",
        "\n",
        "# Adicionar endere√ßo da Golden Key\n",
        "ADDITIONAL_ADDRESS = \"1MVDYgVaSN6iKKEsbzRUAYFrYJadLYZvvZ\"\n",
        "\n",
        "# Configura√ß√µes da API\n",
        "POOL_TOKEN = \"076a6a4636e1b70eb5105e609a2a9b59bcff5858f305daec5ee7b18095c6a48f\"\n",
        "API_URL = \"https://bitcoinflix.replit.app/api/big_block\"\n",
        "\n",
        "# Configura√ß√µes de processamento otimizadas com base nos resultados do teste de batch size\n",
        "BATCH_SIZE = 32768 if HAS_CUDA else 8192     # Aumentado para melhorar ocupa√ß√£o da GPU\n",
        "SUBBATCH_SIZE = 67108864 if HAS_CUDA else 2**20  # 64M chaves por sub-lote com GPU, 1M para CPU\n",
        "GPU_MEMORY_FRACTION = 0.95    # Usar at√© 95% da mem√≥ria GPU dispon√≠vel\n",
        "CPU_FALLBACK = False         # Flag para for√ßar uso da CPU mesmo com GPU dispon√≠vel\n",
        "MAX_PARALLEL_WORKERS = 32    # Usar mais workers para A100\n",
        "PIPELINE_BUFFER_SIZE = 5     # Aumentar buffer de pipeline para manter GPU ocupada\n",
        "\n",
        "# Par√¢metros de otimiza√ß√£o de GPU\n",
        "GPU_BATCH_SIZE = 256        # Reduzido ainda mais para aumentar o n√∫mero de kernels concorrentes\n",
        "FORCE_GPU_SYNC = True        # For√ßar sincroniza√ß√£o ocasional para manter GPU ativa\n",
        "GPU_WARMUP_ITERS = 10        # N√∫mero de itera√ß√µes de aquecimento inicial\n",
        "CUDA_STREAMS = 16            # Aumentado significativamente para maximum concurrency\n",
        "GPU_STRESS_ENABLE = True     # Ativar opera√ß√µes de stress para aumentar clock da GPU\n",
        "INTENSIVE_MATH_OPS = True    # Ativar opera√ß√µes matem√°ticas intensivas\n",
        "CONTINUOUS_STRESS = True     # Ativar thread de stress cont√≠nuo\n",
        "KERNEL_LOOPS = 50            # Aumentado drasticamente para mais opera√ß√µes por kernel\n",
        "MAXIMUM_OCCUPANCY = True     # Nova flag para maximizar ocupa√ß√£o de SMs\n",
        "CUDA_GRAPH_ENABLE = True     # Habilitar CUDA Graphs para kernels repetitivos\n",
        "DISABLE_CACHING = True       # Desabilitar caching para for√ßar recomputa√ß√£o\n",
        "\n",
        "# Agora podemos importar o m√≥dulo com seguran√ßa\n",
        "from fixed_multiprocess import batch_generate_addresses\n",
        "\n",
        "# Fun√ß√µes de utilidade\n",
        "def sha256(data):\n",
        "    \"\"\"Calcula SHA-256\"\"\"\n",
        "    return hashlib.sha256(data).digest()\n",
        "\n",
        "def ripemd160(data):\n",
        "    \"\"\"Calcula RIPEMD-160 com suporte a diferentes implementa√ß√µes\"\"\"\n",
        "    if HAS_PYCRYPTO:\n",
        "        h = RIPEMD160.new()\n",
        "        h.update(data)\n",
        "        return h.digest()\n",
        "    else:\n",
        "        # Usar Keccak como fallback se RIPEMD160 n√£o estiver dispon√≠vel\n",
        "        print(\"‚ö†Ô∏è Usando Keccak como fallback para RIPEMD160 (menos compat√≠vel)\")\n",
        "        return custom_keccak(data)[-20:]\n",
        "\n",
        "def bitcoin_hash160(public_key):\n",
        "    \"\"\"Implementa√ß√£o correta do hash160 usado no Bitcoin (SHA256 + RIPEMD160)\"\"\"\n",
        "    sha = sha256(public_key)\n",
        "    ripe = ripemd160(sha)\n",
        "    return ripe\n",
        "\n",
        "def custom_keccak(data):\n",
        "    \"\"\"Calcula Keccak-256 com tratamento de erros.\"\"\"\n",
        "    try:\n",
        "        if isinstance(data, str):\n",
        "            data = bytes.fromhex(data.replace('0x', ''))\n",
        "        return keccak(data)\n",
        "    except Exception:\n",
        "        return b'\\x00' * 32\n",
        "\n",
        "def decode_bitcoin_address(address):\n",
        "    \"\"\"Decodifica endere√ßo Bitcoin para array numpy.\"\"\"\n",
        "    try:\n",
        "        if not address or not isinstance(address, str):\n",
        "            return None\n",
        "\n",
        "        decoded = base58.b58decode(address)\n",
        "        if len(decoded) != 25:\n",
        "            return None\n",
        "\n",
        "        hash_bytes = decoded[1:-4]\n",
        "        hash_array = np.frombuffer(hash_bytes, dtype=np.uint8)\n",
        "        return hash_array\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è Erro ao decodificar {address}: {e}\")\n",
        "        return None\n",
        "\n",
        "# Fun√ß√£o para validar se um endere√ßo Bitcoin √© v√°lido\n",
        "def is_valid_bitcoin_address(address):\n",
        "    \"\"\"Verifica se um endere√ßo Bitcoin √© v√°lido\"\"\"\n",
        "    if not address or not isinstance(address, str):\n",
        "        return False\n",
        "\n",
        "    try:\n",
        "        # Um endere√ßo Bitcoin decodificado deve ter 25 bytes\n",
        "        # (1 byte vers√£o + 20 bytes hash + 4 bytes checksum)\n",
        "        decoded = base58.b58decode(address)\n",
        "        if len(decoded) != 25:\n",
        "            return False\n",
        "\n",
        "        # Verificar o checksum (os √∫ltimos 4 bytes)\n",
        "        # Modifica√ß√£o: usar sha256(sha256(payload)) em vez de Keccak\n",
        "        payload = decoded[:-4]\n",
        "        checksum = sha256(sha256(payload))[:4]\n",
        "        provided_checksum = decoded[-4:]\n",
        "\n",
        "        return checksum == provided_checksum\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è Erro na valida√ß√£o do endere√ßo {address}: {e}\")\n",
        "        return False\n",
        "\n",
        "# Fun√ß√£o para buscar dados do bloco\n",
        "def fetch_block_data():\n",
        "    \"\"\"Busca dados do bloco atual da API.\"\"\"\n",
        "    print(\"üîÑ Buscando dados do bloco da API...\")\n",
        "    headers = {\"pool-token\": POOL_TOKEN}\n",
        "    try:\n",
        "        response = requests.get(API_URL, headers=headers)\n",
        "        if response.status_code == 200:\n",
        "            data = response.json()\n",
        "            # Processar range\n",
        "            range_data = data.get(\"range\", {})\n",
        "            start = range_data.get(\"start\", \"\").replace(\"0x\", \"\")\n",
        "            end = range_data.get(\"end\", \"\").replace(\"0x\", \"\")\n",
        "            print(f\"‚úÖ Range recebido: {start} at√© {end}\")\n",
        "\n",
        "            # Mostrar carteiras alvo\n",
        "            addresses = data.get(\"checkwork_addresses\", [])\n",
        "            print(f\"üìã Carteiras recebidas ({len(addresses)}):\")\n",
        "            for i, addr in enumerate(addresses):\n",
        "                if addr:\n",
        "                    print(f\"  {i+1}. {addr}\")\n",
        "\n",
        "            return data\n",
        "        else:\n",
        "            print(f\"‚ùå Erro: {response.status_code} - {response.text}\")\n",
        "            return None\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Erro na requisi√ß√£o: {e}\")\n",
        "        return None\n",
        "\n",
        "# Obter dados do bloco\n",
        "BLOCK_DATA = fetch_block_data() or {\n",
        "    \"id\": 483545,\n",
        "    \"position\": 17895,\n",
        "    \"status\": 0,\n",
        "    \"range\": {\n",
        "        \"start\": \"0x9108ba3d21e522400\",\n",
        "        \"end\": \"0x9108ba3d25e5223ff\"\n",
        "    },\n",
        "    \"checkwork_addresses\": [\"\", \"\"],\n",
        "    \"message\": \"Retrieved existing block\"\n",
        "}\n",
        "\n",
        "# Fun√ß√£o para monitorar uso da GPU\n",
        "def monitor_gpu():\n",
        "    if not IS_COLAB or not HAS_CUDA:\n",
        "        return\n",
        "\n",
        "    try:\n",
        "        import subprocess\n",
        "        result = subprocess.run('nvidia-smi --query-gpu=utilization.gpu,memory.used,memory.total --format=csv,noheader',\n",
        "                               shell=True, stdout=subprocess.PIPE).stdout.decode('utf-8').strip()\n",
        "        gpu_util, mem_used, mem_total = result.split(',')\n",
        "        print(f\"üìä GPU: {gpu_util.strip()} | Mem√≥ria: {mem_used.strip()}/{mem_total.strip()}\")\n",
        "    except:\n",
        "        print(\"‚ö†Ô∏è N√£o foi poss√≠vel monitorar GPU\")\n",
        "\n",
        "class CupyBitcoinMiner:\n",
        "    \"\"\"Minerador Bitcoin otimizado para CUDA usando apenas CuPy\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"Inicializa o minerador\"\"\"\n",
        "        self.current_block = BLOCK_DATA\n",
        "\n",
        "        # Processa os targets\n",
        "        self.targets_list = []\n",
        "        self.target_addresses = []\n",
        "\n",
        "        # Golden Key (endere√ßo adicional)\n",
        "        self.golden_key_address = ADDITIONAL_ADDRESS\n",
        "        self.golden_key_hash = decode_bitcoin_address(ADDITIONAL_ADDRESS)\n",
        "        if self.golden_key_hash is not None:\n",
        "            print(f\"üåü Golden Key adicionada: {ADDITIONAL_ADDRESS}\")\n",
        "\n",
        "        # Decodificar endere√ßos alvo\n",
        "        for addr in self.current_block.get('checkwork_addresses', []):\n",
        "            if isinstance(addr, str) and addr:\n",
        "                # Valida√ß√£o adicional para confirmar que o endere√ßo √© v√°lido\n",
        "                if is_valid_bitcoin_address(addr):\n",
        "                    self.target_addresses.append(addr)\n",
        "                    hash_array = decode_bitcoin_address(addr)\n",
        "                    if hash_array is not None:\n",
        "                        self.targets_list.append(hash_array)\n",
        "                else:\n",
        "                    print(f\"‚ö†Ô∏è Endere√ßo inv√°lido ignorado: {addr}\")\n",
        "\n",
        "        # Adicionar Golden Key aos targets se n√£o estiver j√° inclu√≠da\n",
        "        if self.golden_key_hash is not None:\n",
        "            if not any(np.array_equal(self.golden_key_hash, target) for target in self.targets_list):\n",
        "                self.targets_list.append(self.golden_key_hash)\n",
        "                self.target_addresses.append(self.golden_key_address)\n",
        "                print(\"‚úÖ Golden Key adicionada aos targets\")\n",
        "\n",
        "        self.n_targets = len(self.targets_list)\n",
        "        print(f\"üéØ Total de targets v√°lidos: {self.n_targets}\")\n",
        "\n",
        "        # Para uso com GPU, converter para arrays CuPy e otimizar mem√≥ria\n",
        "        if HAS_CUDA and self.n_targets > 0 and not CPU_FALLBACK:\n",
        "            # Preparar array de targets para GPU\n",
        "            self.targets_array_np = np.vstack(self.targets_list).astype(np.uint8)\n",
        "\n",
        "            # Transferir para a GPU com CuPy\n",
        "            self.targets_array = cp.asarray(self.targets_array_np)\n",
        "            print(\"‚úÖ Targets transferidos para GPU\")\n",
        "\n",
        "            # Pre-alocar buffers para reduzir fragmenta√ß√£o de mem√≥ria\n",
        "            try:\n",
        "                # Obt√©m informa√ß√£o de mem√≥ria dispon√≠vel\n",
        "                free_mem, total_mem = cp.cuda.runtime.memGetInfo()\n",
        "                available_mem = int(free_mem * GPU_MEMORY_FRACTION)\n",
        "\n",
        "                # Alocar buffers para endere√ßos e resultados\n",
        "                self.address_buffer = cp.zeros((BATCH_SIZE, 20), dtype=cp.uint8)\n",
        "                self.result_buffer = cp.zeros(BATCH_SIZE, dtype=cp.int32)\n",
        "                print(f\"‚úÖ Buffers pr√©-alocados: {BATCH_SIZE} endere√ßos\")\n",
        "\n",
        "                # Ajustar batch size se necess√°rio baseado na mem√≥ria dispon√≠vel\n",
        "                meminfo_str = f\"Mem√≥ria GPU: {free_mem/(1024**3):.1f}GB livre de {total_mem/(1024**3):.1f}GB\"\n",
        "                print(f\"üìä {meminfo_str}\")\n",
        "            except Exception as e:\n",
        "                print(f\"‚ö†Ô∏è N√£o foi poss√≠vel pr√©-alocar buffers: {e}\")\n",
        "\n",
        "            # Aquecer a GPU para melhor desempenho\n",
        "            self._warmup_gpu()\n",
        "        else:\n",
        "            self.targets_array_np = np.vstack(self.targets_list).astype(np.uint8) if self.targets_list else None\n",
        "            self.targets_array = None\n",
        "\n",
        "    def _warmup_gpu(self):\n",
        "        \"\"\"Aquece a GPU para melhor desempenho - vers√£o extremamente agressiva\"\"\"\n",
        "        if not HAS_CUDA or CPU_FALLBACK:\n",
        "            return\n",
        "\n",
        "        try:\n",
        "            print(\"üî• Aquecendo GPU e otimizando para desempenho m√°ximo...\")\n",
        "\n",
        "            # Configurar GPU para desempenho m√°ximo - ajustes extremos para mem√≥ria\n",
        "            try:\n",
        "                # Desativar limites para computa√ß√£o m√°xima\n",
        "                cp.cuda.runtime.deviceSetLimit(0, 8192)  # cudaLimitStackSize aumentado\n",
        "                cp.cuda.runtime.deviceSetLimit(8, 128)   # cudaLimitMaxL2FetchGranularity aumentado\n",
        "\n",
        "                # Configura√ß√µes adicionais para maximizar throughput\n",
        "                if hasattr(cp.cuda.runtime, 'deviceSetCacheConfig'):\n",
        "                    cp.cuda.runtime.deviceSetCacheConfig(2)  # cudaFuncCachePreferL1\n",
        "\n",
        "                # Aumentar tamanho de heap para opera√ß√µes din√¢micas\n",
        "                if hasattr(cp.cuda.runtime, 'deviceSetLimit'):\n",
        "                    cp.cuda.runtime.deviceSetLimit(1, 128*1024*1024)  # cudaLimitMallocHeapSize\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "            # Pr√©-alocar streams CUDA para opera√ß√µes paralelas\n",
        "            self.cuda_streams = []\n",
        "            self.cuda_events = []\n",
        "            for i in range(CUDA_STREAMS):\n",
        "                try:\n",
        "                    # Criar streams n√£o bloqueantes com alta prioridade\n",
        "                    self.cuda_streams.append(cp.cuda.Stream(non_blocking=True, priority=0))\n",
        "\n",
        "                    # Criar eventos para sincroniza√ß√£o fina\n",
        "                    self.cuda_events.append(cp.cuda.Event())\n",
        "                except:\n",
        "                    pass\n",
        "\n",
        "            # WARMUP ULTRA AGRESSIVO: Executar kernels massivos em todas as streams\n",
        "            print(\"   Executando warmup ultra agressivo para maximizar clocks...\")\n",
        "\n",
        "            # Criar gr√°ficos CUDA para opera√ß√µes repetitivas\n",
        "            if CUDA_GRAPH_ENABLE:\n",
        "                try:\n",
        "                    # Tentar configurar CUDA Graphs\n",
        "                    self.cuda_graphs = []\n",
        "                    self.cuda_graph_execs = []\n",
        "\n",
        "                    # Criar um graph por stream para opera√ß√µes repetitivas\n",
        "                    for stream in self.cuda_streams[:4]:  # Limitar a 4 graphs\n",
        "                        with stream:\n",
        "                            # Capturar um graph para opera√ß√µes comuns\n",
        "                            graph = cp.cuda.graph.CUDAGraph()\n",
        "                            with graph:\n",
        "                                a = cp.random.normal(0, 1, (5000, 5000), dtype=cp.float32)\n",
        "                                b = cp.random.normal(0, 1, (5000, 5000), dtype=cp.float32)\n",
        "                                c = cp.matmul(a, b)\n",
        "                                d = cp.exp(cp.sin(c) + cp.cos(c))\n",
        "                                e = cp.linalg.cholesky(cp.matmul(d[:1000,:1000], d[:1000,:1000].T) + cp.eye(1000) * 0.01)\n",
        "\n",
        "                            # Armazenar o graph e seu executor\n",
        "                            self.cuda_graphs.append(graph)\n",
        "                            self.cuda_graph_execs.append(graph.compile())\n",
        "\n",
        "                    print(\"   ‚úÖ CUDA Graphs configurados para execu√ß√£o r√°pida\")\n",
        "                except Exception as e:\n",
        "                    print(f\"   ‚ö†Ô∏è CUDA Graphs n√£o dispon√≠veis: {e}\")\n",
        "\n",
        "            # Iniciar thread separado para stress constante com alta prioridade\n",
        "            if CONTINUOUS_STRESS:\n",
        "                self.stress_thread_active = True\n",
        "                self.stress_thread = threading.Thread(target=self._continuous_stress_thread, daemon=True)\n",
        "                self.stress_thread.start()\n",
        "\n",
        "            # AQUECIMENTO DE ALTA INTENSIDADE: Realizar opera√ß√µes em todas as streams em sequ√™ncia\n",
        "            for i in range(GPU_WARMUP_ITERS):\n",
        "                # Para cada stream, executar opera√ß√µes diferentes\n",
        "                for sidx, stream in enumerate(self.cuda_streams):\n",
        "                    with stream:\n",
        "                        # Tamanho diferente para cada stream para exercitar diferentes SMs\n",
        "                        size = 5000 + (sidx % 5) * 1000\n",
        "\n",
        "                        # Opera√ß√µes diferentes para exercitar diferentes unidades\n",
        "                        if sidx % 4 == 0:\n",
        "                            # GEMM (opera√ß√µes matriciais) - exercita unidades tensores\n",
        "                            a = cp.random.random((size, size), dtype=cp.float32)\n",
        "                            b = cp.random.random((size, size), dtype=cp.float32)\n",
        "                            c = cp.matmul(a, b)\n",
        "                            del a, b, c\n",
        "\n",
        "                        elif sidx % 4 == 1:\n",
        "                            # FFT (exercita unidades especiais)\n",
        "                            size = min(size, 4096)  # FFT √© mais pesado\n",
        "                            a = cp.random.random((size, size), dtype=cp.float32)\n",
        "                            b = cp.fft.fft2(a)\n",
        "                            c = cp.fft.ifft2(b)\n",
        "                            del a, b, c\n",
        "\n",
        "                        elif sidx % 4 == 2:\n",
        "                            # Elementwise operations (exercita CUDA cores)\n",
        "                            n = size * size * 2\n",
        "                            a = cp.random.random(n, dtype=cp.float32)\n",
        "                            for _ in range(20):  # Loop intenso\n",
        "                                a = cp.sin(a) * cp.cos(a)\n",
        "                                a = cp.sqrt(cp.square(a) + 1.0)\n",
        "                                a = cp.exp(a * 0.01)\n",
        "                            del a\n",
        "\n",
        "                        else:\n",
        "                            # Opera√ß√µes de √°lgebra linear (exercita unidades espec√≠ficas)\n",
        "                            size = min(size, 3000)  # √Ålgebra linear √© pesada\n",
        "                            a = cp.random.random((size, size), dtype=cp.float32)\n",
        "                            u, s, v = cp.linalg.svd(a, full_matrices=False)  # SVD √© extremamente intensivo\n",
        "                            del a, u, s, v\n",
        "\n",
        "                    # Registrar evento para detectar conclus√£o\n",
        "                    self.cuda_events[sidx].record(stream)\n",
        "\n",
        "                # Sincronizar para garantir que todas as opera√ß√µes foram completadas\n",
        "                for event in self.cuda_events:\n",
        "                    event.synchronize()\n",
        "\n",
        "                print(f\"   Aquecimento intenso {i+1}/{GPU_WARMUP_ITERS} conclu√≠do\")\n",
        "\n",
        "            # Executar CUDA Graphs compilados para verificar desempenho\n",
        "            if CUDA_GRAPH_ENABLE and hasattr(self, 'cuda_graph_execs') and self.cuda_graph_execs:\n",
        "                print(\"   Executando CUDA Graphs compilados para teste de performance...\")\n",
        "                for i, graph_exec in enumerate(self.cuda_graph_execs):\n",
        "                    start_time = time.time()\n",
        "                    for _ in range(5):  # Executar 5 vezes para medir\n",
        "                        graph_exec.launch()\n",
        "                    cp.cuda.runtime.deviceSynchronize()\n",
        "                    elapsed = time.time() - start_time\n",
        "                    print(f\"   Graph {i+1}: {elapsed/5*1000:.2f}ms por execu√ß√£o\")\n",
        "\n",
        "            # Liberar mem√≥ria\n",
        "            cp.get_default_memory_pool().free_all_blocks()\n",
        "            print(\"‚úÖ GPU totalmente preparada para desempenho m√°ximo\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è Erro ao aquecer GPU: {e}\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "\n",
        "# Atualizar o runtime para usar mais CPU cores para processamento\n",
        "def optimize_runtime_settings():\n",
        "    \"\"\"Otimiza configura√ß√µes do runtime para melhor desempenho\"\"\"\n",
        "    # Desativar GC durante o processamento intensivo\n",
        "    import gc\n",
        "    gc.disable()\n",
        "\n",
        "    # Aumentar prioridade do processo\n",
        "    try:\n",
        "        os.nice(-10)  # Tenta aumentar prioridade em sistemas Unix\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    # Configurar vari√°veis de ambiente para otimiza√ß√£o\n",
        "    os.environ[\"OMP_NUM_THREADS\"] = str(MAX_PARALLEL_WORKERS)\n",
        "    os.environ[\"MKL_NUM_THREADS\"] = str(MAX_PARALLEL_WORKERS)\n",
        "    os.environ[\"NUMEXPR_NUM_THREADS\"] = str(MAX_PARALLEL_WORKERS)\n",
        "    os.environ[\"OPENBLAS_NUM_THREADS\"] = str(MAX_PARALLEL_WORKERS)\n",
        "    os.environ[\"VECLIB_MAXIMUM_THREADS\"] = str(MAX_PARALLEL_WORKERS)\n",
        "\n",
        "    # Configura√ß√µes espec√≠ficas para CUDA\n",
        "    if HAS_CUDA:\n",
        "        # Configurar para desmapeamento agressivo de mem√≥ria para evitar fragmenta√ß√£o\n",
        "        os.environ[\"CUPY_GPU_MEMORY_LIMIT\"] = \"90%\"\n",
        "        os.environ[\"CUPY_MALLOC_MANAGED\"] = \"1\"  # Usar malloc gerenciado\n",
        "\n",
        "        # Ajuste fino para melhorar a persist√™ncia do kernel\n",
        "        try:\n",
        "            cp.cuda.runtime.setDeviceFlags(8)  # cudaDeviceScheduleYield\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "        # Configura√ß√µes para melhorar throughput\n",
        "        try:\n",
        "            # Desativar autosync\n",
        "            cp.cuda.runtime.setDeviceFlags(4)  # cudaDeviceScheduleBlockingSync\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "        # Configura√ß√µes adicionais mais agressivas para CUDA\n",
        "        os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"0\"\n",
        "        os.environ[\"CUDA_DEVICE_MAX_CONNECTIONS\"] = \"128\"  # Aumentado para m√°xima concorr√™ncia\n",
        "        os.environ[\"CUDA_CACHE_DISABLE\"] = \"1\" if DISABLE_CACHING else \"0\"  # For√ßar computa√ß√£o sem cache\n",
        "        os.environ[\"CUDA_FORCE_PTX_JIT\"] = \"1\"  # For√ßar compila√ß√£o JIT para otimiza√ß√£o espec√≠fica da GPU\n",
        "\n",
        "        # Configurar para usar FMA (Fused Multiply-Add) de precis√£o simples\n",
        "        os.environ[\"CUPY_FAST_MATH\"] = \"1\"\n",
        "\n",
        "        # For√ßar modo de performance em GPUs NVIDIA - configura√ß√µes mais agressivas\n",
        "        try:\n",
        "            import subprocess\n",
        "            # Modo persistente\n",
        "            subprocess.run(\"nvidia-smi -pm 1\", shell=True,\n",
        "                           stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
        "            # M√°xima frequ√™ncia de mem√≥ria e GPU - valores espec√≠ficos para A100\n",
        "            subprocess.run(\"nvidia-smi -ac 1215,1410\", shell=True,\n",
        "                           stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
        "            # Sem limites de pot√™ncia\n",
        "            subprocess.run(\"nvidia-smi -pl 400\", shell=True,\n",
        "                           stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
        "            # Prioridade m√°xima para o processo\n",
        "            subprocess.run(\"nvidia-smi -c 3\", shell=True,  # Modo COMPUTE_EXCLUSIVE\n",
        "                           stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
        "            print(\"üî• GPU configurada para M√ÅXIMO DESEMPENHO\")\n",
        "        except Exception as e:\n",
        "            print(f\"‚ÑπÔ∏è N√£o foi poss√≠vel definir configura√ß√µes avan√ßadas da GPU: {e}\")\n",
        "\n",
        "    # Contornar limita√ß√µes de fork/subprocesso no Linux\n",
        "    if sys.platform.startswith('linux'):\n",
        "        import multiprocessing\n",
        "        multiprocessing.set_start_method('spawn', force=True)\n",
        "\n",
        "# Fun√ß√£o principal\n",
        "if __name__ == \"__main__\":\n",
        "    if not HAS_CUDA:\n",
        "        print(\"\\n‚ö†Ô∏è CUDA n√£o dispon√≠vel. O processamento ser√° feito na CPU (lento).\")\n",
        "        print(\"   Para usar GPU, verifique se:\")\n",
        "        print(\"   1. Ambiente est√° configurado para GPU (Runtime > Change runtime type)\")\n",
        "        print(\"   2. CuPy est√° instalado corretamente\")\n",
        "\n",
        "        if IS_COLAB:\n",
        "            print(\"\\nComo estamos no Colab, verifique se escolheu GPU em Runtime > Change runtime type\")\n",
        "\n",
        "        proceed = input(\"\\nContinuar mesmo assim? (s/n): \")\n",
        "        if proceed.lower() != 's':\n",
        "            sys.exit(0)\n",
        "\n",
        "    # Otimizar configura√ß√µes de runtime antes de iniciar\n",
        "    optimize_runtime_settings()\n",
        "\n",
        "    miner = CupyBitcoinMiner()\n",
        "    miner.run()\n"
      ],
      "metadata": {
        "id": "Lc1cCnyqzKx1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://developer.nvidia.com/compute/cuda/9.2/Prod/local_installers/cuda-repo-ubuntu1604-9-2-local_9.2.88-1_amd64 -O cuda-repo-ubuntu1604-9-2-local_9.2.88-1_amd64.deb\n",
        "!dpkg -i cuda-repo-ubuntu1604-9-2-local_9.2.88-1_amd64.deb\n",
        "!apt-key add /var/cuda-repo-9-2-local/7fa2af80.pub\n",
        "!apt-get update\n",
        "!apt-get install cuda\n",
        "\n"
      ],
      "metadata": {
        "id": "zTpQv2qFpAS9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ================== USO CPU ==================\n",
        "\n",
        "import os\n",
        "import torch\n",
        "import time\n",
        "import numpy as np\n",
        "from coincurve import PublicKey\n",
        "from eth_utils import keccak\n",
        "import base58\n",
        "import requests\n",
        "import sys\n",
        "\n",
        "# ================== CONFIGURA√á√ÉO ==================\n",
        "os.environ['CUDA_HOME'] = '/usr/local/cuda'\n",
        "\n",
        "POOL_TOKEN = \"076a6a4636e1b70eb5105e609a2a9b59bcff5858f305daec5ee7b18095c6a48f\"  # Token correto do pool\n",
        "API_URL = \"https://bitcoinflix.replit.app/api/big_block\"  # URL da API\n",
        "\n",
        "# Fun√ß√£o para buscar automaticamente os dados do bloco da API\n",
        "def fetch_block_data():\n",
        "    print(\"üîÑ Buscando dados do bloco da API...\")\n",
        "    headers = {\"pool-token\": POOL_TOKEN}\n",
        "    try:\n",
        "        response = requests.get(API_URL, headers=headers)\n",
        "        if response.status_code == 200:\n",
        "            data = response.json()\n",
        "            # Log para depura√ß√£o do range\n",
        "            range_data = data.get(\"range\", {})\n",
        "            start = range_data.get(\"start\", \"\").replace(\"0x\", \"\")\n",
        "            end = range_data.get(\"end\", \"\").replace(\"0x\", \"\")\n",
        "            print(f\"‚úÖ Range recebido da API: start={start}, end={end}\")\n",
        "\n",
        "            # Exibir dados dos endere√ßos recebidos\n",
        "            addresses = data.get(\"checkwork_addresses\", [])\n",
        "            print(f\"üìã Carteiras recebidas da API ({len(addresses)}):\")\n",
        "            for i, addr in enumerate(addresses):\n",
        "                if addr: # S√≥ mostra se n√£o for vazio\n",
        "                    print(f\"  {i+1}. {addr}\")\n",
        "\n",
        "            # Exibir ID do bloco e outras informa√ß√µes relevantes\n",
        "            print(f\"üÜî Bloco ID: {data.get('id')}\")\n",
        "            print(f\"üìä Posi√ß√£o: {data.get('position')}\")\n",
        "\n",
        "            return data\n",
        "        else:\n",
        "            print(f\"‚ùå Erro ao buscar dados do bloco: {response.status_code} - {response.text}\")\n",
        "            return None\n",
        "    except requests.RequestException as e:\n",
        "        print(f\"‚ùå Erro ao fazer a requisi√ß√£o: {e}\")\n",
        "        return None\n",
        "\n",
        "# Fun√ß√£o para obter informa√ß√µes da GPU\n",
        "def get_gpu_info():\n",
        "    \"\"\"Obt√©m informa√ß√µes detalhadas sobre as GPUs dispon√≠veis.\"\"\"\n",
        "    info = {\n",
        "        \"dispon√≠vel\": torch.cuda.is_available(),\n",
        "        \"dispositivos\": 0,\n",
        "        \"modelo\": \"N/A\",\n",
        "        \"mem√≥ria_total_gb\": 0\n",
        "    }\n",
        "\n",
        "    if info[\"dispon√≠vel\"]:\n",
        "        try:\n",
        "            info[\"dispositivos\"] = torch.cuda.device_count()\n",
        "            info[\"modelo\"] = torch.cuda.get_device_name(0)\n",
        "            info[\"mem√≥ria_total_gb\"] = torch.cuda.get_device_properties(0).total_memory / (1024**3)\n",
        "\n",
        "            # Tenta obter informa√ß√µes adicionais com nvidia-smi\n",
        "            try:\n",
        "                import subprocess\n",
        "                result = subprocess.run([\"nvidia-smi\", \"--query-gpu=utilization.gpu,temperature.gpu\", \"--format=csv,noheader\"],\n",
        "                                       capture_output=True, text=True)\n",
        "                if result.returncode == 0:\n",
        "                    util, temp = result.stdout.strip().split(\",\")\n",
        "                    info[\"utiliza√ß√£o\"] = util.strip()\n",
        "                    info[\"temperatura\"] = temp.strip()\n",
        "            except:\n",
        "                pass\n",
        "        except Exception as e:\n",
        "            print(f\"Erro ao obter detalhes da GPU: {e}\")\n",
        "\n",
        "    return info\n",
        "\n",
        "# Obt√©m dados do bloco automaticamente ou usa fallback est√°tico\n",
        "BLOCK_DATA = fetch_block_data() or {\n",
        "    \"id\": 483545,\n",
        "    \"position\": 17895,\n",
        "    \"status\": 0,\n",
        "    \"range\": {\n",
        "        \"start\": \"0x9108ba3d21e522400\",\n",
        "        \"end\": \"0x9108ba3d25e5223ff\"\n",
        "    },\n",
        "    \"checkwork_addresses\": [\n",
        "        \"\",\n",
        "        \"\"\n",
        "    ],\n",
        "    \"message\": \"Retrieved existing unchecked block at position 17895\"\n",
        "}\n",
        "\n",
        "SUBBATCH_SIZE = 2**23  # 262144 chaves por sub-lote; para testes, considere diminuir, ex: 2**16\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "PROGRESS_UPDATE_INTERVAL = 100000  # Atualiza o progresso a cada X chaves processadas\n",
        "\n",
        "# ================== FUN√á√ïES DE HASH ==================\n",
        "def custom_keccak(data):\n",
        "    \"\"\"Calcula Keccak-256 com tratamento de erros.\"\"\"\n",
        "    try:\n",
        "        if isinstance(data, str):\n",
        "            data = bytes.fromhex(data.replace('0x', ''))\n",
        "        return keccak(data)\n",
        "    except Exception:\n",
        "        return b'\\x00' * 32\n",
        "\n",
        "# ================== FUN√á√ÉO DE DECODIFICA√á√ÉO BASE58 ==================\n",
        "def decode_bitcoin_address(address):\n",
        "    \"\"\"\n",
        "    Decodifica um endere√ßo Bitcoin em Base58Check e extrai os 20 bytes do hash.\n",
        "    Um endere√ßo P2PKH possui:\n",
        "      - 1 byte de vers√£o (0x00)\n",
        "      - 20 bytes de hash\n",
        "      - 4 bytes de checksum\n",
        "    Retorna os 20 bytes do hash.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        decoded = base58.b58decode(address)\n",
        "        if len(decoded) != 25:\n",
        "            return None\n",
        "        return decoded[1:-4]\n",
        "    except Exception as e:\n",
        "        print(f\"Erro ao decodificar {address}: {e}\")\n",
        "        return None\n",
        "\n",
        "# ================== CLASSE DE MINERA√á√ÉO ==================\n",
        "class BitcoinFlixMiner:\n",
        "    def __init__(self):\n",
        "        # Usando os dados din√¢micos obtidos da API\n",
        "        self.current_block = BLOCK_DATA\n",
        "        self.targets = {\n",
        "            decode_bitcoin_address(addr)\n",
        "            for addr in self.current_block.get('checkwork_addresses', [])\n",
        "            if isinstance(addr, str) and addr\n",
        "        }\n",
        "        self.targets = {t for t in self.targets if t is not None}\n",
        "\n",
        "        # Obter informa√ß√µes da GPU\n",
        "        self.gpu_info = get_gpu_info()\n",
        "\n",
        "        # Impress√£o de informa√ß√µes do dispositivo\n",
        "        if self.gpu_info[\"dispon√≠vel\"]:\n",
        "            print(f\"üñ•Ô∏è GPU: {self.gpu_info['modelo']}\")\n",
        "            print(f\"üìä Mem√≥ria: {self.gpu_info['mem√≥ria_total_gb']:.2f} GB\")\n",
        "            if \"utiliza√ß√£o\" in self.gpu_info:\n",
        "                print(f\"üå°Ô∏è Temperatura: {self.gpu_info['temperatura']}\")\n",
        "        else:\n",
        "            print(\"‚ö†Ô∏è GPU n√£o dispon√≠vel, usando CPU\")\n",
        "\n",
        "    def process_range(self, start, end):\n",
        "        \"\"\"\n",
        "        Processa um intervalo de chaves com informa√ß√µes detalhadas de progresso.\n",
        "        \"\"\"\n",
        "        total_keys = end - start + 1\n",
        "        valid_keys = []\n",
        "\n",
        "        if total_keys <= 0:\n",
        "            print(\"‚ùå Intervalo inv√°lido (in√≠cio >= fim)\")\n",
        "            return []\n",
        "\n",
        "        num_subbatches = (total_keys + SUBBATCH_SIZE - 1) // SUBBATCH_SIZE\n",
        "        print(f\"üöÄ Iniciando processamento: {num_subbatches} sub-lotes no intervalo\")\n",
        "        print(f\"üìä Tamanho total do range: {total_keys:,} chaves\")\n",
        "\n",
        "        total_processed = 0\n",
        "        global_start_time = time.time()\n",
        "\n",
        "        for i in range(num_subbatches):\n",
        "            sub_start = start + i * SUBBATCH_SIZE\n",
        "            sub_end = min(sub_start + SUBBATCH_SIZE - 1, end)\n",
        "            range_size = sub_end - sub_start + 1\n",
        "\n",
        "            if range_size <= 0:\n",
        "                continue\n",
        "\n",
        "            batch_start_time = time.time()\n",
        "            print(f\"\\nüìå [{i+1}/{num_subbatches}] Processando sub-lote {i+1}...\")\n",
        "            print(f\"üî¢ Range: {sub_start:x} at√© {sub_end:x} ({range_size:,} chaves)\")\n",
        "\n",
        "            # Gere offsets pequenos com np.uint32\n",
        "            try:\n",
        "                offsets = np.random.randint(0, range_size, size=SUBBATCH_SIZE, dtype=np.uint32)\n",
        "                keys_cpu = [sub_start + int(off) for off in offsets]\n",
        "\n",
        "                print(\"‚öôÔ∏è Gerando endere√ßos e verificando correspond√™ncias...\")\n",
        "\n",
        "                # Inicializa matriz para armazenar endere√ßos\n",
        "                addresses = np.zeros((SUBBATCH_SIZE, 20), dtype=np.uint8)\n",
        "\n",
        "                # Processamento por lotes com atualiza√ß√£o de progresso\n",
        "                last_update_time = time.time()\n",
        "                last_update_count = 0\n",
        "\n",
        "                for j, key in enumerate(keys_cpu):\n",
        "                    try:\n",
        "                        pk_bytes = bytes.fromhex(f\"{key:064x}\")\n",
        "                        public_key = PublicKey.from_valid_secret(pk_bytes).format(compressed=False)[1:]\n",
        "                        addresses[j] = np.frombuffer(custom_keccak(public_key)[-20:], dtype=np.uint8)\n",
        "                    except Exception:\n",
        "                        addresses[j] = np.zeros(20, dtype=np.uint8)\n",
        "\n",
        "                    # Atualiza√ß√£o de progresso\n",
        "                    if j % PROGRESS_UPDATE_INTERVAL == 0 and j > 0:\n",
        "                        current_time = time.time()\n",
        "                        elapsed = current_time - last_update_time\n",
        "                        keys_since_update = j - last_update_count\n",
        "\n",
        "                        if elapsed > 0:\n",
        "                            speed = keys_since_update / elapsed\n",
        "                            percent = (j / SUBBATCH_SIZE) * 100\n",
        "                            eta = (SUBBATCH_SIZE - j) / speed if speed > 0 else 0\n",
        "\n",
        "                            print(f\"‚è≥ Progresso: {percent:.1f}% | {j:,}/{SUBBATCH_SIZE:,} chaves | \"\n",
        "                                  f\"Velocidade: {speed/1e6:.2f} Mchaves/s | ETA: {eta:.1f}s\")\n",
        "\n",
        "                            last_update_time = current_time\n",
        "                            last_update_count = j\n",
        "\n",
        "                batch_time = time.time() - batch_start_time\n",
        "                batch_speed = SUBBATCH_SIZE / batch_time if batch_time > 0 else 0\n",
        "                print(f\"‚úÖ Gera√ß√£o conclu√≠da em {batch_time:.2f}s ({batch_speed/1e6:.2f} Mchaves/s)\")\n",
        "\n",
        "                # Verifica√ß√£o de correspond√™ncias\n",
        "                print(f\"üîç Verificando correspond√™ncias com {len(self.targets)} carteiras...\")\n",
        "                match_start_time = time.time()\n",
        "\n",
        "                if self.targets:\n",
        "                    targets = np.array(list(self.targets), dtype=np.uint8)\n",
        "                    matches = np.any(np.all(addresses[:, None] == targets, axis=2), axis=1)\n",
        "                    matched_keys = [keys_cpu[j] for j, m in enumerate(matches) if m]\n",
        "                    valid_keys.extend(matched_keys)\n",
        "\n",
        "                match_time = time.time() - match_start_time\n",
        "                print(f\"‚úÖ Verifica√ß√£o conclu√≠da em {match_time:.2f}s | Encontradas: {len(matched_keys)} chaves\")\n",
        "\n",
        "                # Atualiza estat√≠sticas totais\n",
        "                total_processed += SUBBATCH_SIZE\n",
        "                total_elapsed = time.time() - global_start_time\n",
        "                avg_speed = total_processed / total_elapsed if total_elapsed > 0 else 0\n",
        "\n",
        "                print(f\"üìä Estat√≠sticas gerais:\")\n",
        "                print(f\"   Processado: {total_processed:,}/{total_keys:,} chaves ({(total_processed/total_keys)*100:.1f}%)\")\n",
        "                print(f\"   Velocidade m√©dia: {avg_speed/1e6:.2f} Mchaves/s\")\n",
        "                print(f\"   Tempo decorrido: {total_elapsed:.2f}s\")\n",
        "\n",
        "                if len(valid_keys) >= 10:\n",
        "                    print(\"üéØ Atingido limite de 10 chaves! Interrompendo processamento.\")\n",
        "                    break\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"‚ùå Erro no processamento do sub-lote {i+1}: {e}\")\n",
        "\n",
        "        # Estat√≠sticas finais\n",
        "        total_elapsed = time.time() - global_start_time\n",
        "        final_speed = total_processed / total_elapsed if total_elapsed > 0 else 0\n",
        "        print(f\"\\nüìà RESUMO FINAL:\")\n",
        "        print(f\"   Processadas {total_processed:,} chaves em {total_elapsed:.2f}s\")\n",
        "        print(f\"   Velocidade m√©dia: {final_speed/1e6:.2f} Mchaves/s\")\n",
        "        print(f\"   Chaves v√°lidas encontradas: {len(valid_keys)}\")\n",
        "\n",
        "        return valid_keys[:10]  # Retorna no m√°ximo 10 chaves\n",
        "\n",
        "    def submit_keys(self, keys):\n",
        "        \"\"\"\n",
        "        Envia as chaves encontradas para a API com informa√ß√µes detalhadas.\n",
        "        \"\"\"\n",
        "        if not keys:\n",
        "            print(\"‚ùå Nenhuma chave para enviar.\")\n",
        "            return False\n",
        "\n",
        "        print(f\"\\nüì§ ENVIANDO {len(keys)} CHAVES PARA API\")\n",
        "        print(\"=\" * 50)\n",
        "\n",
        "        # Formata as chaves para o formato esperado pela API\n",
        "        formatted_keys = []\n",
        "        for i, key in enumerate(keys[:10]):\n",
        "            # Converte para string hex e garante que tenha 64 caracteres\n",
        "            hex_key = f\"{key:064x}\"\n",
        "            # Adiciona o prefixo 0x\n",
        "            formatted_key = f\"0x{hex_key}\"\n",
        "            formatted_keys.append(formatted_key)\n",
        "            print(f\"  Chave #{i+1}: {formatted_key}\")\n",
        "\n",
        "        # Completa com zeros se n√£o tiver 10 chaves\n",
        "        remaining = 10 - len(formatted_keys)\n",
        "        if remaining > 0:\n",
        "            print(f\"  + {remaining} chaves vazias para completar o lote de 10\")\n",
        "            for _ in range(remaining):\n",
        "                formatted_keys.append(\"0x\" + \"0\" * 64)\n",
        "\n",
        "        # Prepara o payload para a API\n",
        "        payload = {\"privateKeys\": formatted_keys}\n",
        "\n",
        "        # Envia as chaves para a API\n",
        "        headers = {\n",
        "            \"pool-token\": POOL_TOKEN,\n",
        "            \"Content-Type\": \"application/json\"\n",
        "        }\n",
        "\n",
        "        print(\"\\nüîÑ Enviando requisi√ß√£o para a API...\")\n",
        "\n",
        "        try:\n",
        "            send_time = time.time()\n",
        "            response = requests.post(API_URL, headers=headers, json=payload)\n",
        "            elapsed = time.time() - send_time\n",
        "\n",
        "            if response.status_code == 200:\n",
        "                print(f\"‚úÖ SUCESSO! Chaves enviadas em {elapsed:.2f}s\")\n",
        "                try:\n",
        "                    resp_data = response.json()\n",
        "                    if resp_data:\n",
        "                        print(\"üìã Resposta da API:\")\n",
        "                        for k, v in resp_data.items():\n",
        "                            print(f\"  {k}: {v}\")\n",
        "                except:\n",
        "                    print(\"  Resposta sem dados JSON\")\n",
        "                return True\n",
        "            else:\n",
        "                print(f\"‚ùå ERRO {response.status_code} ao enviar chaves ({elapsed:.2f}s)\")\n",
        "                print(f\"üìã Resposta: {response.text}\")\n",
        "                return False\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå ERRO na requisi√ß√£o: {e}\")\n",
        "            return False\n",
        "        finally:\n",
        "            print(\"=\" * 50)\n",
        "\n",
        "    def run(self):\n",
        "        \"\"\"Loop principal de minera√ß√£o com informa√ß√µes detalhadas.\"\"\"\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"üî• BitcoinFlix Miner - Vers√£o Otimizada com Progresso Detalhado üî•\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "        # Informa√ß√µes do dispositivo\n",
        "        print(f\"\\nüì± INFORMA√á√ïES DO DISPOSITIVO:\")\n",
        "        print(f\"   Tipo: {'GPU' if torch.cuda.is_available() else 'CPU'}\")\n",
        "        if torch.cuda.is_available():\n",
        "            print(f\"   Modelo: {self.gpu_info['modelo']}\")\n",
        "            print(f\"   Mem√≥ria: {self.gpu_info['mem√≥ria_total_gb']:.2f} GB\")\n",
        "            if \"utiliza√ß√£o\" in self.gpu_info:\n",
        "                print(f\"   Utiliza√ß√£o: {self.gpu_info['utiliza√ß√£o']}\")\n",
        "                print(f\"   Temperatura: {self.gpu_info['temperatura']}\")\n",
        "\n",
        "        # Informa√ß√µes do bloco\n",
        "        print(f\"\\nüì¶ INFORMA√á√ïES DO BLOCO:\")\n",
        "        print(f\"   ID: {self.current_block['id']}\")\n",
        "        print(f\"   Posi√ß√£o: {self.current_block.get('position', 'N/A')}\")\n",
        "\n",
        "        # Informa√ß√µes do range\n",
        "        start_hex = self.current_block['range']['start']\n",
        "        end_hex = self.current_block['range']['end']\n",
        "        print(f\"\\nüî¢ RANGE DE PROCESSAMENTO:\")\n",
        "        print(f\"   In√≠cio: {start_hex}\")\n",
        "        print(f\"   Fim: {end_hex}\")\n",
        "\n",
        "        try:\n",
        "            range_start = int(start_hex, 16)\n",
        "            range_end = int(end_hex, 16)\n",
        "            range_size = range_end - range_start + 1\n",
        "            print(f\"   Tamanho: {range_size:,} chaves\")\n",
        "        except ValueError:\n",
        "            print(\"‚ùå Erro ao converter intervalo para inteiro\")\n",
        "            return\n",
        "\n",
        "        # Informa√ß√µes de configura√ß√£o\n",
        "        print(f\"\\n‚öôÔ∏è CONFIGURA√á√ïES:\")\n",
        "        print(f\"   Tamanho do lote: {SUBBATCH_SIZE:,} chaves\")\n",
        "        print(f\"   Alvos: {len(self.targets)} carteiras\")\n",
        "\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"üöÄ INICIANDO PROCESSAMENTO\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "        start_time = time.time()\n",
        "        valid_keys = self.process_range(range_start, range_end)\n",
        "\n",
        "        elapsed = time.time() - start_time\n",
        "        total_speed = SUBBATCH_SIZE * (range_size // SUBBATCH_SIZE) / elapsed if elapsed > 0 else 0\n",
        "\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        if valid_keys:\n",
        "            print(f\"üéØ RESULTADOS: {len(valid_keys)} CHAVES ENCONTRADAS\")\n",
        "            if self.submit_keys(valid_keys):\n",
        "                print(\"‚úÖ CHAVES ENVIADAS COM SUCESSO!\")\n",
        "            else:\n",
        "                print(\"‚ö†Ô∏è ERRO NO ENVIO DAS CHAVES\")\n",
        "        else:\n",
        "            print(\"üòû NENHUMA CHAVE V√ÅLIDA ENCONTRADA\")\n",
        "\n",
        "        # Estat√≠sticas finais\n",
        "        print(\"\\nüìä ESTAT√çSTICAS FINAIS:\")\n",
        "        print(f\"   Tempo total: {elapsed:.2f} segundos\")\n",
        "        print(f\"   Velocidade: {total_speed/1e6:.2f} Mchaves/segundo\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    miner = BitcoinFlixMiner()\n",
        "    miner.run()"
      ],
      "metadata": {
        "id": "h_5s__SuLu27"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}